{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857f2f91",
   "metadata": {
    "id": "857f2f91",
    "papermill": {
     "duration": 0.00445,
     "end_time": "2023-10-20T02:15:45.071851",
     "exception": false,
     "start_time": "2023-10-20T02:15:45.067401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Faces Age Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51-VyZP_BGdJ",
   "metadata": {
    "id": "51-VyZP_BGdJ"
   },
   "source": [
    "## Import Libraries and Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XSCWWgUMMU7Y",
   "metadata": {
    "id": "XSCWWgUMMU7Y"
   },
   "outputs": [],
   "source": [
    "!pip install pykan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5hT9QMsYMXVx",
   "metadata": {
    "id": "5hT9QMsYMXVx"
   },
   "outputs": [],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07538deb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T02:15:45.088859Z",
     "iopub.status.busy": "2023-10-20T02:15:45.088192Z",
     "iopub.status.idle": "2023-10-20T02:16:02.778549Z",
     "shell.execute_reply": "2023-10-20T02:16:02.777382Z"
    },
    "id": "07538deb",
    "papermill": {
     "duration": 17.69764,
     "end_time": "2023-10-20T02:16:02.780972",
     "exception": false,
     "start_time": "2023-10-20T02:15:45.083332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import inspect\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset, WeightedRandomSampler\n",
    "import torch.nn.utils.prune as prune\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "from kan import *\n",
    "from sklearn.model_selection import ParameterSampler, KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    running_in_colab = True\n",
    "except ImportError:\n",
    "    running_in_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BSh8HbaKYUpQ",
   "metadata": {
    "id": "BSh8HbaKYUpQ"
   },
   "outputs": [],
   "source": [
    "if running_in_colab:\n",
    "    print(\"Running on Google Colab\")\n",
    "    !apt-get update -qq\n",
    "    !apt-get install -qq git-lfs\n",
    "    !git lfs install\n",
    "    !git clone https://github.com/vMxster/Thesis.git\n",
    "    !cd Thesis && git lfs pull\n",
    "    zip_part   = \"Thesis/Datasets/UTKFace_\"\n",
    "else:\n",
    "    print(\"Running locally in Jupyter\")\n",
    "    zip_part   = \"Datasets/UTKFace_\"\n",
    "\n",
    "zip_extract_to = \"datasets\"\n",
    "os.makedirs(zip_extract_to, exist_ok=True)\n",
    "\n",
    "for i in range(1,4):\n",
    "    zip_path = zip_part + str(i) + \".zip\"\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(zip_extract_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8rTDr1p2Fl6p",
   "metadata": {
    "id": "8rTDr1p2Fl6p"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BGt_VamtFCMK",
   "metadata": {
    "id": "BGt_VamtFCMK"
   },
   "outputs": [],
   "source": [
    "if running_in_colab:\n",
    "    filenames = glob.glob(f'{zip_extract_to}/*.jpg')\n",
    "else:\n",
    "    filenames = [str(p.as_posix()) for p in Path(zip_extract_to).glob(f'*.jpg')]\n",
    "\n",
    "print(len(filenames))\n",
    "print(filenames[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L1QI6KzTHTHy",
   "metadata": {
    "id": "L1QI6KzTHTHy"
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "np.random.shuffle(filenames)\n",
    "\n",
    "age_labels, gender_labels, ethnic_labels, image_path = [], [], [], []\n",
    "\n",
    "for filename in filenames:\n",
    "    image_path.append(filename)\n",
    "    temp = filename.split('_')\n",
    "    age_labels.append(temp[0].split('/')[1])\n",
    "    gender_labels.append(temp[1])\n",
    "    ethnic_labels.append(temp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VegCPN3lJrJA",
   "metadata": {
    "id": "VegCPN3lJrJA"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['image'], df['age'], df['gender'], df['ethnic'] = image_path, age_labels, gender_labels, ethnic_labels\n",
    "\n",
    "df = df[df['age'].str.isdigit()]\n",
    "df = df[df['gender'].str.isdigit()]\n",
    "df = df[df['ethnic'].str.isdigit()]\n",
    "\n",
    "df = df.astype({'age':'int64', 'gender': 'int64', 'ethnic': 'int64'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mZoI-z0w0UMF",
   "metadata": {
    "id": "mZoI-z0w0UMF"
   },
   "outputs": [],
   "source": [
    "gender_dict = {0:\"Male\", 1:\"Female\"}\n",
    "df = df[df['gender'].isin([0, 1])]\n",
    "df['gender'] = df['gender'].map(gender_dict)\n",
    "df['gender'] = df['gender'].astype('category')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rK7dIggU51wR",
   "metadata": {
    "id": "rK7dIggU51wR"
   },
   "outputs": [],
   "source": [
    "ethnic_dict = {0:\"White\", 1:\"Black\", 2:\"Asian\", 3:\"Indian\", 4:\"Others\"}\n",
    "df = df[df['ethnic'].isin([0, 1, 2, 3, 4])]\n",
    "df['ethnic'] = df['ethnic'].map(ethnic_dict)\n",
    "df['ethnic'] = df['ethnic'].astype('category')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iQ04xFMTv605",
   "metadata": {
    "id": "iQ04xFMTv605"
   },
   "outputs": [],
   "source": [
    "def age_group(age):\n",
    "    if age <= 12:\n",
    "        return 0\n",
    "    elif age <= 18:\n",
    "        return 1\n",
    "    elif age <= 60:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "df['age_group'] = df['age'].apply(age_group)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gcgFvVC0-MZX",
   "metadata": {
    "id": "gcgFvVC0-MZX"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5mfmIBJdA5vB",
   "metadata": {
    "id": "5mfmIBJdA5vB"
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4NV3--n4BkyG",
   "metadata": {
    "id": "4NV3--n4BkyG"
   },
   "outputs": [],
   "source": [
    "df.drop('image', axis=1).describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UGztZCEZGB1e",
   "metadata": {
    "id": "UGztZCEZGB1e"
   },
   "outputs": [],
   "source": [
    "age_counts = df.age.value_counts()\n",
    "total_count = age_counts.sum()\n",
    "age_percentages = (age_counts / total_count) * 100\n",
    "\n",
    "# Identify ages with less than 1%\n",
    "other_ages = age_percentages[age_percentages < 1]\n",
    "other_percentage = other_ages.sum()\n",
    "\n",
    "# Create a new series for plotting\n",
    "plot_data = age_percentages[age_percentages >= 1]\n",
    "if other_percentage > 0:\n",
    "    plot_data['Others'] = other_percentage\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Distribution of Ages in Percentage\")\n",
    "plot_data.plot.pie(autopct='%1.1f%%', startangle=90)\n",
    "plt.ylabel('')\n",
    "plt.figtext(0.5, 0.01, \"The 'Others' category includes ages with a distribution of less than 1%.\", ha=\"center\", fontsize=10, bbox={\"facecolor\":\"orange\", \"alpha\":0.5, \"pad\":5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qe5iSfD3wMPw",
   "metadata": {
    "id": "Qe5iSfD3wMPw"
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(40, 30)) # Create a figure with 3 subplots (3 rows, 1 column)\n",
    "fig.suptitle(\"Distribution of Ages by Gender\", fontsize=40) # Main title\n",
    "\n",
    "# Plot for all ages\n",
    "age_counts = df.age.value_counts()\n",
    "sns.barplot(x=age_counts.index, y=age_counts.values, ax=axes[0], color='black')\n",
    "axes[0].set_title(\"Distribution of All Ages\", fontsize=20)\n",
    "axes[0].set_xlabel(\"Age\", fontsize=18)\n",
    "axes[0].set_ylabel(\"Count\", fontsize=18)\n",
    "\n",
    "# Plot for male ages\n",
    "male_age_counts = df[df.gender == 'Male'].age.value_counts()\n",
    "sns.barplot(x=male_age_counts.index, y=male_age_counts.values, ax=axes[1], color='blue')\n",
    "axes[1].set_title(\"Distribution of Ages for Males\", fontsize=20)\n",
    "axes[1].set_xlabel(\"Age\", fontsize=18)\n",
    "axes[1].set_ylabel(\"Count\", fontsize=18)\n",
    "\n",
    "# Plot for female ages\n",
    "female_age_counts = df[df.gender == 'Female'].age.value_counts()\n",
    "sns.barplot(x=female_age_counts.index, y=female_age_counts.values, ax=axes[2], color='orange')\n",
    "axes[2].set_title(\"Distribution of Ages for Females\", fontsize=20)\n",
    "axes[2].set_xlabel(\"Age\", fontsize=18)\n",
    "axes[2].set_ylabel(\"Count\", fontsize=18)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent titles overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yx8Q8UqdxITP",
   "metadata": {
    "id": "yx8Q8UqdxITP"
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"Distribution of Genders\")\n",
    "plt.pie(df.gender.value_counts(), labels=df.gender.value_counts().index, autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ECdTrF6aEcra",
   "metadata": {
    "id": "ECdTrF6aEcra"
   },
   "outputs": [],
   "source": [
    "age_gender_counts = df.groupby(['age', 'gender'], observed=True).size().unstack(fill_value=0)\n",
    "age_gender_percentages = age_gender_counts.apply(lambda x: x / x.sum(), axis=1)\n",
    "\n",
    "ax = age_gender_percentages.plot(kind='bar', stacked=True, figsize=(20, 10), color=['blue', 'orange'])\n",
    "\n",
    "plt.title('Percentage of Males and Females by Age', fontsize=20)\n",
    "plt.xlabel('Age', fontsize=15)\n",
    "plt.ylabel('Percentage', fontsize=15)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(title='Gender')\n",
    "\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    if height > 0:\n",
    "        x, y = p.get_xy()\n",
    "        ax.text(x + width / 2,\n",
    "                y + height / 2,\n",
    "                '{:.1f}%'.format(height * 100),\n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='center',\n",
    "                fontsize=6,\n",
    "                color='white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59YJwsUGzefI",
   "metadata": {
    "id": "59YJwsUGzefI"
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"Distribution of Ethnic groups\")\n",
    "plt.pie(df.ethnic.value_counts(), labels=df.ethnic.value_counts().index, autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8C21Q_DxFT1o",
   "metadata": {
    "id": "8C21Q_DxFT1o"
   },
   "outputs": [],
   "source": [
    "# Bar plot for age and ethnicity\n",
    "for ethnic_group in df['ethnic'].unique():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    ethnic_df = df[df['ethnic'] == ethnic_group]\n",
    "    sns.countplot(data=ethnic_df, x='age')\n",
    "    plt.title(f'Age Distribution for {ethnic_group}')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "# Bar plot for ethnicity and gender\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='ethnic', hue='gender')\n",
    "plt.title('Distribution of Gender by Ethnicity')\n",
    "plt.xlabel('Ethnicity')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WlqCwcVEa0Vt",
   "metadata": {
    "id": "WlqCwcVEa0Vt"
   },
   "outputs": [],
   "source": [
    "class_counts = df['age_group'].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "age_group_labels = {0: \"Child [1;12]\", 1: \"Young [13;18]\", 2: \"Adult [19;60]\", 3: \"Senior [60;inf]\"}\n",
    "pie_labels = [age_group_labels[i] for i in class_counts.index]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(class_counts, labels=pie_labels, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WFrnOr1MwNvn",
   "metadata": {
    "id": "WFrnOr1MwNvn"
   },
   "source": [
    "### Plotting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81LQDyyUv8",
   "metadata": {
    "id": "8b81LQDyyUv8"
   },
   "outputs": [],
   "source": [
    "# Options\n",
    "print(f'Choose one Age in: {sorted([int(age) for age in df[\"age\"].unique()])}\\n')\n",
    "print(f'Choose one Gender in: {df[\"gender\"].unique()}\\n')\n",
    "print(f'Choose one Ethnic (or \"All\") in: {df[\"ethnic\"].unique()}\\n')\n",
    "\n",
    "# Define Specifics\n",
    "age = 26\n",
    "gender = 'Male'\n",
    "ethnic = 'All'\n",
    "\n",
    "if ethnic == 'All':\n",
    "    files = df.loc[(df['gender'] == gender) & (df['age'] == age)]\n",
    "else:\n",
    "    files = df.loc[(df['gender'] == gender) & (df['ethnic'] == ethnic) & (df['age'] == age)]\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for i, (index, row) in enumerate(files.head(25).iterrows()):\n",
    "    plt.subplot(5,5, i+1)\n",
    "    img = Image.open(row['image'])\n",
    "    img = np.array(img)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Age: {row['age']} ; Gender: {row['gender']}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F7qEzz1oMGRj",
   "metadata": {
    "id": "F7qEzz1oMGRj"
   },
   "source": [
    "## Allenamento Modelli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5GZyqqRSUQF-",
   "metadata": {
    "id": "5GZyqqRSUQF-"
   },
   "source": [
    "### Definizione Modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2gGooYZWNFZD",
   "metadata": {
    "id": "2gGooYZWNFZD"
   },
   "outputs": [],
   "source": [
    "class CNNFeatureExtractor(nn.Module):\n",
    "    \"\"\"Feature extractor CNN basato sull'architettura del primo documento\"\"\"\n",
    "    def __init__(self, input_channels=3):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        # Per input 224x224, dopo conv1 (3x3, stride 1) e max_pool (2x2):\n",
    "        # (224 - 3 + 1)/1 = 222, poi 222/2 = 111\n",
    "        # Dopo conv2 (3x3, stride 1) e max_pool (2x2):\n",
    "        # (111 - 3 + 1)/1 = 109, poi 109/2 = 54.5 -> floor a 54\n",
    "        self.feature_dim = 16 * 54 * 54\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, self.feature_dim)  # Flatten\n",
    "        return x\n",
    "\n",
    "class CNN_MLP(nn.Module):\n",
    "    \"\"\"CNN + MLP combinato\"\"\"\n",
    "    def __init__(self, input_channels=3, hidden_sizes=[120, 84, 20], dropout=0.0, num_classes=6, device='cpu'):\n",
    "        super(CNN_MLP, self).__init__()\n",
    "        self.cnn_features = CNNFeatureExtractor(input_channels)\n",
    "\n",
    "        # MLP layers\n",
    "        layers = []\n",
    "        dim = self.cnn_features.feature_dim\n",
    "        for hs in hidden_sizes:\n",
    "            layers.append(nn.Linear(dim, hs))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            dim = hs\n",
    "        layers.append(nn.Linear(dim, num_classes))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.cnn_features(x)\n",
    "        return self.mlp(features)\n",
    "\n",
    "class CNN_KAN(nn.Module):\n",
    "    \"\"\"CNN + KAN combinato\"\"\"\n",
    "    def __init__(self, input_channels=3, width=[8, 4], grid=5, k=3, num_classes=6, seed=0, device='cpu'):\n",
    "        super(CNN_KAN, self).__init__()\n",
    "        self.cnn_features = CNNFeatureExtractor(input_channels)\n",
    "\n",
    "        # KAN network\n",
    "        kan_width = [self.cnn_features.feature_dim] + list(width) + [num_classes]\n",
    "        self.kan = KAN(\n",
    "            width=kan_width,\n",
    "            grid=grid,\n",
    "            k=k,\n",
    "            seed=seed,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.cnn_features(x)\n",
    "        return self.kan(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toQbpNSDUSKt",
   "metadata": {
    "id": "toQbpNSDUSKt"
   },
   "source": [
    "### Definizione Dataset e Split in Train e Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xHD4e-EwNSLZ",
   "metadata": {
    "id": "xHD4e-EwNSLZ"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset personalizzato per immagini con preprocessing\"\"\"\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "        # Transform di default come nel primo documento\n",
    "        if self.transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                   [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "            img = self.transform(img)\n",
    "            label = self.labels[idx]\n",
    "            return img, label\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nel caricamento dell'immagine {self.image_paths[idx]}: {e}\")\n",
    "            # Restituisci un'immagine nera come fallback\n",
    "            img = torch.zeros(3, 224, 224)\n",
    "            return img, self.labels[idx]\n",
    "\n",
    "def create_image_train_test_sets(image_paths, labels, split=0.8):\n",
    "    \"\"\"Crea train e test set per le immagini mantenendo l'ordine temporale\"\"\"\n",
    "    dataset_size = len(image_paths)\n",
    "    train_size = int(dataset_size * split)\n",
    "\n",
    "    train_paths = image_paths[:train_size]\n",
    "    test_paths = image_paths[train_size:]\n",
    "    train_labels = labels[:train_size]\n",
    "    test_labels = labels[train_size:]\n",
    "\n",
    "    return train_paths, test_paths, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GFSzW1CBUM7y",
   "metadata": {
    "id": "GFSzW1CBUM7y"
   },
   "source": [
    "### EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hpit6FBPOfEj",
   "metadata": {
    "id": "Hpit6FBPOfEj"
   },
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=3, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, val_loss):\n",
    "        # Se la loss migliora (di almeno min_delta), resettiamo il counter\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            # Se la loss non migliora da 'patience' epoche, dobbiamo fermarci\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RAZJ5vZNUJe7",
   "metadata": {
    "id": "RAZJ5vZNUJe7"
   },
   "source": [
    "### Train ed Eval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3B_jwfgAOXM6",
   "metadata": {
    "id": "3B_jwfgAOXM6"
   },
   "outputs": [],
   "source": [
    "def train_cnn_epoch(model, loader, optimizer, criterion, device, l2_lambda=0.0):\n",
    "    \"\"\"Training epoch per modelli CNN\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch_idx, (images, labels) in enumerate(tqdm(loader, desc=\"Training\")):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # L2 Regularization\n",
    "        if l2_lambda > 0:\n",
    "            l2_reg = torch.tensor(0.).to(device)\n",
    "            for param in model.parameters():\n",
    "                l2_reg += torch.norm(param, 2)\n",
    "            loss += l2_lambda * l2_reg\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def eval_cnn_loss(model, loader, criterion, device):\n",
    "    \"\"\"Valutazione loss per modelli CNN\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            total_loss += criterion(outputs, labels).item() * images.size(0)\n",
    "    return total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JP9fNayGUFuW",
   "metadata": {
    "id": "JP9fNayGUFuW"
   },
   "source": [
    "### RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NvcF1uNkOT3E",
   "metadata": {
    "id": "NvcF1uNkOT3E"
   },
   "outputs": [],
   "source": [
    "def random_search_cnn(model_builder, param_dist, train_paths, train_labels,\n",
    "                      n_iter=10, cv_folds=5, batch_size=32,\n",
    "                      early_patience=5, early_min_delta=1e-4,\n",
    "                      class_weights=None, device='cpu'):\n",
    "    \"\"\"Random search for CNN models with KFold Cross Validation\"\"\"\n",
    "\n",
    "    train_keys = ['lr', 'l2_lambda']\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_params, best_train_params = None, None\n",
    "    best_model = None\n",
    "\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    print(\"Starting Random Search CNN with KFold Cross Validation...\")\n",
    "\n",
    "    for param_id, params in enumerate(ParameterSampler(param_dist, n_iter=n_iter, random_state=42)):\n",
    "        print(f\"Testing parameter set {param_id+1}/{n_iter}\")\n",
    "\n",
    "        model_params = {k: v for k, v in params.items() if k not in train_keys}\n",
    "        train_params = {k: v for k, v in params.items() if k in train_keys}\n",
    "        val_losses = []\n",
    "\n",
    "        # Prepare indices for KFold\n",
    "        indices = np.arange(len(train_paths))\n",
    "\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(kf.split(indices)):\n",
    "            print(f\"  Fold {fold_idx+1}/{cv_folds}\")\n",
    "\n",
    "            # Create subsets for this fold\n",
    "            fold_train_paths = [train_paths[i] for i in train_idx]\n",
    "            fold_train_labels = [train_labels[i] for i in train_idx]\n",
    "            fold_val_paths = [train_paths[i] for i in val_idx]\n",
    "            fold_val_labels = [train_labels[i] for i in val_idx]\n",
    "\n",
    "            # Create dataset for this fold\n",
    "            train_dataset = ImageDataset(fold_train_paths, fold_train_labels)\n",
    "            val_dataset = ImageDataset(fold_val_paths, fold_val_labels)\n",
    "\n",
    "            # Calculate weights for weighted sampling\n",
    "            if class_weights is not None:\n",
    "                sample_weights = np.array([class_weights.get(label, 1.0) for label in fold_train_labels])\n",
    "                sampler = WeightedRandomSampler(\n",
    "                    weights=sample_weights,\n",
    "                    num_samples=len(sample_weights),\n",
    "                    replacement=True\n",
    "                )\n",
    "                train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "            else:\n",
    "                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            # Create and train the model\n",
    "            if 'width' in model_params:\n",
    "                model = model_builder(**model_params, device=device)\n",
    "                if isinstance(model, CNN_KAN):\n",
    "                    model.kan.speed()\n",
    "            else:\n",
    "                model = model_builder(**model_params)\n",
    "            model.to(device)\n",
    "\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=train_params['lr'])\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            stopper = EarlyStopper(patience=early_patience, min_delta=early_min_delta)\n",
    "\n",
    "            for epoch in range(100):\n",
    "                train_loss = train_cnn_epoch(model, train_loader, optimizer, criterion, device,\n",
    "                                           l2_lambda=train_params.get('l2_lambda', 0.0))\n",
    "                val_loss = eval_cnn_loss(model, val_loader, criterion, device)\n",
    "\n",
    "                if epoch % 10 == 0:\n",
    "                    print(f\"    Epoch {epoch}: train_loss = {train_loss:.6f}, val_loss = {val_loss:.6f}\")\n",
    "\n",
    "                if stopper.early_stop(val_loss):\n",
    "                    print(f\"    Early stopping at epoch {epoch}, best_val_loss: {stopper.best_loss:.6f}\")\n",
    "                    break\n",
    "\n",
    "            final_val_loss = eval_cnn_loss(model, val_loader, criterion, device)\n",
    "            val_losses.append(final_val_loss)\n",
    "\n",
    "        mean_val = np.mean(val_losses)\n",
    "        print(f\"  Mean validation loss: {mean_val:.6f}\")\n",
    "\n",
    "        if mean_val < best_val_loss:\n",
    "            best_val_loss = mean_val\n",
    "            best_model_params = model_params\n",
    "            best_train_params = train_params\n",
    "            if 'width' in best_model_params:\n",
    "                best_model = model_builder(**best_model_params, device=device).to(device)\n",
    "            else:\n",
    "                best_model = model_builder(**best_model_params).to(device)\n",
    "\n",
    "            best_model.load_state_dict(model.state_dict())\n",
    "            print(f\"  New best validation loss: {best_val_loss:.6f}\")\n",
    "\n",
    "    print(f\"\\nBest validation loss: {best_val_loss:.6f}\")\n",
    "    return best_model, best_model_params, best_train_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aqmioU9_TzTk",
   "metadata": {
    "id": "aqmioU9_TzTk"
   },
   "source": [
    "### Calcolo Metriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O-k7I9v-L0up",
   "metadata": {
    "id": "O-k7I9v-L0up"
   },
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    total_params = 0\n",
    "\n",
    "    if isinstance(model, CNN_KAN):\n",
    "        # Count parameters for the CNNFeatureExtractor part (standard nn.Module)\n",
    "        cnn_params = sum(p.numel() for p in model.cnn_features.parameters() if p.requires_grad)\n",
    "        total_params += cnn_params\n",
    "\n",
    "        # Count parameters for the KAN part (using the specific KAN formula)\n",
    "        kan_model = model.kan\n",
    "        try:\n",
    "            if not kan_model.width or len(kan_model.width) < 2:\n",
    "                # No parameters if width is invalid\n",
    "                kan_params = 0\n",
    "            else:\n",
    "                sum_edge_terms = 0\n",
    "                for i in range(len(kan_model.width) - 1):\n",
    "                    # Nl and Nl+1 in the formula\n",
    "                    Nl = kan_model.width[i]\n",
    "                    Nl_plus_1 = kan_model.width[i+1]\n",
    "\n",
    "                    # Handle potential list formats for Nl/Nl+1, though integers are expected for width\n",
    "                    if isinstance(Nl, list): Nl = Nl[0]\n",
    "                    if isinstance(Nl_plus_1, list): Nl_plus_1 = Nl_plus_1[0]\n",
    "\n",
    "                    # G and k from the KAN object\n",
    "                    G = kan_model.grid\n",
    "                    k = kan_model.k\n",
    "\n",
    "                    # Nl * Nl+1 * (G + k - 1)\n",
    "                    sum_edge_terms += Nl * Nl_plus_1 * (G + k - 1)\n",
    "                kan_params = sum_edge_terms\n",
    "            total_params += kan_params\n",
    "            return total_params\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating KAN parameters for CNN_KAN's KAN component: {e}\")\n",
    "            return total_params # Return sum of CNN params + whatever could be calculated\n",
    "\n",
    "    # If it's a standard nn.Module (like CNN_MLP or CNNFeatureExtractor directly)\n",
    "    elif isinstance(model, nn.Module):\n",
    "        try:\n",
    "            return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating standard nn.Module parameters: {e}\")\n",
    "            return 0\n",
    "\n",
    "    # If it's directly a KAN instance (not wrapped in CNN_KAN)\n",
    "    elif isinstance(model, KAN):\n",
    "        try:\n",
    "            if not model.width or len(model.width) < 2:\n",
    "                return 0\n",
    "            else:\n",
    "                sum_edge_terms = 0\n",
    "                for i in range(len(model.width) - 1):\n",
    "                    Nl = model.width[i]\n",
    "                    Nl_plus_1 = model.width[i+1]\n",
    "                    if isinstance(Nl, list): Nl = Nl[0]\n",
    "                    if isinstance(Nl_plus_1, list): Nl_plus_1 = Nl_plus_1[0]\n",
    "                    G = model.grid\n",
    "                    k = model.k\n",
    "                    sum_edge_terms += Nl * Nl_plus_1 * (G + k - 1)\n",
    "                return sum_edge_terms\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating KAN parameters: {e}\")\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def bootstrap_ci(metric_fn, y_true, y_pred, n_bootstraps=1000, alpha=0.05, **metric_kwargs):\n",
    "    y_true_arr = np.asarray(y_true)\n",
    "    y_pred_arr = np.asarray(y_pred)\n",
    "    vals = []\n",
    "    n_samples = len(y_true)\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "        idx = np.random.randint(0, n_samples, n_samples)\n",
    "        vals.append(metric_fn(y_true_arr[idx], y_pred_arr[idx], **metric_kwargs))\n",
    "\n",
    "    low = np.percentile(vals, 100 * (alpha / 2))\n",
    "    high = np.percentile(vals, 100 * (1 - alpha / 2))\n",
    "    return low, high\n",
    "\n",
    "def get_cnn_estimator_scores(model_name, model, test_paths, test_labels,\n",
    "                           train_paths, train_labels, device, batch_size=32):\n",
    "    \"\"\"Valutazione prestazioni per modelli CNN - stile secondo documento\"\"\"\n",
    "    print(f\"\\n--- Valutazione Prestazioni per {model_name} (CNN) ---\")\n",
    "\n",
    "    # Calcola parametri del modello\n",
    "    param_count = count_params(model)\n",
    "    print(f\"Model Parameters: {param_count}\")\n",
    "\n",
    "    # Crea dataset e dataloader\n",
    "    train_dataset = ImageDataset(train_paths, train_labels)\n",
    "    test_dataset = ImageDataset(test_paths, test_labels)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Predizioni\n",
    "    model.eval()\n",
    "    y_pred_train, y_true_train = [], []\n",
    "    y_pred_test, y_true_test = [], []\n",
    "    y_proba_test = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Training set\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "            y_pred_train.extend(pred.cpu().numpy())\n",
    "            y_true_train.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Test set\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "            proba = F.softmax(outputs, dim=1)\n",
    "\n",
    "            y_pred_test.extend(pred.cpu().numpy())\n",
    "            y_true_test.extend(labels.cpu().numpy())\n",
    "            y_proba_test.extend(proba.cpu().numpy())\n",
    "\n",
    "    y_proba_test = np.array(y_proba_test)\n",
    "\n",
    "    # Calcola metriche\n",
    "    accuracy_tr = accuracy_score(y_true_train, y_pred_train)\n",
    "    f1_weighted_tr = f1_score(y_true_train, y_pred_train, average='weighted', zero_division=0)\n",
    "    f1_macro_tr = f1_score(y_true_train, y_pred_train, average='macro', zero_division=0)\n",
    "\n",
    "    accuracy_te = accuracy_score(y_true_test, y_pred_test)\n",
    "    f1_weighted_te = f1_score(y_true_test, y_pred_test, average='weighted', zero_division=0)\n",
    "    f1_macro_te = f1_score(y_true_test, y_pred_test, average='macro', zero_division=0)\n",
    "\n",
    "    # Bootstrap CI\n",
    "    f1_weighted_low, f1_weighted_high = bootstrap_ci(\n",
    "        f1_score, y_true_test, y_pred_test, average='weighted', zero_division=0\n",
    "    )\n",
    "    f1_macro_low, f1_macro_high = bootstrap_ci(\n",
    "        f1_score, y_true_test, y_pred_test, average='macro', zero_division=0\n",
    "    )\n",
    "\n",
    "    print(\"\\nClassification Report (Test Set):\")\n",
    "    print(classification_report(y_true_test, y_pred_test, zero_division=0))\n",
    "\n",
    "    print(\"\\nConfusion Matrix (Test Set):\")\n",
    "    print(confusion_matrix(y_true_test, y_pred_test))\n",
    "\n",
    "    scores_row = [\n",
    "        model_name, param_count,\n",
    "        accuracy_tr, accuracy_te,\n",
    "        f1_weighted_tr, f1_weighted_te, f1_weighted_low, f1_weighted_high,\n",
    "        f1_macro_tr, f1_macro_te, f1_macro_low, f1_macro_high\n",
    "    ]\n",
    "\n",
    "    # Calcolo AUC\n",
    "    try:\n",
    "        auc_roc_ovr = roc_auc_score(y_true_test, y_proba_test, multi_class='ovr', average='weighted')\n",
    "        auc_pr_ovr = average_precision_score(pd.get_dummies(y_true_test), y_proba_test, average='weighted')\n",
    "\n",
    "        # Bootstrap per AUC\n",
    "        auc_roc_low, auc_roc_high = bootstrap_ci(\n",
    "            lambda yt, yp: roc_auc_score(yt, yp, multi_class='ovr', average='weighted'),\n",
    "            y_true_test, y_proba_test\n",
    "        )\n",
    "        auc_pr_low, auc_pr_high = bootstrap_ci(\n",
    "            lambda yt, yp: average_precision_score(pd.get_dummies(yt), yp, average='weighted'),\n",
    "            y_true_test, y_proba_test\n",
    "        )\n",
    "\n",
    "        scores_row.extend([auc_roc_ovr, auc_roc_low, auc_roc_high, auc_pr_ovr, auc_pr_low, auc_pr_high])\n",
    "        print(f\"AUC-ROC (OVR, Weighted): {auc_roc_ovr:.3f}\")\n",
    "        print(f\"AUC-PR (OVR, Weighted): {auc_pr_ovr:.3f}\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Errore nel calcolo di AUC/PR: {e}\")\n",
    "        scores_row.extend([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "\n",
    "    all_scores.append(scores_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N2VbqTAtT4PW",
   "metadata": {
    "id": "N2VbqTAtT4PW"
   },
   "source": [
    "### Preparazione Dati, Definizione Griglia ed Allenamento Modelli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L7mFOrwMLmeE",
   "metadata": {
    "id": "L7mFOrwMLmeE"
   },
   "source": [
    "**Scelta del numero di iterazioni per RandomizedSearchCV con CNN_MLP grid**\n",
    "\n",
    "Il grid ha:\n",
    "\n",
    "- Configurazioni Totali:\n",
    "$$\n",
    "M = 54\n",
    "$$\n",
    "\n",
    "Supponiamo di voler avere una probabilità \\( P = 0.90 \\) di includere almeno una delle migliori \\( k = 10 \\) configurazioni tra queste 54.\n",
    "\n",
    "Usiamo la formula:\n",
    "\n",
    "$$\n",
    "n = \\frac{\\ln(1 - P)}{\\ln\\left(1 - \\frac{k}{M}\\right)}\n",
    "$$\n",
    "\n",
    "Calcoliamo:\n",
    "\n",
    "$$\n",
    "n = \\frac{\\ln(1 - 0.90)}{\\ln\\left(1 - \\frac{10}{54}\\right)} = \\frac{\\ln(0.10)}{\\ln\\left(\\frac{44}{54}\\right)} = \\frac{-2.3026}{\\ln(\\frac{44}{54})} \\approx \\frac{2.3026}{0.2047} \\approx 11.25\n",
    "$$\n",
    "\n",
    "Quindi, con **11 iterazioni** di Randomized Search, si ha circa il 90% di probabilità di testare almeno una delle 10 migliori configurazioni, risparmiando molto rispetto a un Grid Search completo con 54 combinazioni.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F7zhlGsyMYrT",
   "metadata": {
    "id": "F7zhlGsyMYrT"
   },
   "source": [
    "**Scelta del numero di iterazioni per RandomizedSearchCV con CNN_KAN grid**\n",
    "\n",
    "Il grid ha:\n",
    "\n",
    "- Configurazioni Totali:\n",
    "$$\n",
    "M = 72\n",
    "$$\n",
    "\n",
    "Supponiamo di voler avere una probabilità \\( P = 0.90 \\) di includere almeno una delle migliori \\( k = 10 \\) configurazioni tra queste 72.\n",
    "\n",
    "Usiamo la formula:\n",
    "\n",
    "$$\n",
    "n = \\frac{\\ln(1 - P)}{\\ln\\left(1 - \\frac{k}{M}\\right)}\n",
    "$$\n",
    "\n",
    "Calcoliamo:\n",
    "\n",
    "$$\n",
    "n = \\frac{\\ln(1 - 0.90)}{\\ln\\left(1 - \\frac{10}{72}\\right)} = \\frac{\\ln(0.10)}{\\ln\\left(\\frac{62}{72}\\right)} = \\frac{-2.3026}{\\ln(\\frac{62}{72})} \\approx \\frac{2.3026}{0.1495} \\approx 15.40\n",
    "$$\n",
    "\n",
    "Quindi, con **15 iterazioni** di Randomized Search, si ha circa il 90% di probabilità di testare almeno una delle 10 migliori configurazioni, risparmiando molto rispetto a un Grid Search completo con 72 combinazioni.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3Vwc1L7pL6L0",
   "metadata": {
    "id": "3Vwc1L7pL6L0"
   },
   "source": [
    "**Da dove viene la formula per stimare il numero di iterazioni nel Randomized Search?**\n",
    "\n",
    "Per stimare quante iterazioni (`n`) sono necessarie per avere una certa probabilità \\(P\\) di includere almeno una configurazione tra le \\(k\\) migliori (su \\(M\\) totali), usiamo la seguente logica probabilistica:\n",
    "\n",
    "1. Probabilità di *non* pescare una top-\\(k\\) in un singolo tentativo.\n",
    "Se ci sono \\(M\\) configurazioni totali e \\(k\\) di esse sono “quasi ottimali”, la probabilità di *non* sceglierne una buona è:\n",
    "$$\n",
    "1 - \\frac{k}{M}\n",
    "$$\n",
    "\n",
    "2. Probabilità di non pescarne *nessuna* in \\(n\\) tentativi indipendenti\n",
    "$$\n",
    "\\left(1 - \\frac{k}{M} \\right)^n\n",
    "$$\n",
    "\n",
    "3. Probabilità di pescare **almeno una** delle top-\\(k\\)\n",
    "$$\n",
    "P(\\text{≥1 top-}k) = 1 - \\left(1 - \\frac{k}{M} \\right)^n\n",
    "$$\n",
    "\n",
    "4. Ricavare \\(n\\) dalla formula\n",
    "$$\n",
    "1 - \\left(1 - \\frac{k}{M} \\right)^n = P\n",
    "\\quad \\Longrightarrow \\quad\n",
    "n = \\frac{\\ln(1 - P)}{\\ln\\left(1 - \\frac{k}{M} \\right)}\n",
    "$$\n",
    "\n",
    "5. Approssimazione per $$ k \\ll M $$\n",
    "Poiché $$ \\ln(1 - x) \\approx -x $$ per \\(x\\) piccolo:\n",
    "$$\n",
    "n \\approx - \\frac{\\ln(1 - P)}{k/M}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ns7CqHEEO_bM",
   "metadata": {
    "id": "Ns7CqHEEO_bM"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device utilizzato: {device}\")\n",
    "\n",
    "image_paths = list(df['image'])\n",
    "labels = list(df['age_group'].astype('category').cat.codes)\n",
    "\n",
    "# Dividi in train/test\n",
    "train_paths, test_paths, train_labels, test_labels = create_image_train_test_sets(\n",
    "    image_paths, labels, split=0.8\n",
    ")\n",
    "\n",
    "# Calcola pesi delle classi\n",
    "class_labels = np.unique(train_labels)\n",
    "class_weights_balanced = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=class_labels,\n",
    "    y=train_labels\n",
    ")\n",
    "class_weights_dict = dict(zip(class_labels, class_weights_balanced))\n",
    "\n",
    "# Definisci spazi di ricerca iperparametri\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NHod6sHw7aO-",
   "metadata": {
    "id": "NHod6sHw7aO-"
   },
   "outputs": [],
   "source": [
    "cnn_mlp_param_dist = {\n",
    "    'input_channels': [3],\n",
    "    'hidden_sizes': [[120, 84, 20], [64, 32], [128, 64, 32]],\n",
    "    'dropout': [0.0, 0.2, 0.5],\n",
    "    'num_classes': [num_classes],\n",
    "    'lr': [1e-3, 1e-4],\n",
    "    'l2_lambda': [0.0, 1e-5, 1e-4]\n",
    "}\n",
    "\n",
    "cnn_kan_param_dist = {\n",
    "    'input_channels': [3],\n",
    "    'width': [[8, 4], [16, 8], [32, 16]],\n",
    "    'grid': [5, 10],\n",
    "    'k': [2, 3],\n",
    "    'num_classes': [num_classes],\n",
    "    'seed': [0],\n",
    "    'lr': [1e-3, 1e-4],\n",
    "    'l2_lambda': [0.0, 1e-5, 1e-4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w_gR8hW3Orar",
   "metadata": {
    "id": "w_gR8hW3Orar"
   },
   "outputs": [],
   "source": [
    "# Addestramento CNN+MLP\n",
    "print(\"=== CNN + MLP Results ===\")\n",
    "best_cnn_mlp, model_params_cnn_mlp, train_params_cnn_mlp = random_search_cnn(\n",
    "    lambda **p: CNN_MLP(**p),\n",
    "    cnn_mlp_param_dist,\n",
    "    train_paths,\n",
    "    train_labels,\n",
    "    class_weights=class_weights_dict,\n",
    "    device=device,\n",
    "    n_iter=11\n",
    ")\n",
    "\n",
    "get_cnn_estimator_scores(\"CNN_MLP\", best_cnn_mlp,\n",
    "                        test_paths, test_labels,\n",
    "                        train_paths, train_labels,\n",
    "                        device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bx0-pTEZ7XYD",
   "metadata": {
    "id": "Bx0-pTEZ7XYD"
   },
   "outputs": [],
   "source": [
    "# Addestramento CNN+KAN\n",
    "print(\"\\n=== CNN + KAN Results ===\")\n",
    "best_cnn_kan, model_params_cnn_kan, train_params_cnn_kan = random_search_cnn(\n",
    "    lambda **p: CNN_KAN(**p),\n",
    "    cnn_kan_param_dist,\n",
    "    train_paths,\n",
    "    train_labels,\n",
    "    class_weights=class_weights_dict,\n",
    "    device=device,\n",
    "    n_iter=15\n",
    ")\n",
    "\n",
    "get_cnn_estimator_scores(\"CNN_KAN\", best_cnn_kan,\n",
    "                        test_paths, test_labels,\n",
    "                        train_paths, train_labels,\n",
    "                        device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5uIugxCaMC9R",
   "metadata": {
    "id": "5uIugxCaMC9R"
   },
   "source": [
    "## Confronto Visivo delle Prestazioni dei Modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5vxh_8pW9qkC",
   "metadata": {
    "id": "5vxh_8pW9qkC"
   },
   "outputs": [],
   "source": [
    "def plot_estimator_scores(scores):\n",
    "    # Prepariamo i dati per il plot di Accuracy (Train vs Test)\n",
    "    melted_accuracy = (\n",
    "        scores[['Model', 'Accuracy_Train', 'Accuracy_Test']]\n",
    "        .rename(columns={'Accuracy_Train': 'Train', 'Accuracy_Test': 'Test'})\n",
    "        .melt(id_vars='Model', var_name='Set', value_name='Score')\n",
    "    )\n",
    "\n",
    "    model_order = scores['Model'].tolist()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    fig.tight_layout(pad=4.0)\n",
    "\n",
    "    # --- Plot 1: Accuracy (Train vs Test) ---\n",
    "    axs[0, 0].set_title('Accuracy')\n",
    "    sns.barplot(data=melted_accuracy, x='Score', y='Model', hue='Set', ax=axs[0, 0], order=model_order)\n",
    "    axs[0, 0].set_xlabel('Accuracy Score')\n",
    "    axs[0, 0].legend(loc='lower right', title='Set')\n",
    "    axs[0, 0].set_xlim(0, 1)\n",
    "\n",
    "    # --- Funzione helper per disegnare barh con CI in modo consistente ---\n",
    "    def plot_barh_with_ci(ax, data, metric_col, ci_low_col, ci_high_col, title, model_order):\n",
    "        ax.set_title(title)\n",
    "        # Assicurati che i dati siano ordinati per il plot coerente\n",
    "        data_ordered = data.set_index('Model').loc[model_order].reset_index()\n",
    "\n",
    "        for i, row in data_ordered.iterrows():\n",
    "            # Gestisci i valori NaN per i CI\n",
    "            val = row[metric_col]\n",
    "            if pd.isna(val):\n",
    "                continue # Salta il modello se il valore della metrica è NaN\n",
    "\n",
    "            err_low = [val - row[ci_low_col]] if not pd.isna(row[ci_low_col]) else [0]\n",
    "            err_high = [row[ci_high_col] - val] if not pd.isna(row[ci_high_col]) else [0]\n",
    "\n",
    "            ax.barh(\n",
    "                row['Model'], val,\n",
    "                xerr=[err_low, err_high],\n",
    "                capsize=5,\n",
    "                color=sns.color_palette(\"viridis\")[i % len(sns.color_palette(\"viridis\"))] # Colore coerente\n",
    "            )\n",
    "        ax.set_xlabel(title.split(' ')[0]) # Estrae il nome della metrica dal titolo\n",
    "        ax.invert_yaxis() # Per avere lo stesso ordine dei modelli sull'asse y\n",
    "        ax.set_xlim(0, 1) # Imposta i limiti per le metriche [0, 1]\n",
    "\n",
    "    # --- Plot 2: F1-Weighted Test Score ± CI95% ---\n",
    "    plot_barh_with_ci(axs[0, 1], scores, 'F1_Weighted_Test', 'F1_Weighted_CI_Low', 'F1_Weighted_CI_High',\n",
    "                      'F1-Weighted Test ± CI95%', model_order)\n",
    "\n",
    "    # --- Plot 3: F1-Macro Test Score ± CI95% ---\n",
    "    plot_barh_with_ci(axs[0, 2], scores, 'F1_Macro_Test', 'F1_Macro_CI_Low', 'F1_Macro_CI_High',\n",
    "                      'F1-Macro Test ± CI95%', model_order)\n",
    "\n",
    "    # --- Plot 4: AUC-ROC OVR Weighted Test Score ± CI95% ---\n",
    "    plot_barh_with_ci(axs[1, 0], scores, 'AUC_ROC_OVR_Weighted', 'AUC_ROC_CI_Low', 'AUC_ROC_CI_High',\n",
    "                      'AUC-ROC (OVR Weighted) Test ± CI95%', model_order)\n",
    "\n",
    "    # --- Plot 5: AUC-PR OVR Weighted Test Score ± CI95% ---\n",
    "    plot_barh_with_ci(axs[1, 1], scores, 'AUC_PR_OVR_Weighted', 'AUC_PR_CI_Low', 'AUC_PR_CI_High',\n",
    "                      'AUC-PR (OVR Weighted) Test ± CI95%', model_order)\n",
    "\n",
    "    # --- Plot 6: Model Complexity (Parameter/Node Count) ---\n",
    "    axs[1, 2].set_title('Model Complexity (Parameters/Nodes)', fontsize=12, fontweight='bold')\n",
    "\n",
    "    # Order data by model order for consistency\n",
    "    scores_ordered = scores.set_index('Model').loc[model_order].reset_index()\n",
    "\n",
    "    # Create color palette\n",
    "    colors = sns.color_palette(\"plasma\", len(scores_ordered))\n",
    "\n",
    "    bars = axs[1, 2].barh(scores_ordered['Model'], scores_ordered['Param_Count'], color=colors)\n",
    "    axs[1, 2].set_xlabel('Parameter/Node Count')\n",
    "    axs[1, 2].invert_yaxis()\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for i, (bar, count) in enumerate(zip(bars, scores_ordered['Param_Count'])):\n",
    "        if not pd.isna(count) and count > 0:\n",
    "            axs[1, 2].text(bar.get_width() + max(scores_ordered['Param_Count']) * 0.01,\n",
    "                          bar.get_y() + bar.get_height()/2,\n",
    "                          f'{int(count):,}',\n",
    "                          va='center', fontsize=9)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RTHU3LQ49qkD",
   "metadata": {
    "id": "RTHU3LQ49qkD"
   },
   "outputs": [],
   "source": [
    "estimator_scores_df = pd.DataFrame(\n",
    "    all_scores,\n",
    "    columns = [\n",
    "        'Model', 'Param_Count',\n",
    "        'Accuracy_Train', 'Accuracy_Test',\n",
    "        'F1_Weighted_Train', 'F1_Weighted_Test', 'F1_Weighted_CI_Low', 'F1_Weighted_CI_High',\n",
    "        'F1_Macro_Train', 'F1_Macro_Test', 'F1_Macro_CI_Low', 'F1_Macro_CI_High',\n",
    "        'AUC_ROC_OVR_Weighted', 'AUC_ROC_CI_Low', 'AUC_ROC_CI_High',\n",
    "        'AUC_PR_OVR_Weighted', 'AUC_PR_CI_Low', 'AUC_PR_CI_High'\n",
    "    ]\n",
    ")\n",
    "plot_estimator_scores(estimator_scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EvcGaDcg8Q8R",
   "metadata": {
    "id": "EvcGaDcg8Q8R"
   },
   "source": [
    "## Selezione del Miglior Modello\n",
    "Calcoliamo un punteggio complessivo per ciascun modello basandoci sulle metriche di valutazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B0DEhNMS8M8S",
   "metadata": {
    "id": "B0DEhNMS8M8S"
   },
   "outputs": [],
   "source": [
    "# 1) Define metrics and their optimization direction\n",
    "metrics = {\n",
    "    'Accuracy_Test': 'max',\n",
    "    'F1_Weighted_Test': 'max',\n",
    "    'F1_Macro_Test': 'max',\n",
    "    'AUC_ROC_OVR_Weighted': 'max',\n",
    "    'AUC_PR_OVR_Weighted': 'max'\n",
    "}\n",
    "\n",
    "# 2) Build ranking DataFrame\n",
    "df_ranks = estimator_scores_df.set_index('Model')\n",
    "ranks = pd.DataFrame(index=df_ranks.index)\n",
    "\n",
    "# Calculate ranks for performance metrics\n",
    "for metric, direction in metrics.items():\n",
    "    if direction == 'max':\n",
    "        # Per metriche 'max' (più alto è meglio), rank in ordine decrescente (rank 1 al migliore)\n",
    "        ranks[f\"{metric}_rank\"] = df_ranks[metric].rank(ascending=False, method='average')\n",
    "    elif direction == 'min':\n",
    "        # Per metriche 'min' (più basso è meglio), rank in ordine crescente (rank 1 al migliore)\n",
    "        ranks[f\"{metric}_rank\"] = df_ranks[metric].rank(ascending=True, method='average')\n",
    "\n",
    "# Calculate complexity rank (lower parameter count is better)\n",
    "ranks['Complexity_rank'] = df_ranks['Param_Count'].rank(ascending=True, method='average')\n",
    "\n",
    "# 3) Calculate weighted scores\n",
    "# Performance score (average of performance ranks)\n",
    "performance_cols = [col for col in ranks.columns if col.endswith('_rank') and col != 'Complexity_rank']\n",
    "ranks['performance_score'] = ranks[performance_cols].mean(axis=1)\n",
    "\n",
    "# Method 1: Equal weighting\n",
    "ranks['equal_weight_score'] = ranks['performance_score'] + ranks['Complexity_rank']\n",
    "\n",
    "# Method 2: Complexity heavily weighted (complexity counts 2x)\n",
    "ranks['complexity_weighted_score'] = ranks['performance_score'] + (2 * ranks['Complexity_rank'])\n",
    "\n",
    "# Method 3: Extreme complexity weighting (complexity counts 3x)\n",
    "ranks['extreme_complexity_score'] = ranks['performance_score'] + (3 * ranks['Complexity_rank'])\n",
    "\n",
    "# Method 4: Pareto efficiency approach (performance vs complexity)\n",
    "# Normalize scores to [0,1] for fair comparison\n",
    "performance_norm = (ranks['performance_score'] - ranks['performance_score'].min()) / (ranks['performance_score'].max() - ranks['performance_score'].min())\n",
    "complexity_norm = (ranks['Complexity_rank'] - ranks['Complexity_rank'].min()) / (ranks['Complexity_rank'].max() - ranks['Complexity_rank'].min())\n",
    "ranks['pareto_score'] = 0.4 * performance_norm + 0.6 * complexity_norm  # 60% weight on complexity\n",
    "\n",
    "# Display results for each method\n",
    "methods = {\n",
    "    'Equal Weight (1:1)': 'equal_weight_score',\n",
    "    'Complexity Weighted (1:2)': 'complexity_weighted_score',\n",
    "    'Extreme Complexity (1:3)': 'extreme_complexity_score',\n",
    "    'Pareto Approach (40:60)': 'pareto_score'\n",
    "}\n",
    "\n",
    "results_summary = pd.DataFrame(index=df_ranks.index)\n",
    "results_summary['Performance_Score'] = ranks['performance_score']\n",
    "results_summary['Complexity_Rank'] = ranks['Complexity_rank']\n",
    "results_summary['Param_Count'] = df_ranks['Param_Count']\n",
    "\n",
    "for method_name, score_col in methods.items():\n",
    "    best_model = ranks[score_col].idxmin() if 'pareto' not in score_col else ranks[score_col].idxmin()\n",
    "    best_score = ranks.loc[best_model, score_col]\n",
    "    results_summary[method_name] = ranks[score_col]\n",
    "    print(f\"{method_name:25} -> {best_model:15} (score: {best_score:.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED RANKING TABLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create comprehensive ranking table\n",
    "ranking_display = pd.DataFrame(index=df_ranks.index)\n",
    "ranking_display['Param_Count'] = df_ranks['Param_Count'].astype(int)\n",
    "ranking_display['Avg_Performance'] = ranks['performance_score'].round(2)\n",
    "ranking_display['Complexity_Rank'] = ranks['Complexity_rank'].astype(int)\n",
    "\n",
    "for method_name, score_col in methods.items():\n",
    "    ranking_display[f'{method_name.split()[0]}_Rank'] = ranks[score_col].rank().astype(int)\n",
    "\n",
    "# Sort by complexity-weighted score (our recommended approach)\n",
    "ranking_display_sorted = ranking_display.sort_values('Complexity_Rank')\n",
    "display(ranking_display_sorted)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Our recommended model (complexity weighted approach)\n",
    "recommended_model = ranks['complexity_weighted_score'].idxmin()\n",
    "recommended_score = ranks.loc[recommended_model, 'complexity_weighted_score']\n",
    "recommended_params = df_ranks.loc[recommended_model, 'Param_Count']\n",
    "recommended_f1_score = df_ranks.loc[recommended_model, 'F1_Weighted_Test']\n",
    "\n",
    "print(f\"   RECOMMENDED MODEL: {recommended_model}\")\n",
    "print(f\"   Reason: Best balance between performance and complexity\")\n",
    "print(f\"   Parameters: {int(recommended_params):,}\")\n",
    "print(f\"   F1-Weighted Score: {recommended_f1_score:.4f}\")\n",
    "print(f\"   Complexity-Weighted Rank Score: {recommended_score:.3f}\")\n",
    "\n",
    "# Show top 3 models for comparison\n",
    "print(f\"\\n  TOP 3 MODELS (Complexity-Weighted Ranking):\")\n",
    "top_3 = ranks.sort_values('complexity_weighted_score').head(3)\n",
    "for i, (model, row) in enumerate(top_3.iterrows(), 1):\n",
    "    params = int(df_ranks.loc[model, 'Param_Count'])\n",
    "    current_f1_score = df_ranks.loc[model, 'F1_Weighted_Test']\n",
    "    print(f\"   {i}. {model:15} | Params: {params:>8,} | F1: {current_f1_score:.4f} | Score: {row['complexity_weighted_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EcYln5O9htGZ",
   "metadata": {
    "id": "EcYln5O9htGZ"
   },
   "source": [
    "# Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UMZLPbFDhuWP",
   "metadata": {
    "id": "UMZLPbFDhuWP"
   },
   "outputs": [],
   "source": [
    "## Modified Ablation Study with L1 Norm Pruning on MLP/KAN Components Only\n",
    "\n",
    "class ModifiedPruningAblationStudy:\n",
    "    def __init__(self, device='cpu'):\n",
    "        self.device = device\n",
    "        self.pruning_results = []\n",
    "\n",
    "    def get_model_sparsity(self, model):\n",
    "        \"\"\"Calcola la sparsità delle componenti MLP/KAN (escludendo CNN)\"\"\"\n",
    "        if isinstance(model, CNN_KAN):\n",
    "            # Per CNN_KAN, calcola sparsità solo della componente KAN\n",
    "            try:\n",
    "                kan_model = model.kan\n",
    "                if not hasattr(kan_model, 'width') or len(kan_model.width) < 2:\n",
    "                    return 0.0\n",
    "\n",
    "                # Calcola parametri totali KAN usando count_params esistente\n",
    "                cnn_params = sum(p.numel() for p in model.cnn_features.parameters() if p.requires_grad)\n",
    "                total_params = count_params(kan_model)\n",
    "\n",
    "                # Conta i parametri zero nella componente KAN\n",
    "                zero_params = 0\n",
    "                for i in range(len(kan_model.width) - 1):\n",
    "                    if i < len(kan_model.act_fun):\n",
    "                        layer = kan_model.act_fun[i]\n",
    "                        # Accedi ai coefficienti spline (coef parameter)\n",
    "                        if hasattr(layer, 'coef') and layer.coef is not None:\n",
    "                            zero_params += float(torch.sum(layer.coef == 0))\n",
    "\n",
    "                return zero_params / total_params if total_params > 0 else 0.0\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Error calculating KAN sparsity: {e}\")\n",
    "                return 0.0\n",
    "\n",
    "        elif isinstance(model, CNN_MLP):\n",
    "            # Per CNN_MLP, calcola sparsità solo della componente MLP usando count_params\n",
    "            cnn_params = sum(p.numel() for p in model.cnn_features.parameters() if p.requires_grad)\n",
    "            total_model_params = count_params(model)\n",
    "            total_mlp_params = total_model_params - cnn_params\n",
    "\n",
    "            zero_params = 0\n",
    "            # Analizza solo i layers MLP (non CNN)\n",
    "            for module in model.mlp.modules():\n",
    "                if isinstance(module, torch.nn.Linear):\n",
    "                    if hasattr(module, 'weight'):\n",
    "                        zero_params += float(torch.sum(module.weight == 0))\n",
    "                    if hasattr(module, 'bias') and module.bias is not None:\n",
    "                        zero_params += float(torch.sum(module.bias == 0))\n",
    "\n",
    "            return zero_params / total_mlp_params if total_mlp_params > 0 else 0.0\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    def count_active_parameters(self, model):\n",
    "        \"\"\"Conta i parametri attivi solo nelle componenti MLP/KAN\"\"\"\n",
    "        if isinstance(model, CNN_KAN):\n",
    "            # Conta parametri CNN (sempre attivi)\n",
    "            cnn_params = sum(p.numel() for p in model.cnn_features.parameters() if p.requires_grad)\n",
    "\n",
    "            # Conta parametri attivi KAN\n",
    "            kan_active_params = 0\n",
    "            try:\n",
    "                kan_model = model.kan\n",
    "                for i in range(len(kan_model.width) - 1):\n",
    "                    if i < len(kan_model.act_fun):\n",
    "                        layer = kan_model.act_fun[i]\n",
    "                        if hasattr(layer, 'coef') and layer.coef is not None:\n",
    "                            kan_active_params += float(torch.sum(layer.coef != 0))\n",
    "\n",
    "                return int(cnn_params + kan_active_params)\n",
    "            except:\n",
    "                # Fallback: usa count_params originale\n",
    "                return count_params(model)\n",
    "\n",
    "        elif isinstance(model, CNN_MLP):\n",
    "            # Conta parametri CNN (sempre attivi)\n",
    "            cnn_params = sum(p.numel() for p in model.cnn_features.parameters() if p.requires_grad)\n",
    "\n",
    "            # Conta parametri attivi MLP\n",
    "            mlp_active_params = 0\n",
    "            for module in model.mlp.modules():\n",
    "                if isinstance(module, torch.nn.Linear):\n",
    "                    if hasattr(module, 'weight'):\n",
    "                        mlp_active_params += float(torch.sum(module.weight != 0))\n",
    "                    if hasattr(module, 'bias') and module.bias is not None:\n",
    "                        mlp_active_params += float(torch.sum(module.bias != 0))\n",
    "\n",
    "            return int(cnn_params + mlp_active_params)\n",
    "        else:\n",
    "            return count_params(model)\n",
    "\n",
    "    def apply_l1_pruning_mlp_kan_only(self, model, pruning_ratio):\n",
    "        \"\"\"Applica L1 norm pruning solo alle componenti MLP/KAN\"\"\"\n",
    "        pruned_model = copy.deepcopy(model)\n",
    "\n",
    "        if isinstance(model, CNN_KAN):\n",
    "            # Pruning solo sulla componente KAN\n",
    "            try:\n",
    "                if pruning_ratio == 0.0:\n",
    "                    return pruned_model\n",
    "\n",
    "                kan_model = pruned_model.kan\n",
    "\n",
    "                # Colleziona tutti i parametri KAN per L1 pruning globale\n",
    "                kan_modules_to_prune = []\n",
    "                for i in range(len(kan_model.width) - 1):\n",
    "                    if i < len(kan_model.act_fun):\n",
    "                        layer = kan_model.act_fun[i]\n",
    "                        if hasattr(layer, 'coef') and layer.coef is not None:\n",
    "                            # Crea un modulo temporaneo per il pruning\n",
    "                            temp_module = torch.nn.Linear(1, 1, bias=False)\n",
    "                            temp_module.weight = torch.nn.Parameter(layer.coef.view(-1, 1))\n",
    "                            kan_modules_to_prune.append((temp_module, 'weight'))\n",
    "\n",
    "                if kan_modules_to_prune:\n",
    "                    # Applica L1 pruning globale sui parametri KAN\n",
    "                    prune.global_unstructured(\n",
    "                        kan_modules_to_prune,\n",
    "                        pruning_method=prune.L1Unstructured,\n",
    "                        amount=pruning_ratio,\n",
    "                    )\n",
    "\n",
    "                    # Applica le maschere ai coefficienti originali\n",
    "                    idx = 0\n",
    "                    for i in range(len(kan_model.width) - 1):\n",
    "                        if i < len(kan_model.act_fun):\n",
    "                            layer = kan_model.act_fun[i]\n",
    "                            if hasattr(layer, 'coef') and layer.coef is not None:\n",
    "                                original_shape = layer.coef.shape\n",
    "                                mask = kan_modules_to_prune[idx][0].weight_mask.view(original_shape)\n",
    "                                layer.coef.data = layer.coef.data * mask\n",
    "                                idx += 1\n",
    "\n",
    "                    # Rimuovi le maschere temporanee\n",
    "                    for module, param_name in kan_modules_to_prune:\n",
    "                        prune.remove(module, param_name)\n",
    "\n",
    "                print(f\"  Applied L1 pruning to KAN component with ratio: {pruning_ratio:.3f}\")\n",
    "                return pruned_model\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Error during KAN L1 pruning: {e}\")\n",
    "                return model\n",
    "\n",
    "        elif isinstance(model, CNN_MLP):\n",
    "            # Pruning solo sulla componente MLP\n",
    "            mlp_modules_to_prune = []\n",
    "\n",
    "            # Colleziona tutti i layer Linear dell'MLP\n",
    "            for module in pruned_model.mlp.modules():\n",
    "                if isinstance(module, torch.nn.Linear):\n",
    "                    mlp_modules_to_prune.append((module, 'weight'))\n",
    "                    if hasattr(module, 'bias') and module.bias is not None:\n",
    "                        mlp_modules_to_prune.append((module, 'bias'))\n",
    "\n",
    "            if mlp_modules_to_prune:\n",
    "                # Applica L1 pruning globale solo sui layer MLP\n",
    "                prune.global_unstructured(\n",
    "                    mlp_modules_to_prune,\n",
    "                    pruning_method=prune.L1Unstructured,\n",
    "                    amount=pruning_ratio,\n",
    "                )\n",
    "\n",
    "                # Rendi permanente il pruning\n",
    "                for module, param_name in mlp_modules_to_prune:\n",
    "                    prune.remove(module, param_name)\n",
    "\n",
    "            print(f\"  Applied L1 pruning to MLP component with ratio: {pruning_ratio:.3f}\")\n",
    "            return pruned_model\n",
    "\n",
    "        else:\n",
    "            print(f\"  Model type not supported for component-wise pruning\")\n",
    "            return model\n",
    "\n",
    "    def evaluate_pruned_model(self, model, model_name, test_paths, test_labels,\n",
    "                            train_paths, train_labels, batch_size=32):\n",
    "        \"\"\"Valuta le prestazioni di un modello pruned\"\"\"\n",
    "        model.eval()\n",
    "\n",
    "        # Crea dataset e dataloader\n",
    "        test_dataset = ImageDataset(test_paths, test_labels)\n",
    "        train_dataset = ImageDataset(train_paths, train_labels)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Predizioni su test set\n",
    "        y_pred_test, y_true_test = [], []\n",
    "        y_proba_test = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = model(images)\n",
    "                pred = torch.argmax(outputs, dim=1)\n",
    "                proba = F.softmax(outputs, dim=1)\n",
    "\n",
    "                y_pred_test.extend(pred.cpu().numpy())\n",
    "                y_true_test.extend(labels.cpu().numpy())\n",
    "                y_proba_test.extend(proba.cpu().numpy())\n",
    "\n",
    "        y_proba_test = np.array(y_proba_test)\n",
    "\n",
    "        # Calcola metriche\n",
    "        accuracy = accuracy_score(y_true_test, y_pred_test)\n",
    "        f1_weighted = f1_score(y_true_test, y_pred_test, average='weighted', zero_division=0)\n",
    "        f1_macro = f1_score(y_true_test, y_pred_test, average='macro', zero_division=0)\n",
    "\n",
    "        # AUC metriche (con gestione errori)\n",
    "        try:\n",
    "            auc_roc = roc_auc_score(y_true_test, y_proba_test, multi_class='ovr', average='weighted')\n",
    "            auc_pr = average_precision_score(pd.get_dummies(y_true_test), y_proba_test, average='weighted')\n",
    "        except ValueError:\n",
    "            auc_roc = np.nan\n",
    "            auc_pr = np.nan\n",
    "\n",
    "        return {\n",
    "            'model_name': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_weighted': f1_weighted,\n",
    "            'f1_macro': f1_macro,\n",
    "            'auc_roc': auc_roc,\n",
    "            'auc_pr': auc_pr\n",
    "        }\n",
    "\n",
    "    def run_modified_pruning_study(self, model, model_name, test_paths, test_labels,\n",
    "                                 train_paths, train_labels,\n",
    "                                 pruning_ratios=[0.0, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 0.95]):\n",
    "        \"\"\"\n",
    "        Conduce lo studio di ablazione con L1 pruning solo su MLP/KAN\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== Modified L1 Pruning Study for {model_name} ===\")\n",
    "        print(f\"NOTA: Pruning applicato solo alle componenti MLP/KAN, CNN feature extractor invariato\")\n",
    "\n",
    "        # Parametri originali totali\n",
    "        original_params = count_params(model)\n",
    "\n",
    "        # Parametri solo delle componenti MLP/KAN usando count_params\n",
    "        if isinstance(model, CNN_KAN):\n",
    "            cnn_params = sum(p.numel() for p in model.cnn_features.parameters() if p.requires_grad)\n",
    "            total_model_params = count_params(model)\n",
    "            kan_params = total_model_params - cnn_params\n",
    "            prunable_params = kan_params\n",
    "            component_name = \"KAN\"\n",
    "        elif isinstance(model, CNN_MLP):\n",
    "            cnn_params = sum(p.numel() for p in model.cnn_features.parameters() if p.requires_grad)\n",
    "            total_model_params = count_params(model)\n",
    "            mlp_params = total_model_params - cnn_params\n",
    "            prunable_params = mlp_params\n",
    "            component_name = \"MLP\"\n",
    "        else:\n",
    "            total_model_params = count_params(model)\n",
    "            prunable_params = total_model_params\n",
    "            cnn_params = 0\n",
    "            component_name = \"Unknown\"\n",
    "\n",
    "        print(f\"CNN Parameters (invariati): {cnn_params:,}\")\n",
    "        print(f\"{component_name} Parameters (prunable): {prunable_params:,}\")\n",
    "        print(f\"Total Parameters: {total_model_params:,}\")\n",
    "\n",
    "        for pruning_ratio in pruning_ratios:\n",
    "            print(f\"\\nTesting {component_name} pruning ratio: {pruning_ratio:.4f}\")\n",
    "\n",
    "            if pruning_ratio == 0.0:\n",
    "                # Modello originale\n",
    "                pruned_model = model\n",
    "                sparsity = 0.0\n",
    "                active_params = total_model_params\n",
    "            else:\n",
    "                # Applica L1 pruning solo su MLP/KAN\n",
    "                pruned_model = self.apply_l1_pruning_mlp_kan_only(model, pruning_ratio)\n",
    "                sparsity = self.get_model_sparsity(pruned_model)\n",
    "                active_params = self.count_active_parameters(pruned_model)\n",
    "\n",
    "            # Valuta prestazioni\n",
    "            metrics = self.evaluate_pruned_model(\n",
    "                pruned_model, model_name, test_paths, test_labels,\n",
    "                train_paths, train_labels\n",
    "            )\n",
    "\n",
    "            # Calcola statistiche di compressione\n",
    "            pruned_component_params = active_params - cnn_params\n",
    "            component_compression = prunable_params / pruned_component_params if pruned_component_params > 0 else float('inf')\n",
    "            overall_compression = total_model_params / active_params if active_params > 0 else float('inf')\n",
    "\n",
    "            # Salva risultati\n",
    "            result = {\n",
    "                'model_name': model_name,\n",
    "                'pruning_ratio': pruning_ratio,\n",
    "                'sparsity': sparsity,\n",
    "                'original_params': total_model_params,\n",
    "                'active_params': active_params,\n",
    "                'cnn_params': cnn_params,\n",
    "                'prunable_params': prunable_params,\n",
    "                'pruned_component_params': pruned_component_params,\n",
    "                'component_compression_ratio': component_compression,\n",
    "                'overall_compression_ratio': overall_compression,\n",
    "                'accuracy': metrics['accuracy'],\n",
    "                'f1_weighted': metrics['f1_weighted'],\n",
    "                'f1_macro': metrics['f1_macro'],\n",
    "                'auc_roc': metrics['auc_roc'],\n",
    "                'auc_pr': metrics['auc_pr']\n",
    "            }\n",
    "\n",
    "            self.pruning_results.append(result)\n",
    "\n",
    "            print(f\"  {component_name} Sparsity: {sparsity:.3f}\")\n",
    "            print(f\"  Active params: {active_params:,} / {original_params:,}\")\n",
    "            print(f\"  {component_name} compression: {component_compression:.2f}x\")\n",
    "            print(f\"  Overall compression: {overall_compression:.2f}x\")\n",
    "            print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
    "            print(f\"  F1-Weighted: {metrics['f1_weighted']:.4f}\")\n",
    "\n",
    "    def plot_modified_pruning_results(self, figsize=(18, 12)):\n",
    "        \"\"\"\n",
    "        Visualizza i risultati dello studio di pruning modificato\n",
    "        \"\"\"\n",
    "        if not self.pruning_results:\n",
    "            print(\"No pruning results to plot. Run pruning study first.\")\n",
    "            return\n",
    "\n",
    "        df = pd.DataFrame(self.pruning_results)\n",
    "\n",
    "        fig, axes = plt.subplots(2, 4, figsize=figsize)\n",
    "        fig.suptitle('Modified L1 Pruning Study - MLP/KAN Components Only', fontsize=16, fontweight='bold')\n",
    "\n",
    "        models = df['model_name'].unique()\n",
    "        colors = sns.color_palette(\"husl\", len(models))\n",
    "\n",
    "        # Plot 1: Accuracy vs Pruning Ratio\n",
    "        ax = axes[0, 0]\n",
    "        for i, model in enumerate(models):\n",
    "            model_data = df[df['model_name'] == model]\n",
    "            ax.plot(model_data['pruning_ratio'], model_data['accuracy'],\n",
    "                   marker='o', label=model, color=colors[i], linewidth=2)\n",
    "        ax.set_xlabel('Pruning Ratio (MLP/KAN)')\n",
    "        ax.set_ylabel('Test Accuracy')\n",
    "        ax.set_title('Accuracy vs Component Pruning Ratio')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Plot 2: F1-Weighted vs Pruning Ratio\n",
    "        ax = axes[0, 1]\n",
    "        for i, model in enumerate(models):\n",
    "            model_data = df[df['model_name'] == model]\n",
    "            ax.plot(model_data['pruning_ratio'], model_data['f1_weighted'],\n",
    "                   marker='s', label=model, color=colors[i], linewidth=2)\n",
    "        ax.set_xlabel('Pruning Ratio (MLP/KAN)')\n",
    "        ax.set_ylabel('F1-Weighted Score')\n",
    "        ax.set_title('F1-Weighted vs Component Pruning')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Plot 3: Performance vs Component Compression Ratio\n",
    "        ax = axes[0, 2]\n",
    "        for i, model in enumerate(models):\n",
    "            model_data = df[df['model_name'] == model]\n",
    "            finite_mask = np.isfinite(model_data['component_compression_ratio'])\n",
    "            if finite_mask.any():\n",
    "                ax.scatter(model_data.loc[finite_mask, 'component_compression_ratio'],\n",
    "                          model_data.loc[finite_mask, 'f1_weighted'],\n",
    "                          label=f'{model} (Component)', color=colors[i], s=50, alpha=0.7, marker='o')\n",
    "        ax.set_xlabel('Component Compression Ratio (x)')\n",
    "        ax.set_ylabel('F1-Weighted Score')\n",
    "        ax.set_title('Performance vs Component Compression')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_xscale('log')\n",
    "\n",
    "        # Plot 4: Performance vs Overall Compression Ratio\n",
    "        ax = axes[0, 3]\n",
    "        for i, model in enumerate(models):\n",
    "            model_data = df[df['model_name'] == model]\n",
    "            finite_mask = np.isfinite(model_data['overall_compression_ratio'])\n",
    "            if finite_mask.any():\n",
    "                ax.scatter(model_data.loc[finite_mask, 'overall_compression_ratio'],\n",
    "                          model_data.loc[finite_mask, 'f1_weighted'],\n",
    "                          label=f'{model} (Overall)', color=colors[i], s=50, alpha=0.7, marker='^')\n",
    "        ax.set_xlabel('Overall Compression Ratio (x)')\n",
    "        ax.set_ylabel('F1-Weighted Score')\n",
    "        ax.set_title('Performance vs Overall Compression')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_xscale('log')\n",
    "\n",
    "        # Plot 5: Component Sparsity vs Performance\n",
    "        ax = axes[1, 0]\n",
    "        for i, model in enumerate(models):\n",
    "            model_data = df[df['model_name'] == model]\n",
    "            ax.plot(model_data['sparsity'], model_data['accuracy'],\n",
    "                   marker='d', label=model, color=colors[i], linewidth=2)\n",
    "        ax.set_xlabel('Component Sparsity')\n",
    "        ax.set_ylabel('Test Accuracy')\n",
    "        ax.set_title('Accuracy vs Component Sparsity')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Plot 6: Parameter Distribution\n",
    "        ax = axes[1, 1]\n",
    "        for i, model in enumerate(models):\n",
    "            model_data = df[df['model_name'] == model]\n",
    "            # Mostra la distribuzione dei parametri\n",
    "            ax.bar(np.arange(len(model_data)) + i*0.35, model_data['cnn_params'],\n",
    "                  width=0.35, label=f'{model} CNN', alpha=0.7, color=colors[i])\n",
    "            ax.bar(np.arange(len(model_data)) + i*0.35, model_data['pruned_component_params'],\n",
    "                  width=0.35, bottom=model_data['cnn_params'],\n",
    "                  label=f'{model} MLP/KAN', alpha=0.7, color=colors[i], hatch='///')\n",
    "        ax.set_xlabel('Pruning Level')\n",
    "        ax.set_ylabel('Parameters Count')\n",
    "        ax.set_title('Parameter Distribution (CNN vs MLP/KAN)')\n",
    "        ax.legend()\n",
    "        ax.set_yscale('log')\n",
    "\n",
    "        # Plot 7: Dual Compression Comparison\n",
    "        ax = axes[1, 2]\n",
    "        for i, model in enumerate(models):\n",
    "            model_data = df[df['model_name'] == model]\n",
    "            ax.plot(model_data['pruning_ratio'], model_data['component_compression_ratio'],\n",
    "                   marker='o', label=f'{model} Component', color=colors[i], linestyle='-')\n",
    "            ax.plot(model_data['pruning_ratio'], model_data['overall_compression_ratio'],\n",
    "                   marker='^', label=f'{model} Overall', color=colors[i], linestyle='--')\n",
    "        ax.set_xlabel('Pruning Ratio')\n",
    "        ax.set_ylabel('Compression Ratio (x)')\n",
    "        ax.set_title('Component vs Overall Compression')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_yscale('log')\n",
    "\n",
    "        # Plot 8: Performance Retention\n",
    "        ax = axes[1, 3]\n",
    "        for i, model in enumerate(models):\n",
    "            model_data = df[df['model_name'] == model].sort_values('pruning_ratio')\n",
    "            baseline_f1 = model_data.iloc[0]['f1_weighted']\n",
    "            performance_retention = model_data['f1_weighted'] / baseline_f1\n",
    "            ax.plot(model_data['pruning_ratio'], performance_retention,\n",
    "                   marker='s', label=model, color=colors[i], linewidth=2)\n",
    "        ax.set_xlabel('Pruning Ratio (MLP/KAN)')\n",
    "        ax.set_ylabel('Performance Retention')\n",
    "        ax.set_title('Performance Retention vs Pruning')\n",
    "        ax.axhline(y=0.95, color='red', linestyle='--', alpha=0.7, label='95% threshold')\n",
    "        ax.axhline(y=0.90, color='orange', linestyle='--', alpha=0.7, label='90% threshold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def generate_modified_pruning_report(self):\n",
    "        \"\"\"\n",
    "        Genera un report dettagliato dei risultati del pruning modificato\n",
    "        \"\"\"\n",
    "        if not self.pruning_results:\n",
    "            print(\"No pruning results available. Run pruning study first.\")\n",
    "            return\n",
    "\n",
    "        df = pd.DataFrame(self.pruning_results)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*90)\n",
    "        print(\"MODIFIED L1 PRUNING STUDY - DETAILED REPORT\")\n",
    "        print(\"Pruning applied only to MLP/KAN components, CNN features preserved\")\n",
    "        print(\"=\"*90)\n",
    "\n",
    "        for model_name in df['model_name'].unique():\n",
    "            model_data = df[df['model_name'] == model_name].sort_values('pruning_ratio')\n",
    "\n",
    "            print(f\"\\n{model_name} Results:\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "            # Parametri base\n",
    "            baseline_row = model_data.iloc[0]\n",
    "            baseline_f1 = baseline_row['f1_weighted']\n",
    "            cnn_params = baseline_row['cnn_params']\n",
    "            prunable_params = baseline_row['prunable_params']\n",
    "\n",
    "            component_name = \"KAN\" if \"KAN\" in model_name else \"MLP\"\n",
    "\n",
    "            print(f\"CNN Parameters (preserved): {cnn_params:,}\")\n",
    "            print(f\"{component_name} Parameters (prunable): {prunable_params:,}\")\n",
    "            print(f\"Baseline F1-Weighted: {baseline_f1:.4f}\")\n",
    "\n",
    "            # Trova il punto di degradazione significativa (>5% loss in F1)\n",
    "            degradation_point = None\n",
    "            for _, row in model_data.iterrows():\n",
    "                f1_loss = (baseline_f1 - row['f1_weighted']) / baseline_f1\n",
    "                if f1_loss > 0.05:  # 5% degradation threshold\n",
    "                    degradation_point = row['pruning_ratio']\n",
    "                    break\n",
    "\n",
    "            if degradation_point:\n",
    "                print(f\"Significant degradation starts at: {degradation_point:.1%} {component_name} pruning\")\n",
    "            else:\n",
    "                print(\"No significant degradation observed within tested range\")\n",
    "\n",
    "            # Migliore trade-off per il componente (massima compressione con <2% loss)\n",
    "            best_tradeoff = None\n",
    "            for _, row in model_data.iterrows():\n",
    "                f1_loss = (baseline_f1 - row['f1_weighted']) / baseline_f1\n",
    "                if f1_loss <= 0.02 and row['pruning_ratio'] > 0:\n",
    "                    best_tradeoff = row\n",
    "\n",
    "            if best_tradeoff is not None:\n",
    "                print(f\"\\nBest trade-off point:\")\n",
    "                print(f\"  {component_name} pruning ratio: {best_tradeoff['pruning_ratio']:.1%}\")\n",
    "                print(f\"  {component_name} compression: {best_tradeoff['component_compression_ratio']:.1f}x\")\n",
    "                print(f\"  Overall model compression: {best_tradeoff['overall_compression_ratio']:.1f}x\")\n",
    "                print(f\"  F1-Weighted: {best_tradeoff['f1_weighted']:.4f}\")\n",
    "                print(f\"  Performance loss: {((baseline_f1 - best_tradeoff['f1_weighted'])/baseline_f1)*100:.1f}%\")\n",
    "\n",
    "            # Efficienza del pruning per componente\n",
    "            max_component_compression = model_data['component_compression_ratio'].replace([np.inf, -np.inf], np.nan).max()\n",
    "            if not np.isnan(max_component_compression):\n",
    "                print(f\"\\nMaximum {component_name} compression achieved: {max_component_compression:.1f}x\")\n",
    "\n",
    "            max_overall_compression = model_data['overall_compression_ratio'].replace([np.inf, -np.inf], np.nan).max()\n",
    "            if not np.isnan(max_overall_compression):\n",
    "                print(f\"Maximum overall compression achieved: {max_overall_compression:.1f}x\")\n",
    "\n",
    "        # Tabella comparativa migliorata\n",
    "        print(f\"\\n{'='*90}\")\n",
    "        print(\"COMPARATIVE SUMMARY TABLE - COMPONENT-WISE PRUNING\")\n",
    "        print(\"=\"*90)\n",
    "\n",
    "        summary_rows = []\n",
    "        for model_name in df['model_name'].unique():\n",
    "            model_data = df[df['model_name'] == model_name]\n",
    "            baseline = model_data[model_data['pruning_ratio'] == 0.0].iloc[0]\n",
    "            component_name = \"KAN\" if \"KAN\" in model_name else \"MLP\"\n",
    "\n",
    "            # Trova risultati a diverse soglie di pruning\n",
    "            for target_ratio in [0.3, 0.5, 0.7, 0.9]:\n",
    "                closest = model_data.iloc[(model_data['pruning_ratio'] - target_ratio).abs().argsort()].iloc[0]\n",
    "                if abs(closest['pruning_ratio'] - target_ratio) < 0.1:  # Se abbastanza vicino\n",
    "                    performance_loss = ((baseline['f1_weighted'] - closest['f1_weighted']) / baseline['f1_weighted']) * 100\n",
    "                    summary_rows.append({\n",
    "                        'Model': model_name,\n",
    "                        'Component': component_name,\n",
    "                        'Pruning_Ratio': f\"{target_ratio:.0%}\",\n",
    "                        'Component_Compression': f\"{closest['component_compression_ratio']:.1f}x\",\n",
    "                        'Overall_Compression': f\"{closest['overall_compression_ratio']:.1f}x\",\n",
    "                        'F1_Score': f\"{closest['f1_weighted']:.4f}\",\n",
    "                        'Perf_Loss': f\"{performance_loss:.1f}%\"\n",
    "                    })\n",
    "\n",
    "        if summary_rows:\n",
    "            summary_df = pd.DataFrame(summary_rows)\n",
    "            print(summary_df.to_string(index=False))\n",
    "\n",
    "        # Analisi della preservazione CNN\n",
    "        print(f\"\\n{'='*90}\")\n",
    "        print(\"CNN FEATURE PRESERVATION ANALYSIS\")\n",
    "        print(\"=\"*90)\n",
    "        print(\"This study preserves CNN feature extraction layers while pruning only\")\n",
    "        print(\"the classifier components (MLP/KAN). This approach maintains the model's\")\n",
    "        print(\"ability to extract visual features while reducing computational complexity\")\n",
    "        print(\"in the decision-making layers.\")\n",
    "\n",
    "# Esegui lo studio di ablazione modificato\n",
    "print(\"Iniziando Modified L1 Pruning Study...\")\n",
    "print(\"IMPORTANTE: Pruning applicato solo a MLP/KAN, CNN feature extractor preservato\")\n",
    "print(\"METODOLOGIA:\")\n",
    "print(\"- CNN_MLP: L1 norm pruning solo sui layer Linear dell'MLP\")\n",
    "print(\"- CNN_KAN: L1 norm pruning solo sui coefficienti spline del KAN\")\n",
    "print(\"- CNNFeatureExtractor: Mantenuto intatto per preservare l'estrazione di feature\\n\")\n",
    "\n",
    "# Inizializza la classe per lo studio modificato\n",
    "modified_pruning_study = ModifiedPruningAblationStudy(device=device)\n",
    "\n",
    "# Definisci i livelli di pruning da testare (uguali per entrambi dato che ora usiamo L1 norm)\n",
    "pruning_ratios_uniform = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.98]\n",
    "\n",
    "# Esegui modified pruning study su CNN_MLP\n",
    "if 'best_cnn_mlp' in locals():\n",
    "    print(\"Trovato modello CNN_MLP - Eseguendo L1 pruning study solo su MLP...\")\n",
    "    modified_pruning_study.run_modified_pruning_study(\n",
    "        model=best_cnn_mlp,\n",
    "        model_name='CNN_MLP',\n",
    "        test_paths=test_paths,\n",
    "        test_labels=test_labels,\n",
    "        train_paths=train_paths,\n",
    "        train_labels=train_labels,\n",
    "        pruning_ratios=pruning_ratios_uniform\n",
    "    )\n",
    "\n",
    "# Esegui modified pruning study su CNN_KAN\n",
    "if 'best_cnn_kan' in locals():\n",
    "    print(\"Trovato modello CNN_KAN - Eseguendo L1 pruning study solo su KAN...\")\n",
    "    modified_pruning_study.run_modified_pruning_study(\n",
    "        model=best_cnn_kan,\n",
    "        model_name='CNN_KAN',\n",
    "        test_paths=test_paths,\n",
    "        test_labels=test_labels,\n",
    "        train_paths=train_paths,\n",
    "        train_labels=train_labels,\n",
    "        pruning_ratios=pruning_ratios_uniform\n",
    "    )\n",
    "\n",
    "# Visualizza i risultati\n",
    "modified_pruning_study.plot_modified_pruning_results()\n",
    "\n",
    "# Genera report dettagliato\n",
    "modified_pruning_study.generate_modified_pruning_report()\n",
    "\n",
    "# Salva i risultati in DataFrame per ulteriori analisi\n",
    "pruning_results_df = pd.DataFrame(modified_pruning_study.pruning_results)\n",
    "print(f\"\\nPruning results saved to 'pruning_results_df' with {len(pruning_results_df)} entries\")\n",
    "print(\"\\nPruning results:\")\n",
    "display(pruning_results_df)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "51-VyZP_BGdJ",
    "8rTDr1p2Fl6p",
    "5mfmIBJdA5vB",
    "WFrnOr1MwNvn",
    "5GZyqqRSUQF-",
    "toQbpNSDUSKt",
    "GFSzW1CBUM7y",
    "RAZJ5vZNUJe7",
    "JP9fNayGUFuW",
    "aqmioU9_TzTk",
    "N2VbqTAtT4PW",
    "5uIugxCaMC9R",
    "EvcGaDcg8Q8R",
    "EcYln5O9htGZ"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 249.324246,
   "end_time": "2023-10-20T02:19:51.297702",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-20T02:15:41.973456",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
