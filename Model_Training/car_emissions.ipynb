{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHZsdOd5Oo0n"
      },
      "source": [
        "# Previsioni delle quantità di CO<sub>2</sub> emesse da veicoli"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2-yNkVyOo0p"
      },
      "source": [
        "## Caricamento dei dati\n",
        "Per questo progetto sono stati utilizzati tre dataset differenti. <br>\n",
        "Quindi sono necessarie tre esplorazioni separate dei dati e un'omogeneizzazione dei dati, al fine di ottenere un unico dataset per l'addestramento. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWDykHeoOrVy"
      },
      "outputs": [],
      "source": [
        "!pip install pykan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soWzXv-ZniK1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "from sklearn.model_selection import KFold, ParameterSampler, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, r2_score,\n",
        "    mean_absolute_error, max_error\n",
        ")\n",
        "import sklearn.metrics as metrics\n",
        "from scipy import stats\n",
        "import xgboost as xgb\n",
        "\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import types\n",
        "import seaborn as sns\n",
        "sns.set_theme()\n",
        "from kan import *\n",
        "import random\n",
        "import inspect\n",
        "import json\n",
        "import os.path\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzwpYQI1BPm4"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G0GLTGzK4YK"
      },
      "outputs": [],
      "source": [
        "DATASETS = {\n",
        "    \"car_emissions_spain2022.csv\": \"https://raw.githubusercontent.com/vMxster/Thesis/main/Datasets/car_emissions_spain2022.csv\",\n",
        "    \"car_emissions_canada2014.csv\": \"https://raw.githubusercontent.com/vMxster/Thesis/main/Datasets/car_emissions_canada2014.csv\",\n",
        "    \"car_emissions_uk2013.csv\": \"https://raw.githubusercontent.com/vMxster/Thesis/main/Datasets/car_emissions_uk2013.csv\"\n",
        "}\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"Running in Google Colab. Downloading datasets to the current directory.\")\n",
        "    for filename, dataset_url in DATASETS.items():\n",
        "        if not os.path.exists(filename):\n",
        "            urlretrieve(dataset_url, filename)\n",
        "else:\n",
        "    print(\"Not in Google Colab. Downloading datasets to the 'Datasets' subdirectory.\")\n",
        "    DATASETS_DIR = \"datasets_car_emissions\"\n",
        "    if not os.path.exists(DATASETS_DIR):\n",
        "        os.makedirs(DATASETS_DIR)\n",
        "\n",
        "    for filename, dataset_url in DATASETS.items():\n",
        "        filepath = os.path.join(DATASETS_DIR, filename)\n",
        "        if not os.path.exists(filepath):\n",
        "            urlretrieve(dataset_url, filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V--ZSglqSBnO"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    spain_emissions = pd.read_csv(\"car_emissions_spain2022.csv\")\n",
        "else:\n",
        "    spain_emissions = pd.read_csv(os.path.join(DATASETS_DIR, \"car_emissions_spain2022.csv\"))\n",
        "spain_emissions.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1eqQSaVSBSI"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    canada_emissions = pd.read_csv(\"car_emissions_canada2014.csv\")\n",
        "else:\n",
        "    canada_emissions = pd.read_csv(os.path.join(DATASETS_DIR, \"car_emissions_canada2014.csv\"))\n",
        "canada_emissions.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeugoMUnLhQb"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    uk_emissions = pd.read_csv(\"car_emissions_uk2013.csv\", low_memory=False)\n",
        "else:\n",
        "    uk_emissions = pd.read_csv(os.path.join(DATASETS_DIR, \"car_emissions_uk2013.csv\"), low_memory=False)\n",
        "uk_emissions.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-RXbQ6GTCu3",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# **Esplorazione dei singoli dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTm4gnAdOo0s"
      },
      "source": [
        "## Esplorazione del dataset `uk_emissions`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amXIdtMSOo0s"
      },
      "source": [
        "Il dataset in questione è stato reso fruibile dalla Vehicle Certification Agency (VCA) del Department for Transport britannico, al fine di reperire informazioni inerenti a tutte le vetture nuove in vendita nel Regno Unito nel lasso temporale 2000-2013, e quelle usate immatricolate per la prima volta a partire dal 1° marzo 2001. Il termine *nuova* si riferisce ad una qualsiasi automobile allora disponibile per l'acquisto o il leasing presso un concessionario e che non fosse stata precedentemente registrata. Sempre citando la [documentazione](https://www.gov.uk/co2-and-vehicle-tax-tools), abbiamo che entrambi i veicoli nuovi ed usati possono essere cercati per trovarne i corrispondenti:\n",
        "- Fuel consumption and CO<sub>2</sub> emissions (by make and model)\n",
        "- vehicle tax information (by make, model, registration date and current tax tables)\n",
        "- The cost of tax for all vehicle types\n",
        "\n",
        "Mentre sono disponibili solamente per le macchine nuove le seguenti informazioni:\n",
        "\n",
        "- Tax band, including Band A (exempt from tax)\n",
        "- Fuel economy\n",
        "- Annual fuel running costs\n",
        "- Company car taxation, based on CO<sub>2</sub> bands\n",
        "- Alternative fuel types\n",
        "\n",
        "Potremmo quindi inziare l'analisi del dataset verificando la veridicità di quest'ultimo ragguaglio, ossia controllando che le auto usate assumano valore NaN in corrispondenza delle colonne sopracitate. Sfortunatamente non disponiamo di una variabile che distingua esplicitamente i mezzi nuovi da quelli usati, ma sappiamo che le osservazioni con `date_of_change` (assumendo si riferisca alla data del passaggio di proprietà) diverso da NaN indicano una vettura sicuramente di seconda mano. Quindi sebbene queste rappresentino un sottoinsieme delle usate (mancherebbero quelle usate da un unico proprietario) eseguiamo il test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hwsVe7QOo0s"
      },
      "outputs": [],
      "source": [
        "used_cars_subset = uk_emissions.loc[~uk_emissions[\"date_of_change\"].isna()]\n",
        "columns_supposedly_nan = used_cars_subset[[\"tax_band\",\n",
        "                                           \"standard_12_months\",\n",
        "                                           \"standard_6_months\",\n",
        "                                           \"first_year_12_months\",\n",
        "                                           \"first_year_6_months\",\n",
        "                                           \"fuel_cost_12000_miles\"]]\n",
        "print(columns_supposedly_nan)\n",
        "columns_supposedly_nan.isna().all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqKLU1TeOo0t"
      },
      "source": [
        "Abbiamo appurato l'attendibilità della documentazione riguardo al valore degli attributi supposti NaN nelle auto usate. Ci rimane da esaminare l'assenza di tipi di carburante alternativi (contraddistinti dal valore _Petrol/E85(Flex Fuel)_) nella feature categorica `fuel_type` in tali osservazioni:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0VFqbUzOo0t"
      },
      "outputs": [],
      "source": [
        "used_cars_subset[\"fuel_type\"].isin([\"Petrol / E85 (Flex Fuel)\"]).any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAnzC2DuOo0t"
      },
      "source": [
        "Possiamo ritenerci soddisfatti. Sarebbe ora lecito chiedersi quali siano i marchi automobilistici più popolari nel dataset. Soddisfiamo la nostra curiosità visualizzando i primi dieci in ordine decrescente per numero di comparse in un diagramma a torta, condensando i restanti brand nello spicchio `Others` per motivi di comprensibilità."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0574FPnOo0t"
      },
      "outputs": [],
      "source": [
        "# n.b., i termini \"manufacturer\" e \"brand\" sono utilizzati come sinonimi\n",
        "print(\"[\" + str(uk_emissions[\"manufacturer\"].nunique()) \\\n",
        "      + \"] different manufacturers and [\"               \\\n",
        "      + str(uk_emissions[\"manufacturer\"].count())       \\\n",
        "      + \"] total cars are registered\")\n",
        "manufacturers = uk_emissions[\"manufacturer\"].value_counts()\n",
        "majority_brands = manufacturers[:10]\n",
        "minority_brands = manufacturers[10:]\n",
        "# oppure raggruppando i brand che rappresentano meno del 5%\n",
        "# minority_brands_perc = manufacturers[manufacturers < uk_emissions[\"manufacturer\"].count() * 5 / 100]\n",
        "majority_brands[\"Others\"] = minority_brands.sum()\n",
        "my_explode = np.append(np.zeros(majority_brands.count() - 1), 0.1)\n",
        "majority_brands.plot.pie(title = \"TOP 10 BRANDS\", explode = my_explode, shadow = True, autopct = \"%.2f%%\", figsize=(6, 6));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjUkjt3zOo0t"
      },
      "outputs": [],
      "source": [
        "print(\"OTHERS: 11th to 62nd brand in descending order of popularity:\\n\")\n",
        "percentages = minority_brands.to_numpy() * 100 / uk_emissions[\"manufacturer\"].count()\n",
        "list_of_series = [minority_brands.index.values, minority_brands.values, percentages]\n",
        "minority_df = pd.DataFrame({\"manufacturer\"  : minority_brands.index.values,\n",
        "                            \"# occurrences\" : minority_brands.values,\n",
        "                            \"percentage\"    : percentages})\n",
        "n_brands = uk_emissions[\"manufacturer\"].nunique()\n",
        "minority_df.index = range(11, n_brands + 1)\n",
        "print(minority_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NKYtFfNOo0t"
      },
      "source": [
        "Vediamo ora all'interno di ciascuno dei brand graficati in precedenza quale sia il modello con più occorrenze registrate, servendoci di un istogramma dove ci cureremo di mantenere l'ordine dei produttori secondo le percentuali dianzi calcolate, per una maggiore leggibilità."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhYQNwJ7Oo0u"
      },
      "outputs": [],
      "source": [
        "brands_and_models = uk_emissions[[\"manufacturer\", \"model\"]].copy()\n",
        "brands_and_models = brands_and_models[brands_and_models.manufacturer.isin(majority_brands.index)]\n",
        "print(\"Manufacturers left after screening: [\" + str(brands_and_models.manufacturer.nunique()) + \"]\")\n",
        "majority_brands = majority_brands.drop(\"Others\")\n",
        "brands_and_models = brands_and_models.value_counts([\"manufacturer\", \"model\"]) \\\n",
        "        .reset_index(name = \"count\")                                          \\\n",
        "        .sort_values([\"count\"], ascending = False)                            \\\n",
        "        .drop_duplicates([\"manufacturer\"])                                    \\\n",
        "        .set_index([\"manufacturer\"])                                          \\\n",
        "        .reindex(majority_brands.index) # ri-ordiniamo secondo la classifica dei brand stilata in precedenza\n",
        "brands_and_models[\"car\"] = brands_and_models.index + \"\\n\" + brands_and_models[\"model\"] # concateniamo le stringhe\n",
        "brands_and_models.plot.bar(title = \"MOST POPULAR MODEL FOR EACH OF THE TOP 10 BRANDS \", x = \"car\", y = \"count\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVC8MAZQOo0u"
      },
      "source": [
        "Rimarcherei come un marchio automobilistico possa ripetersi più volte nel dataframe per via degli ipotetici diversi modelli ad esso associati, mentre le molteplici apparizioni di uno stesso modello sono giustificate da una o più differenze di valori in variabili attinenti a specifiche tecniche quali la `engine_capacity` o il `fuel_type`. Potremmo infatti trovare, e.g., una _Ford Courier_ sia a benzina (petrol) con cilindrata (engine_capacity) di 1299 cm<sup>3</sup> che a diesel con cilndrata di 1753 cm<sup>3</sup>. Andiamo ad estrarre qualche insight, facendo attenzione a non assumere che non vi possano essere modelli omonimi tra brand diversi (contando quindi i valori unici in coppia con il relativo brand). Di seguito ignoreremo le le differenze di trasmissione."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i87neem1Oo0u"
      },
      "outputs": [],
      "source": [
        "n_cars = len(uk_emissions[[\"manufacturer\", \"model\", \"description\"]].copy().drop_duplicates())\n",
        "n_models = len(uk_emissions[[\"manufacturer\", \"model\"]].copy().drop_duplicates())\n",
        "n_brands = len(uk_emissions[[\"manufacturer\"]].copy().drop_duplicates())\n",
        "print(\"Average number of engine variants per model: [{:.2f}]\".format(n_cars / n_models))\n",
        "print(\"Average number of models per manufacturer:  [{:.2f}]\".format(n_models / n_brands))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF-ocdbDOo0u"
      },
      "source": [
        "Indaghiamo la relazione tra la classi dello [Standard europeo sulle emissioni inquinanti](https://en.wikipedia.org/wiki/European_emission_standards) e lo sprigionamento di CO delle vetture, per mezzo di un diagramma a scatola e baffi. Osserviamo come le medie dei box siano ordinate. La presenza di outliers, assieme al fatto che uno stesso range di valori di monossido di carbonio possa appartenere a più classi, sono chiari indicatori di come il CO non sia, ragionevolmente, l'unico inquinante tenuto in considerazione per determinare l'appartenenza ad una certa categoria `euro_standard`. Com'è infatti possibile verificare nella pagina a cui rinvia l'hyperlink, THC, NMHC, NH<sub>3</sub> e NO<sub>x</sub> sono alcuni tra gli altri composti valutati."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYJMLeACOo0u"
      },
      "outputs": [],
      "source": [
        "quartiles_first = uk_emissions.boxplot(column = \"co_emissions\", by = \"euro_standard\", showmeans = True);\n",
        "quartiles_first.set_ylabel(\"co_emissions\");\n",
        "quartiles_first.set_title(\"\");\n",
        "plt.ylim(0, 2500);\n",
        "plt.suptitle(\"\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpYhjw_HOo0u"
      },
      "source": [
        "Similmente a quanto fatto sopra andiamo, attraverso un diagramma degli estremi e dei quartili, ad analizzare l'eventuale legame tra `tax_band` e `co2_emissions`. Questa volta notiamo tuttavia come il valore massimo di diossido di carbonio (in g/km) di una certa fascia corrisponda al minimo di quella successiva. In effetti, come riportato nella [guida](https://assets.publishing.service.gov.uk/media/6603f64b13397a0011e419be/v149-rates-of-vehicle-tax-for-cars-motorcycles-light-goods-vehicles-and-private-light-goods-vehicles.pdf) redatta dalla Driver and Vehicle Licensing Agency (DVLA), la CO<sub>2</sub> risulterebbe essere, assieme al `fuel_type`, l'unico elemento considerato nel decretare gli scaglioni di tasse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAPGNmnuOo0v"
      },
      "outputs": [],
      "source": [
        "quartiles_second = uk_emissions.boxplot(column = \"co2\", by = \"tax_band\", showmeans=True, figsize = (10, 16));\n",
        "quartiles_second.set_ylabel(\"co2_emissions\");\n",
        "quartiles_second.set_title(\"\");\n",
        "plt.suptitle(\"\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYbenazWOo0v"
      },
      "source": [
        "Concludiamo l'esplorazione di questo dataset con un grafico a dispersione che leghi l'`engine_capacity` (volume del motore in cm<sup>3</sup>) di ciascuna vettura con i relativi `combined_metric` (consumi in l/100km). Come ci aspettavamo, in linea di massima, al crescere del primo aumenta anche il secondo ed il trend potrebbe, come suggerisce anche l'indice di correlazione di Pearson tra le due colonne, essere approssimato in maniera soddisfacente da una retta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRjBuptIOo0v"
      },
      "outputs": [],
      "source": [
        "uk_emissions.plot.scatter(\"engine_capacity\", \"combined_metric\", s=7, c=\"red\");\n",
        "print(\"Pearson correlation coefficient: [{:.2f}]\".format(uk_emissions[\"engine_capacity\"].corr(uk_emissions[\"combined_metric\"])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4ytHD44Vng_"
      },
      "source": [
        "## Esplorazione del dataset `spain_emissions`\n",
        "### Rimozione delle righe riguardanti veicoli elettrici\n",
        "\n",
        "All'interno del dataset proveniente dal ministero spagnolo sono presenti anche dati riguardanti macchine elettriche. Questa tipologia di dato non è interessante per l'obiettivo del modello, ovvero la quantità di CO<sub>2</sub> emessa.\n",
        "\n",
        "La cella seguente analizza i valori delle righe che hanno `engine_type` \"Eléctricos puros\", estraendo solo le colonne sul minimo e massimo di consumo di litri di carburante e sul minimo e massimo di emissioni di CO<sub>2</sub> per km percorso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dBbENl8YDCh"
      },
      "outputs": [],
      "source": [
        "columns = [\"emissions_min_gCO2_km\", \"emissions_max_gCO2_km\"]\n",
        "spain_emissions.loc[spain_emissions[\"engine_type\"] == \"Eléctricos puros\", columns].isna().all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm9sZvHQZPNm"
      },
      "source": [
        "Come era previdibile, tutti i valori delle emissioni di CO<sub>2</sub> per km nelle righe riguardanti i veicoli elettrici sono mancanti, quindi le rispettive righe possono essere eliminate, poichè non utili per l'addestramento del modello, il cui obiettivo è la previsione dell'emissione di CO<sub>2</sub> per veicoli a motore termico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2z_hiy2aFIx"
      },
      "outputs": [],
      "source": [
        "electric_cars_index = spain_emissions.loc[spain_emissions[\"engine_type\"] == \"Eléctricos puros\"].index\n",
        "spain_emissions = spain_emissions.drop(electric_cars_index)\n",
        "spain_emissions[\"engine_type\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNuiQXUhOo0v"
      },
      "source": [
        "\n",
        "Come si può notare dall'output della cella precedente, la colonna `engine_type` non contiene il valore \"Eléctricos puros\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o55p1KJtOo0w"
      },
      "source": [
        "### Rimozione delle colonne contenenti solo valori `NaN`\n",
        "Nel dataset dell'emissioni di CO<sub>2</sub> proveniente dalla Spagna la colonne `type_hybrid`, `electric_consumption_kwh_100km`, `battery_capacity_kwh ` contengono solo valori `NaN`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08Up5_wkOo0w"
      },
      "outputs": [],
      "source": [
        "all_nan_columns = [\"type_hybrid\", \"electric_consumption_kwh_100km\", \"battery_capacity_kwh\"]\n",
        "spain_emissions[all_nan_columns].isna().values.all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hFP7Xz9Oo0w"
      },
      "outputs": [],
      "source": [
        "spain_emissions = spain_emissions.drop(all_nan_columns, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boGfbrNrOo0w"
      },
      "source": [
        "### Rimozione delle righe senza un valore valido di trasmissione\n",
        "La colonna `transmission` contiene il tipo di trasmissione del veicolo, quindi la modalità di cambio della marcia, se automatica o manuale, che nella colonna sono rispettivamente \"A\" e \"M\". L'output della prossima cella mostra che sono presenti 35 righe con valori di trasmissioni non validi, poichè nel dataset spagnolo \"SC\" sta per \"Sin clasificasion\", ovvero non classificato. Perciò le righe con valori di trasmissione non validi, essendo un numero molto ridotto, verrano eliminate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-g3B3B7kOo0w"
      },
      "outputs": [],
      "source": [
        "spain_emissions[\"transmission\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqnay60eOo0w"
      },
      "outputs": [],
      "source": [
        "valid_transmissions = spain_emissions[\"transmission\"].isin([\"A\", \"M\"])\n",
        "spain_emissions[\"transmission\"] =  spain_emissions.loc[valid_transmissions, \"transmission\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ERHBFS0Oo00"
      },
      "source": [
        "## Esplorazione del dataset `canada_emissions`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57K0_N3aOo00"
      },
      "source": [
        "### Gestione dimensioni motore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ0ZcdDSOo00"
      },
      "source": [
        "All'interno del dataset proveniente dal ministero canadese sono presenti le dimensioni in L (Litri) del motore dei vari veicoli. Decidiamo di trasformarle in cm$^3$ rinominando quindi la feature Engine_cm3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oup7GfbHOo01"
      },
      "outputs": [],
      "source": [
        "canada_emissions = canada_emissions.rename(columns={\"Engine size (L)\": \"Engine_cm3\"})\n",
        "canada_emissions[\"Engine_cm3\"] = canada_emissions[\"Engine_cm3\"] * 1000\n",
        "canada_emissions.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FElap24Oo01"
      },
      "source": [
        "### Trattamento valori mancanti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uutRF7HNOo01"
      },
      "source": [
        "Con la cella seguente verifico se il dataset contiene dei dati mancanti (nan)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLOT__jSOo01"
      },
      "outputs": [],
      "source": [
        "canada_emissions.isna().values.any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ZD6_igOo01"
      },
      "source": [
        "Visto che il risultato è false non c'è alcun valore mancante da gestire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2RKQBd4Oo01"
      },
      "source": [
        "### Grafici\n",
        "Questa sezione contiene alcuni grafici che evidenziano alcuni aspetti del dataframe `canada_emissions`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLJ--h89Oo01"
      },
      "source": [
        "L'istogramma seguente mostra la distribuzione delle emissioni di CO$_2$ nel dataframe canadese. I valori si concentrano principalmente nell'intervallo [150,350]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDj2ZX6iOo01"
      },
      "outputs": [],
      "source": [
        "canada_emissions[\"CO2 emissions (g/km)\"].plot.hist(bins=20,title=\"CO\\u2082 emissions distribution\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-D2LWmvOo01"
      },
      "source": [
        "L'istogramma seguente mostra le dimensioni dei motori dei vari veicoli nel dataframe canadese. I valori si concentrano principalmente nell'intervallo [1500,6000]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuCbWDz4Oo02"
      },
      "outputs": [],
      "source": [
        "canada_emissions[\"Engine_cm3\"].plot.hist(bins=20,title=\"Engine size\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxyB5EAPOo02"
      },
      "source": [
        "Il seguente grafico a torta mostra il numero di cilindri (in percentuale) dei vari veicoli nel dataframe canadese. La maggior parte di essi ha 6 cilindri."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L688ujZAOo02"
      },
      "outputs": [],
      "source": [
        "canada_emissions[\"Cylinders\"].value_counts().plot.pie(title=\"Cylinders number\" , shadow=True, figsize=(6,6), labels=None)\n",
        "labels = [str(cylinder) + \" cylinders\" for cylinder in canada_emissions[\"Cylinders\"].value_counts().index]\n",
        "plt.legend(labels);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRjBn9caOo02"
      },
      "source": [
        "Il seguente grafico a barre mostra i vari tipi di veicoli presenti nel dataset canadese con la relativa frequenza."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucKXZGT0Oo02"
      },
      "outputs": [],
      "source": [
        "canada_vehicle_class = canada_emissions[\"Vehicle class\"].value_counts()\n",
        "plt.bar(canada_vehicle_class.index, canada_vehicle_class.values)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.title(\"Vehicle class\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LQEB6jT7pJo",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# **Omogeneizzazione ed unione dei dati**\n",
        "Avendo reperito tre set di dati ciascuno da una fonte differente, sebbene questi concernano il medesimo dominio e condividano pertanto una considerevole quantità di attributi, potremmo essere erroneamente portati a compiere un troncamento delle colonne, conservando esclusivamente quelle appartenenti all'intersezione delle tre tabelle, tuttavia così facendo andremmo a trascurare il caso-limite in cui le features eliminate dovessero essere le uniche legate, attraverso un relazione non randomica, a quella indagata. Una soluzione più scrupolosa consisterebbe, al contrario, nell'**unione** degli **attributi**, colmando opportunamente le celle vuote formatesi. In effetti, come visto a lezione, i valori NAN possono essere sostituiti, tra gli altri, da (a seconda che le colonne siano di tipo categorico o numerico):\n",
        "- media\n",
        "- moda\n",
        "- mediana\n",
        "\n",
        "Questo ragionamento va ad ogni modo applicato nei limiti del ragionevole: se una variabile dovesse essere presente solamente in uno dei tre dataset, sarebbe piuttosto fuorviante \"inventare\" i 2/3  dei valori da essa assunti (ipotizzando i dataset di egual dimensione). Decidiamo quindi di mantenere le colonne presenti in almeno due dataset su tre. In aggiunta, le stesse variabili in comune, malgrado facciano riferimento allo stesso concetto, si manifestano saltuariamente sotto denominazioni diverse, ed a loro volta i valori da queste assunti potrebbero avere formato dissimile (e.g. capitalizzazione delle lettere nel caso testuale o numero di cifre significative in quello numerico).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL4XLfx-Oo02"
      },
      "source": [
        "## Omogeneizzazione di `uk_emissions`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhT4DqRHOo03"
      },
      "source": [
        "Rimuoviamo le colonne proprie di questo dataset, per moderare la presenza di NaN o dati sostitutivi in quello risultante dall'unione:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQOZ1qaYOo03"
      },
      "outputs": [],
      "source": [
        "uk_emissions = uk_emissions.drop(columns = [\"file\", \"description\", \"euro_standard\", \"tax_band\", \"transmission\", \"urban_metric\",\n",
        "                                            \"extra_urban_metric\", \"urban_imperial\", \"extra_urban_imperial\", \"combined_imperial\",\n",
        "                                            \"noise_level\", \"thc_emissions\", \"co_emissions\", \"nox_emissions\", \"thc_nox_emissions\",\n",
        "                                            \"particulates_emissions\", \"fuel_cost_12000_miles\", \"fuel_cost_6000_miles\", \"standard_12_months\",\n",
        "                                            \"standard_6_months\", \"first_year_12_months\", \"first_year_6_months\", \"date_of_change\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_8OAkEOOo03"
      },
      "source": [
        "Trasformiamo i nomi delle variabili in quelli concordati con gli altri componenti del gruppo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgV8XA7eOo03"
      },
      "outputs": [],
      "source": [
        "uk_emissions.columns = uk_emissions.columns.str.capitalize()\n",
        "uk_emissions.rename(columns = {\"Engine_capacity\" : \"Engine_cm3\",\n",
        "                               \"Combined_metric\" : \"Fuel_consumption\",\n",
        "                               \"Co2\" : \"CO2_Emissions\"}, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4kvU0mLOo03"
      },
      "source": [
        "Ci troviamo ora dinnanzi ad una delle principali complicazioni indotte dall'utilizzo di più dataset. L'obbiettivo sarebbe quello di manipolare i nomi delle vetture in modo tale da garantire la consistenza semantica del dataset finale: non vorremmo che, e.g., le automobili _BMW 3 Series_ e _Bmw Series 3_ siano considerate differenti, perlomeno sugli attributi `Manufacturer`e `Model`, anche per consentire all'algoritmo di machine learning di trarre conclusioni rispetto al modello specifico. Il problema non si pone per variabili numeriche come i consumi o la cilindrata, dove siamo interessati più al range di appartenenza piuttosto che ai valori precisi. Vista la mancanza di un pattern universale e siccome risulterebbe eccessivamente gravoso indagare tutte le ~90'000 osservazioni, ci limiteremo ad uniformare quantomeno un campione di automobili analizzato."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMbZukvvOo03"
      },
      "outputs": [],
      "source": [
        "uk_emissions.dropna(inplace = True)\n",
        "uk_emissions[\"Model\"] = uk_emissions[\"Model\"].replace(\"[\\(\\[].*?[\\)\\]]\", \"\", regex = True)\n",
        "uk_emissions[\"Model\"] = uk_emissions.apply(lambda row : row[\"Model\"].replace(str(row[\"Manufacturer\"]), ''), axis=1)\n",
        "uk_emissions[\"Model\"] = uk_emissions[\"Model\"].str.split(\" \").str[0].str.replace(\",\", \"\")\n",
        "uk_emissions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuiMr8EpOo03"
      },
      "source": [
        "## Omogeneizzazione di `spain_emissions`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6DB5TuYOo03"
      },
      "source": [
        "### Traduzione spagnolo-inglese\n",
        "Il dataset proveniente dalla Spagna contiene due colonne in spagnolo, `engine_type` e `market_segment`. Quindi è necessaria una traduzione dallo spagnolo all'inglese per entrambe le colonne, così da adattarle agli altri due dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABlBvHjAOo04"
      },
      "source": [
        "Definisco una funzione per sostituire i valori di una colonna di un dataframe con dei nuovi valori passati come argomento, in questo caso la rispettiva traduzione in inglese, tramite una funzione di mapping fornita da pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP7tT8pZOo04"
      },
      "outputs": [],
      "source": [
        "def get_column_mapped_values(column, new_values):\n",
        "    mapping = dict(zip(column.unique(), new_values))\n",
        "    return column.map(mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fQGsCaNOo04"
      },
      "outputs": [],
      "source": [
        "#Traduzione della colonna engine_type\n",
        "spanish_engine_type = spain_emissions[\"engine_type\"].unique()\n",
        "english_engine_type = [\"Petrol\", \"Diesel\", \"Plug-in hybrid\", \"Petrol hybrid\", \"Natural gas\",\n",
        "                       \"Diesel Hybrid\", \"Liquefied petroleum gas(LPG)\", \"Fuel cell\", \"Extended range\"]\n",
        "\n",
        "spain_emissions[\"engine_type\"] = get_column_mapped_values(spain_emissions[\"engine_type\"], english_engine_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dsKmIqCOo04"
      },
      "source": [
        "Per la traduzione della colonna `market_segment` si fa riferimento al dataset canadese, il quale contiene una colonna per la classificazione dei veicoli, `Vehicle class`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GeAZDvfOo04"
      },
      "outputs": [],
      "source": [
        "canada_emissions[\"Vehicle class\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxQEEtJMOo04"
      },
      "outputs": [],
      "source": [
        "#Traduzione della colonna market_segment\n",
        "english_market_segment = [\"Minicompact\", \"Compact\", \"Small off-road\", \"Mid-size\", \"Sport utility vehicle\", \"Full-size\",\n",
        "                          \"Mid-size off-road\", \"Full-size off-road\", \"Minivan\", \"Luxury\", \"Minivan\", \"Van: Passenger\"] \\\n",
        "                        + ([\"Van: Cargo\"] * 2) + ([\"Lorry\"] * 7)\n",
        "\n",
        "spain_emissions[\"market_segment\"] = get_column_mapped_values(spain_emissions[\"market_segment\"], english_market_segment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVg-6t3bOo05"
      },
      "source": [
        "### Calcolo medie del consumo di carburante e delle emissioni di CO<sub>2</sub>\n",
        "Sia per il consumo di carburante che per le emissioni di CO<sub>2</sub> sono presenti i valori di minimo, di massimo e la media\n",
        "WLTP (<i>Worldwide harmonized Light vehicles Test Procedure</i>), ovvero le misure ottenute dal test standard a livello mondiale per il controllo delle emissioni e dei consumi dei veicoli.\n",
        "Da questi tre valori ne verrà calcolata la media così da avere una sola colonna per i consumi di carburante e una sola colonna per i consumi di CO<sub>2</sub>, la variabile target da predire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSO4Ibj6Oo05"
      },
      "source": [
        "Prima di poter precedere è necessario controllare che in tutte le righe del dataframe sia presente almeno uno dei tre valori richiesti e che sia diverso da 0, sia per calcolare la media del consumo che delle emissioni.\n",
        "<br>Nella cella successiva si può vedere esattamente in quante righe sono mancanti questi valori necessari."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ugu2rhoOo05"
      },
      "outputs": [],
      "source": [
        "def isnaOrIsZero(dataframe):\n",
        "    return dataframe.isna() | dataframe.eq(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5rxPNZkOo05"
      },
      "outputs": [],
      "source": [
        "consumption_columns = [\"consumption_min_l_100km\", \"consumption_max_l_100km\", \"avg_wltp_consumption_l_100km\"]\n",
        "emissions_columns = [\"emissions_min_gCO2_km\", \"emissions_max_gCO2_km\", \"avg_wltp_emissions_gCO2_km\"]\n",
        "\n",
        "rows_no_consumption = isnaOrIsZero(spain_emissions[consumption_columns]).all(axis=1)\n",
        "number_rows_missing_consumption = rows_no_consumption.sum()\n",
        "print(\"Rows with no consumption_l_100km:\", number_rows_missing_consumption)\n",
        "\n",
        "rows_no_emissions = isnaOrIsZero(spain_emissions[emissions_columns]).all(axis=1)\n",
        "number_rows_missing_emissions = rows_no_emissions.sum()\n",
        "print(\"Rows with no emissions_gCO2_km:\", number_rows_missing_emissions)\n",
        "\n",
        "rows_no_emissions_consumptions = (rows_no_consumption & rows_no_emissions)\n",
        "number_rows_missing_emissions_consumptions = rows_no_emissions_consumptions.sum()\n",
        "print(\"Rows with no emissions_gCO2_km and no consumption_l_km:\", number_rows_missing_emissions_consumptions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYJfR_TgOo06"
      },
      "source": [
        "Come riportato nell'output della cella precedente, ci sono <strong>1560</strong> righe senza alcun valore di consumo di carburante, <strong>1562</strong> righe senza alcun valore di emissioni di CO<sub>2</sub> e <strong>1560</strong> in cui è assente sia il consumo di carburante che le emissioni di CO<sub>2</sub>. <br>\n",
        "Nella cella successiva vengono calcolate le medie di carburante ed emissioni di ciascuna riga e vengono inserite in due nuove colonne `consumption_l_100km`, `emissions_gCO2_km`. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC5T5vQbOo06"
      },
      "outputs": [],
      "source": [
        "mean_consumption = \"consumption_l_100km\"\n",
        "mean_emissions = \"emissions_gCO2_km\"\n",
        "spain_emissions[mean_consumption] = spain_emissions[consumption_columns].mean(axis=1)\n",
        "spain_emissions[mean_emissions] = spain_emissions[emissions_columns].mean(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI9Ura_nOo06"
      },
      "outputs": [],
      "source": [
        "spain_emissions = spain_emissions.drop(consumption_columns + emissions_columns, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjzhUqA-Oo07"
      },
      "source": [
        "Quindi vengono sostituiti i valori mancanti e i valori posti a 0, poichè considerati anch'essi mancanti, siccome le categorie di veicoli considerate dovrebbero presentare dei consumi di carburante e delle emissioni di CO<sub>2</sub> positivi. <br>\n",
        "La cella successiva mostra le categorie di veicoli in cui sono assenti sia i consumi di carburante che le emissioni. Le due categorie con più occorrenze sono i \"Van: Cargo\" e \"Lorry\", due mezzi molto pesanti e con valori differenti rispetto ad altre categorie, quindi sarebbe più corretto riempire i valori assenti o posti a 0, con i mediani delle due rispettive categorie. Mentre per le restanti categorie si può utilizzare direttamente il mediano di tutta la colonna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zcfxz-9_Oo07"
      },
      "outputs": [],
      "source": [
        "most_missing_market_segments = spain_emissions.loc[rows_no_emissions_consumptions, \"market_segment\"].value_counts()[:5]\n",
        "most_missing_market_segments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHsboYlxOo07"
      },
      "source": [
        "Le celle successive evidenziano la necessità di usare, come valore per riempire i valori NaN o posti a 0 delle categorie di veicoli \"Van: Cargo\" e \"Lorry\", i rispettivi mediani, anzichè usare direttamente il mediano di tutta la colonna, vista l'ampia differenza causata dalla presenza di veicoli di diverse dimensioni e consumi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KEcetpDOo07"
      },
      "outputs": [],
      "source": [
        "columns = [mean_consumption, mean_emissions]\n",
        "market_segments = [\"Van: Cargo\", \"Lorry\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaCCoSGROo08"
      },
      "outputs": [],
      "source": [
        "all_median = pd.DataFrame(spain_emissions[columns].median(), columns = [\"All\"]).T\n",
        "van_cargo_lorries = spain_emissions.loc[spain_emissions[\"market_segment\"].isin(market_segments), [\"market_segment\"] + columns]\n",
        "van_cargo_lorries_median = van_cargo_lorries[van_cargo_lorries.ne(0)].groupby(\"market_segment\").median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxZ-kF83Oo08"
      },
      "outputs": [],
      "source": [
        "pd.concat([all_median, van_cargo_lorries_median]).style.set_caption(\"Market segments medians\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RsTV5XbOo08"
      },
      "outputs": [],
      "source": [
        "def fillnaZeroes(market_segment, columns):\n",
        "    vehicles = spain_emissions.loc[spain_emissions[\"market_segment\"] == market_segment, columns].replace(0, np.nan)\n",
        "    vehicles = vehicles.fillna(vehicles.median())\n",
        "    return vehicles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGTEfQkLOo08"
      },
      "outputs": [],
      "source": [
        "for market_segment in market_segments:\n",
        "    spain_emissions.loc[spain_emissions[\"market_segment\"] == market_segment, columns] = fillnaZeroes(market_segment, columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyCFN7nnOo08"
      },
      "outputs": [],
      "source": [
        "other_market_segments = set(spain_emissions[\"market_segment\"].unique()) - set(market_segments)\n",
        "spain_emissions[columns] = spain_emissions[columns].replace(0, np.nan).fillna(spain_emissions[columns].median())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiGs11JcOo08"
      },
      "source": [
        "### Utilizzo di valori espliciti per il tipo di trasmissione\n",
        "Il dataset spagnolo per indicare la tipologia di trasmissione utilizza solamente \"A\" e \"M\". Per adattarlo agli altri dataset e per renderlo più chiaro si è deciso di mappare i rispettivi valori con la versione estesa, ovvero \"Automatic\", \"Manual\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUc6aLrvOo09"
      },
      "outputs": [],
      "source": [
        "renaming_dict = {\"A\": \"Automatic\", \"M\": \"Manual\"}\n",
        "spain_emissions[\"transmission\"] = spain_emissions[\"transmission\"].map(renaming_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvrReqjZOo09"
      },
      "source": [
        "### Inserimento dell'anno del modello del veicolo\n",
        "I dataset canadesi e britannici presentano entrambi una colonna per l'anno del modello(`Model year` in `canada_emissions` e `year` in `uk_emissions`), una feature che può essere importante per la predezioni delle emissioni prodotte. Quindi a partire dagli altri due dataset, viene estratta la colonna dell'anno."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eJTH1qzOo09"
      },
      "source": [
        "Prima di procedere all'inserimento è necessario un adattamento della colonna `model`, poichè nel dataset `spain_emissions` ciascun valore è formato dal nome della casa automobilistica, ovvero il valore della colonna `make`, dal nome effettivo del modello e da altre informazioni aggiuntive sul modello. Quindi, si procede all'eliminazione della casa automobilistica e delle informazioni aggiuntive per adattarlo alla colonna del modello degli altri due dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9gsPU6jOo09"
      },
      "source": [
        "La prossime due celle rimuovono suffissi non presenti negli altri due dataset, eliminando le parole contenute nella variabile locale `useless_words`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XwbVr9fOo09"
      },
      "outputs": [],
      "source": [
        "useless_words = {\"Canarias\", \"Vehículos\", \"Turismos\", \"Comerciales\", \"Nuevo\", \"NUEVO\", \"Turismos\"}\n",
        "# Per rimuovere suffissi fuorvianti, non presenti negli altri dataset, nei nomi delle case automobilistiche\n",
        "def remove_useless_suffix(make):\n",
        "    make_words = make.split()\n",
        "    make_words = set(make_words) - useless_words\n",
        "    return \" \".join(make_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYT-oHzEOo09"
      },
      "outputs": [],
      "source": [
        "spain_emissions[\"make\"] = spain_emissions[\"make\"].apply(remove_useless_suffix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpy4TQoAOo09"
      },
      "source": [
        "Di seguito, l'adattamento del nome del modello eliminando la casa automobilistica e le informazioni aggiuntive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGbZUNDpOo09"
      },
      "outputs": [],
      "source": [
        "# Per rimuovere il nome della casa automobilistica e le informazioni aggiuntive dal nome del modello\n",
        "def remove_manufacturer_and_addional_info(make_model):\n",
        "    make = make_model[\"make\"]\n",
        "    model = make_model[\"model\"]\n",
        "    removedManufacturer = model.replace(make, \"\").split()\n",
        "    model = [word for word in removedManufacturer if word not in useless_words][0]\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dB56vfGOo09"
      },
      "outputs": [],
      "source": [
        "spain_emissions[\"model\"] = spain_emissions[[\"make\", \"model\"]].apply(remove_manufacturer_and_addional_info, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CibwxyfXOo09"
      },
      "source": [
        "Dopo l'adattamento del nome della casa automobilistica e del nome del modello del veicolo, si può procedere all'effettivo inserimento dell'anno in base ai valori dell'anno nei dataset `uk_emissions` e `canada_emissions`. I valori dell'anno che risultano non presenti a seguito del join con `uk_emissions` verranno prelevati dal secondo dataset `canada_emissions`. In caso dei valori risultassero ancora mancanti, tali righe verranno scartate dal dataset, poichè prive di un'informazione rilevante ai fini dell'addestramento del modello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUxEM-dfOo0-"
      },
      "outputs": [],
      "source": [
        "spain_emissions = (\n",
        "    pd.merge(\n",
        "        spain_emissions,\n",
        "        uk_emissions[[\"Manufacturer\", \"Model\", \"Year\"]],\n",
        "        how = \"left\",\n",
        "        left_on = [\"make\", \"model\"],\n",
        "        right_on =  [\"Manufacturer\", \"Model\"]\n",
        "    )\n",
        "    .drop_duplicates()\n",
        ")[list(spain_emissions.columns) + [\"Year\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1s_AZFuOo0-"
      },
      "outputs": [],
      "source": [
        "spain_emissions_year_na = spain_emissions[spain_emissions[\"Year\"].isna()].drop(\"Year\", axis=1)\n",
        "spain_emissions_year_canada = (\n",
        "    pd.merge(\n",
        "        spain_emissions_year_na,\n",
        "        canada_emissions[[\"Make\", \"Model\", \"Model year\"]],\n",
        "        how = \"left\",\n",
        "        left_on = [\"make\", \"model\"],\n",
        "        right_on =  [\"Make\", \"Model\"]\n",
        "    )\n",
        "    .drop_duplicates()\n",
        "    .rename(columns = {\"Model year\": \"Year\"})\n",
        ")[list(spain_emissions.columns)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8qt966rOo0-"
      },
      "source": [
        "La cella a seguire inserisce i valori dell'anno ottenuti dal join con `canada_emissions` al posto dei valori mancanti a seguito del join con `uk_emissions`. Infine, le righe in cui la colonna `year` risulta ancora mancante dopo i due join verranno scartate.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgiwX1ITOo0-"
      },
      "outputs": [],
      "source": [
        "spain_emissions[\"Year\"] = spain_emissions[\"Year\"].fillna(spain_emissions_year_canada[\"Year\"])\n",
        "spain_emissions = spain_emissions.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ4A1fl_Oo0-"
      },
      "source": [
        "### Grafici di `spain_emissions`\n",
        "Questa sezione contiene alcuni grafici che evidenziano alcuni aspetti del dataframe risultante `spain_emissions`.value_countsunique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOBOJftmOo0-"
      },
      "source": [
        "L'istogramma seguente mostra la distribuzione delle emissioni di CO<sub>2</sub> nel dataset spagnolo. I valori si concentrano principalmente nell'intervallo [100, 200]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og-EKmVyOo0-"
      },
      "outputs": [],
      "source": [
        "spain_emissions[\"emissions_gCO2_km\"].plot.hist(bins=20,title=\"CO\\u2082 emissions distribution\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbDfdnCLOo0-"
      },
      "source": [
        "Il seguente grafico mostra la correlazione tra il consumo di carburante e le emissioni di CO<sub>2</sub>. Si evince che esiste una dipendenza tra i due valori, fatta eccezione per alcuni punti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_vTAN-ROo0_"
      },
      "outputs": [],
      "source": [
        "spain_emissions.plot.scatter(\"consumption_l_100km\", \"emissions_gCO2_km\", title=\"Fuel consumption and CO\\u2082 emissions correlation\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYrm_C8JOo0_"
      },
      "source": [
        "Nel grafico a torta è rappresentata la distribuzione delle categorie di veicoli. Una metà è occupata da sole 4 categorie, mentre le altre 8 si spartiscono il restante 50%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAWSXomjOo0_"
      },
      "outputs": [],
      "source": [
        "spain_emissions[\"market_segment\"].value_counts()[:-1].plot.pie(autopct=\"%.2f%%\", title=\"Market segments distribution\", shadow=True, label=\"\", figsize=(10,10));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKPiXXCWOo0_"
      },
      "source": [
        "Nel seguente grafico è mostrata la relazione tra ciascuna categoria di veicoli e le emissioni di CO<sub>2</sub> corrispondenti. Sono presenti molti outlier sia nella parte inferiore che nella parte superiore di ciascun boxplot. Si può notare come i le medie dei valori di veicoli più pesanti e più inquinanti come \"Lorry\", \"Van: Cargo\" e \"Luxury\" siano molto più alti delle medie dei valori corrispondenti ai veicoli più leggeri e meno inquinanti come \"Compact\", \"Minicompact\" e \"Mid-size\". Questa osservazione è vera solo per le medie e i mediani, siccome i valori di ciascun boxplot coprono una buona parte dell'asse y, quindi alcuni veicoli \"Compact\" hanno valori più alti di alcuni \"Lorry\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1KCi4KBOo0_"
      },
      "outputs": [],
      "source": [
        "spain_emissions.boxplot(column=\"emissions_gCO2_km\", by=\"market_segment\", showmeans=True, figsize=(18, 6)).set_title(\"CO\\u2082 emissions grouped by market segment\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-9wNyXxOo0_"
      },
      "source": [
        "Mentre nel grafico successivo vengono mostrati gli stessi valori, ma in relazione alla tipologia di motore. Quasi tutti boxplot hanno i valori di media e mediana che si assestano tra 150 e 200, presentando però anche in questo caso molti outlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOOr3jYzOo0_"
      },
      "outputs": [],
      "source": [
        "spain_emissions.boxplot(column=\"emissions_gCO2_km\", by=\"engine_type\", showmeans=True, figsize=(18, 6)).set_title(\"CO\\u2082 emissions grouped by market engine type\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVXbZ5OdOo0_"
      },
      "source": [
        "### Scelta delle colonne di `spain_emissions` per l'addestramento\n",
        "Questa ultima parte dell'omogeneizzazione di `spain_emissions` seleziona solo le colonne utilizzate nell'addestramento rinominandole e facendo le ultime modifiche ai valori delle colonne, in modo da utilizzare uno standard comune agli altri dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fj6WOV6uOo1A"
      },
      "outputs": [],
      "source": [
        "old_columns = [\"Year\", \"make\", \"model\", \"engine_displacement_cm3\", \"consumption_l_100km\", \"engine_type\", \"emissions_gCO2_km\", \"transmission\"]\n",
        "new_columns = [\"Year\", \"Manufacturer\", \"Model\", \"Engine_cm3\", \"Fuel_consumption\", \"Fuel_type\", \"CO2_Emissions\", \"Transmission_type\"]\n",
        "columns_dict = dict(zip(old_columns, new_columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohb0w1_MOo1A"
      },
      "outputs": [],
      "source": [
        "spain_emissions = spain_emissions[old_columns].rename(columns = columns_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE39I7-pOo1A"
      },
      "source": [
        "Da questo punto in poi, Liquefied Petroleum Gas (LPG) verrà semplicemente sostituito con LPG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn6zr5VKOo1A"
      },
      "outputs": [],
      "source": [
        "spain_emissions[\"Fuel_type\"] = spain_emissions[\"Fuel_type\"].replace(\"Liquefied petroleum gas(LPG)\", \"LPG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo6B5sH0Oo1A",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# **Omogeneizzazione di `canada_emissions`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-DdF007Oo1A"
      },
      "source": [
        "### Gestione tipi di carburante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7NgR5oYOo1A"
      },
      "source": [
        "All'interno del dataset proveniente dal ministero canadese sono presenti dati riguardanti il tipo di carburante (colonna \"Fuel type\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-FGFjBEOo1A"
      },
      "source": [
        "La cella seguente mostra il numero di occorrenze di ogni lettera nella colonna Fuel type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7b55yzbOo1A"
      },
      "outputs": [],
      "source": [
        "canada_emissions[\"Fuel type\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csKs6KN7Oo1B"
      },
      "source": [
        "Riportiamo sotto il significato delle lettere.\n",
        "\n",
        "- `X`: Benzina normale (ha un indice di ottano più basso ed è quindi meno resistente alla detonazione)\n",
        "- `Z`: Benzina premium (ha un indice di ottano più alto e offre una maggiore resistenza alla detonazione. È ideale per motori ad alte prestazioni, che hanno un rapporto di compressione                           più elevato e richiedono un carburante più stabile.)\n",
        "- `D`: Diesel\n",
        "- `E`: Etanolo(E85)\n",
        "- `N`: gas naturale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whn4Y92ZOo1B"
      },
      "source": [
        "Per motivi di compatibilità dei dataset è superfluo mantenere la distinzione tra benzina normale e benzina premium. Compattiamo quindi le due lettere X e Z in una parola unica: Petrol.\n",
        "Inoltre trasformiamo anche E in Etanolo, N in Natural gas e D in Diesel per gli stessi motivi di confrontabilità.\n",
        "Prima di iniziare a modificare il dataframe per poter effettuare tutte le doverose modifiche per renderlo confrontabile con gli altri dataset ne salviamo una copia per evitare di perdere quello originale che potrebbe tornare utile."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DoK-CXcOo1B"
      },
      "outputs": [],
      "source": [
        "canada_emissions_copy = canada_emissions.copy()\n",
        "canada_emissions[\"Fuel type\"] = canada_emissions[\"Fuel type\"].replace({'X': 'Petrol', 'Z': 'Petrol', 'D': 'Diesel', 'N': 'Natural Gas', 'E': 'Ethanol'})\n",
        "canada_emissions[\"Fuel type\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk1tD6EcOo1B"
      },
      "source": [
        "Il seguente grafico a torta mostra la percentuale dei diversi tipi di carburante presi in considerazione. Si può notare che la maggior parte dei dati riguardano veicoli a benzina."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uzOp5-rOo1C"
      },
      "outputs": [],
      "source": [
        "fuel_type_colors = {\"Petrol\": \"yellow\", \"Ethanol\": \"red\", \"Diesel\": \"green\", \"Natural Gas\": \"blue\"}\n",
        "canada_fuel_type = canada_emissions[\"Fuel type\"].value_counts()\n",
        "canada_fuel_type.plot.pie(colors = canada_fuel_type.index.map(fuel_type_colors), shadow=True, figsize=(8,8))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ojd2ODGOo1C"
      },
      "source": [
        "### Eliminazione colonne superflue e rename delle feature importanti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_S4JeUIOo1C"
      },
      "source": [
        "E' inoltre doveroso eliminare le feature City, Highway, Combined che indicano rispettivamente il consumo di carburante: nelle strade di città, nelle autostrade e in entrambe. Eliminiamo inoltre la colonna superflua dell'id, quella del tipo veicolo (Vehicle class) e quella del numero di cilindri (Cylinders) del veicolo, non presente negli altri dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBcVRjH1Oo1C"
      },
      "outputs": [],
      "source": [
        "canada_emissions = canada_emissions.drop([\"_id\",\"Highway (L/100 km)\",\"City (L/100 km)\", \"Combined (L/100 km)\", \"Vehicle class\", \"Cylinders\"], axis=1)\n",
        "canada_emissions.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6lSOuxTOo1D"
      },
      "source": [
        "La celle seguente serve solo per modificare i nomi delle feature in modo che siano compatibili con gli altri dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZotE7BNOo1D"
      },
      "outputs": [],
      "source": [
        "canada_emissions = canada_emissions.rename(columns={\"Model year\": \"Year\",\"Make\": \"Manufacturer\",\"Fuel type\": \"Fuel_type\", \"Transmission\": \"Transmission_type\",\"Combined (mpg)\": \"Fuel_consumption\", \"CO2 emissions (g/km)\": \"CO2_Emissions\"})\n",
        "canada_emissions.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euuorc3ROo1E"
      },
      "source": [
        "### Gestione del tipo di trasmissione"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxLdlUs-Oo1E"
      },
      "source": [
        "Le prossime celle servono per rendere confrontabili con gli altri dataframe i valori riguardanti il tipo di trasmissione. In particolare trasformiamo tutti i valori di trasmissioni inizianti per A in Automatic e tutti quelli inizianti per M in Manual eccetto per i valori AM (che sarebbero automated manual) che verranno eliminati per evitare incomprensioni dato che gli altri dataset distinguono solamente tra cambio manuale e automatico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccW0koy_Oo1E"
      },
      "outputs": [],
      "source": [
        "index_to_drop = canada_emissions[canada_emissions[\"Transmission_type\"].str.startswith(\"AM\")].index\n",
        "canada_emissions = canada_emissions.drop(index_to_drop)\n",
        "canada_emissions[\"Transmission_type\"] = canada_emissions[\"Transmission_type\"].replace({r'^M.*': 'Manual',r'^A.*': 'Automatic' }, regex=True)\n",
        "canada_emissions[\"Transmission_type\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJyJTyyDOo1E"
      },
      "source": [
        "Mostriamo ora i risultati appena ottenuti in un grafico a torta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qECJrp5ROo1E"
      },
      "outputs": [],
      "source": [
        "canada_emissions[\"Transmission_type\"].value_counts().plot.pie(autopct=\"%.2f%%\", shadow=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC1VzvEcOo1E"
      },
      "source": [
        "Come ci aspettavamo grazie allì'uso della funzione `value_counts()` i veicoli a cambio automatico sono la maggioranza."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMpQSOcUOo1E"
      },
      "source": [
        "### Dataset risultante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sde9iVB0Oo1F"
      },
      "source": [
        "Adattamento finale del nome del modello eliminando la casa automobilistica e le informazioni aggiuntive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j49IhPfJOo1F"
      },
      "outputs": [],
      "source": [
        "# Per rimuovere il nome della casa automobilistica e le informazioni aggiuntive dal nome del modello\n",
        "def remove_manufacturer(make_model):\n",
        "    make = make_model[\"Manufacturer\"]\n",
        "    model = make_model[\"Model\"]\n",
        "    removedManufacturer = model.replace(make, \"\").split()\n",
        "    model = [word for word in removedManufacturer if word not in useless_words][0]\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBU_JVlBOo1F"
      },
      "outputs": [],
      "source": [
        "canada_emissions[\"Model\"] = canada_emissions[[\"Manufacturer\", \"Model\"]].apply(remove_manufacturer, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib3byipBOo1F"
      },
      "source": [
        "Mostriamo di seguito il dataframe risultante `canada_emissions`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKd3SXIBOo1F"
      },
      "outputs": [],
      "source": [
        "canada_emissions.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUYVpfq6Oo1F",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Unione dei dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6A1rd8PpOo1F"
      },
      "outputs": [],
      "source": [
        "emissions = pd.concat([spain_emissions, canada_emissions, uk_emissions], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwnzNbBOOo1F"
      },
      "source": [
        "Infine, per i contenuti di tipo stringa come `Manufacturer` e `Model`, sarà necessaria una standardizzazione tra i diversi dataset. Lo standard scelto è la maiuscola per il primo carattere e la minuscola per gli altri caratteri."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf4Z0Fq1Oo1F"
      },
      "outputs": [],
      "source": [
        "capitalize_columns = [\"Manufacturer\", \"Model\"]\n",
        "emissions[capitalize_columns] = emissions[capitalize_columns].apply(lambda col: col.str.capitalize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MjjXftvOo1G"
      },
      "source": [
        "Nella prossima cella, mostriamo una breve descrizione in formato tabellare delle feature numeriche del dataset completo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdG1BNRLOo1G"
      },
      "outputs": [],
      "source": [
        "emissions.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctFIdOgCoXL1"
      },
      "outputs": [],
      "source": [
        "emissions.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl65f1wtOo1G",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Addestramento modelli\n",
        "A seguito dell'esplorazione e dell'omogeneizzazione dei tre dataset, si può procedere all'addestramento dei modelli. I modelli verranno addestrati sulle seguenti feature indipendenti:\n",
        "- `Year`: anno in cui è stato prodotto il veicolo\n",
        "- `Manufacturer`: casa automobilistica che ha prodotto il veicolo\n",
        "- `Model`: nome del modello del veicolo\n",
        "- `Engine_cm3`: volume del motore in cm<sup>3</sup>\n",
        "- `Transmission_type`: tipologia di trasmissione del veicolo, ovvero se il cambio della marcia è automatico o manuale\n",
        "- `Fuel_type`: tipologia di carburante usato nel veicolo. Per esempio può essere benzina, diesel, benzina e ibrida ecc.\n",
        "- `Fuel_consumption`: i litri di carburante consumati dal veicolo ogni 100 km"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBOU8sFDOo1G"
      },
      "source": [
        "La variabile dipendente target dell'addestramento è `CO2_Emissions`, la quantità di CO<sub>2</sub> emessa dal veicolo in grammi per km."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8S8nQpXOo1G"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------- Data Preparation ----------\n",
        "X = emissions.drop(\"CO2_Emissions\", axis=1)\n",
        "y = emissions[\"CO2_Emissions\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create train pool and split into train (22500) + val (2500)\n",
        "train_pool_n = 22500 + 2500\n",
        "X_train_pool = X_train.sample(n=train_pool_n, random_state=42)\n",
        "y_train_pool = y_train.loc[X_train_pool.index]\n",
        "\n",
        "# final train and val sets (keep names X_train / y_train for compatibility)\n",
        "X_train = X_train_pool.sample(n=22500, random_state=42)\n",
        "y_train = y_train_pool.loc[X_train.index]\n",
        "\n",
        "X_val = X_train_pool.drop(X_train.index)\n",
        "y_val = y_train_pool.loc[X_val.index]\n",
        "\n",
        "# Limit the number of samples in test\n",
        "X_test = X_test.sample(n=2500, random_state=42)\n",
        "y_test = y_test.loc[X_test.index]\n",
        "\n",
        "categorical_features = ['Manufacturer', 'Model', 'Fuel_type', 'Transmission_type']\n",
        "numerical_features = ['Year', 'Engine_cm3', 'Fuel_consumption']\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "encoder.fit(X_train[categorical_features])\n",
        "\n",
        "def encode_df(df):\n",
        "    enc = encoder.transform(df[categorical_features])\n",
        "    enc_df = pd.DataFrame(\n",
        "        enc, columns=encoder.get_feature_names_out(categorical_features), index=df.index\n",
        "    )\n",
        "    return pd.concat([df[numerical_features].reset_index(drop=True),\n",
        "                      enc_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "X_train_enc = encode_df(X_train)\n",
        "X_val_enc = encode_df(X_val)\n",
        "X_test_enc = encode_df(X_test)\n",
        "\n",
        "def to_tensor(x_df, y_series):\n",
        "    X_t = torch.tensor(x_df.values, dtype=torch.float32)\n",
        "    y_t = torch.tensor(y_series.values, dtype=torch.float32).unsqueeze(1)\n",
        "    return X_t, y_t\n",
        "\n",
        "X_train_tensor, y_train_tensor = to_tensor(X_train_enc, y_train)\n",
        "X_val_tensor, y_val_tensor = to_tensor(X_val_enc, y_val)\n",
        "X_test_tensor, y_test_tensor = to_tensor(X_test_enc, y_test)\n",
        "\n",
        "# Full training dataset\n",
        "full_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOiglnqCTrf7"
      },
      "source": [
        "## Definizione dei Modelli: MLP e KAN\n",
        "\n",
        "In questo blocco vengono definite due architetture di modelli per regressione:\n",
        "\n",
        "* **`MLP` (Multi-Layer Perceptron)**: una rete neurale feed-forward costruita in modo flessibile a partire da:\n",
        "\n",
        "  * `input_dim`: numero di feature in input;\n",
        "  * `hidden_sizes`: lista con il numero di neuroni per ciascun layer nascosto;\n",
        "  * `dropout`: tasso di dropout per regolarizzare l'addestramento.\n",
        "    Ogni layer nascosto è seguito da un'attivazione `ReLU` e un livello di `Dropout`. L'output è uno scalare, indicato per problemi di regressione.\n",
        "\n",
        "* **`build_kan`**: funzione che restituisce un modello **KAN (Kolmogorov–Arnold Networks)**, una rete neurale basata su un'architettura alternativa ai classici MLP, caratterizzata da:\n",
        "\n",
        "  * una struttura definita tramite la lista `width`,\n",
        "  * griglie di punti (`grid`) e grado del polinomio (`k`) per le interpolazioni,\n",
        "  * seme casuale (`seed`) per la riproducibilità e\n",
        "  * assegnazione del modello al corretto `device` (CPU o GPU).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0883e428-9e7f-4561-bc2d-59e7502dce79"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_sizes, dropout):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        dim = input_dim\n",
        "        for hs in hidden_sizes:\n",
        "            layers.append(nn.Linear(dim, hs))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            dim = hs\n",
        "        layers.append(nn.Linear(dim, 1))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def build_kan(input_dim, width, grid, k, seed=0):\n",
        "    model = KAN(\n",
        "        width=[input_dim] + list(width) + [1],\n",
        "        grid=grid,\n",
        "        k=k,\n",
        "        seed=seed,\n",
        "        device=device\n",
        "    )\n",
        "    model.speed()  # enable efficient mode: disable symbolic branch\n",
        "    return model\n",
        "\n",
        "def build_random_forest(**params):\n",
        "    return RandomForestRegressor(**params)\n",
        "\n",
        "def build_xgboost(**params):\n",
        "    return xgb.XGBRegressor(**params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyNK9pF4Trf7"
      },
      "source": [
        "## Nested Random Search con Early Stopping\n",
        "\n",
        "Questo blocco di codice implementa una procedura completa di **Nested Random Search** per la selezione di iperparametri di modelli di regressione in PyTorch, integrando una strategia di **Early Stopping** per migliorare l'efficienza del training.\n",
        "\n",
        "* La classe `EarlyStopper` consente di interrompere l'addestramento anticipatamente se la loss di validazione non migliora per un numero di epoche definito (`patience`), riducendo il rischio di overfitting e velocizzando l'ottimizzazione.\n",
        "* Le funzioni `train_epoch` ed `eval_loss` gestiscono rispettivamente il training e la valutazione della loss media su un dataset.\n",
        "* La funzione principale `nested_random_search` esegue una **Nested Cross-Validation**, dove:\n",
        "\n",
        "  * Il ciclo esterno (outer loop) valuta le prestazioni generali del modello su diversi split train/test.\n",
        "  * Il ciclo interno (inner loop) esplora combinazioni casuali di iperparametri tramite `ParameterSampler` per ottimizzare la loss di validazione, utilizzando K-Fold CV.\n",
        "* Per ogni fold esterno, viene selezionata la migliore combinazione di iperparametri trovata all’interno, con successivo riaddestramento sul training set esteso e valutazione finale sul test set.\n",
        "\n",
        "Il risultato è una lista di tuple contenenti i migliori parametri di modello, parametri di training e loss finale per ciascun fold esterno, utile per valutare la **robustezza e generalizzazione** del modello selezionato."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b812d5b-9727-4e5f-91b2-f40696c1c52f"
      },
      "outputs": [],
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=3, min_delta=0.0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "\n",
        "    def early_stop(self, val_loss):\n",
        "        # Se la loss migliora (di almeno min_delta), resettiamo il counter\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            # Se la loss non migliora da 'patience' epoche, dobbiamo fermarci\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "def train_epoch(model, loader, optimizer, criterion, l2_lambda=0.0):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for Xb, yb in loader:\n",
        "        Xb, yb = Xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(Xb), yb)\n",
        "\n",
        "        if l2_lambda > 0:\n",
        "            l2_reg = torch.tensor(0.).to(device)\n",
        "            for param in model.parameters():\n",
        "                l2_reg += torch.norm(param, 2)\n",
        "            loss += l2_lambda * l2_reg\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * Xb.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def eval_loss(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            total_loss += criterion(model(Xb), yb).item() * Xb.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def nested_random_search_neural(model_builder, param_dist, dataset,\n",
        "                               outer_folds=5, inner_folds=3, n_iter=10,\n",
        "                               early_patience=10, early_min_delta=1e-4):\n",
        "    \"\"\"\n",
        "    Esegue Nested Random Search con Randomized Search interno per reti neurali (MLP e KAN)\n",
        "    Args:\n",
        "        model_builder: funzione che crea un modello dato model_params\n",
        "        param_dist: dizionario di liste per ogni iperparametro (model_params + training_params)\n",
        "        dataset: TensorDataset per il training\n",
        "        outer_folds, inner_folds: numeri di fold per CV\n",
        "        n_iter: numero di campioni di Random Search\n",
        "        early_patience: numero di epoche di pazienza per Early Stopping\n",
        "        early_min_delta: miglioramento minimo per considerare un progresso\n",
        "    Returns:\n",
        "        lista di tuple (best_model_params, best_training_params, test_loss) per ogni outer fold\n",
        "    \"\"\"\n",
        "    # Chiavi riservate per training\n",
        "    train_keys = ['lr', 'batch_size', 'l2_lambda']\n",
        "    outer_cv = KFold(n_splits=outer_folds, shuffle=True, random_state=42)\n",
        "    results = []\n",
        "\n",
        "    for train_idx, test_idx in outer_cv.split(range(len(dataset))):\n",
        "        inner_train = Subset(dataset, train_idx)\n",
        "        inner_test = Subset(dataset, test_idx)\n",
        "        best_val_loss = float('inf')\n",
        "        best_model_params, best_train_params = None, None\n",
        "\n",
        "        # Random Search interno\n",
        "        for params in ParameterSampler(param_dist, n_iter=n_iter, random_state=42):\n",
        "            # Separa i parametri del modello da quelli di training\n",
        "            model_params = {k: v for k, v in params.items() if k not in train_keys}\n",
        "            train_params = {k: v for k, v in params.items() if k in train_keys}\n",
        "\n",
        "            # Valutazione su inner_folds con Early Stopping\n",
        "            inner_cv = KFold(n_splits=inner_folds, shuffle=True, random_state=42)\n",
        "            val_losses = []\n",
        "            for subtrain_idx, val_idx in inner_cv.split(range(len(inner_train))):\n",
        "                subtrain = Subset(inner_train, subtrain_idx)\n",
        "                valset = Subset(inner_train, val_idx)\n",
        "                train_loader = DataLoader(subtrain, batch_size=train_params['batch_size'], shuffle=True)\n",
        "                val_loader = DataLoader(valset, batch_size=train_params['batch_size'], shuffle=False)\n",
        "\n",
        "                # Costruisci modello\n",
        "                model = model_builder(**model_params)\n",
        "                if hasattr(model, 'speed'):\n",
        "                    model.speed()\n",
        "                model.to(device)\n",
        "                optimizer = optim.Adam(model.parameters(), lr=train_params['lr'], weight_decay=train_params.get('l2_lambda', 0.0))\n",
        "                stopper = EarlyStopper(patience=early_patience, min_delta=early_min_delta)\n",
        "\n",
        "                # Training\n",
        "                for epoch in range(1000):\n",
        "                    train_epoch(model, train_loader, optimizer, nn.MSELoss(), l2_lambda=train_params.get('l2_lambda', 0.0))\n",
        "                    val_loss = eval_loss(model, val_loader, nn.MSELoss())\n",
        "                    if stopper.early_stop(val_loss):\n",
        "                        break\n",
        "\n",
        "                # Loss di validazione\n",
        "                val_losses.append(eval_loss(model, val_loader, nn.MSELoss()))\n",
        "\n",
        "            mean_val = np.mean(val_losses)\n",
        "            if mean_val < best_val_loss:\n",
        "                best_val_loss = mean_val\n",
        "                best_model_params = model_params\n",
        "                best_train_params = train_params\n",
        "\n",
        "        # Riaddestramento con i migliori parametri su tutto il sottoinsieme interno con Early Stopping\n",
        "        full_train_loader = DataLoader(inner_train, batch_size=best_train_params['batch_size'], shuffle=True)\n",
        "        test_loader = DataLoader(inner_test, batch_size=best_train_params['batch_size'], shuffle=False)\n",
        "\n",
        "        final_model = model_builder(**best_model_params)\n",
        "        if hasattr(final_model, 'speed'):\n",
        "            final_model.speed()\n",
        "        final_model.to(device)\n",
        "\n",
        "        optimizer = optim.Adam(final_model.parameters(), lr=best_train_params['lr'], weight_decay=train_params.get('l2_lambda', 0.0))\n",
        "        stopper = EarlyStopper(patience=early_patience, min_delta=early_min_delta)\n",
        "\n",
        "        for epoch in range(1000):\n",
        "            train_epoch(final_model, full_train_loader, optimizer, nn.MSELoss(), l2_lambda=best_train_params.get('l2_lambda', 0.0))\n",
        "            if stopper.early_stop(eval_loss(final_model, full_train_loader, nn.MSELoss())):\n",
        "                break\n",
        "\n",
        "        test_loss = eval_loss(final_model, test_loader, nn.MSELoss())\n",
        "        results.append((best_model_params, best_train_params, test_loss))\n",
        "\n",
        "    return results\n",
        "\n",
        "def nested_random_search_sklearn(model_builder, param_dist, X_data, y_data,\n",
        "                                outer_folds=5, inner_folds=3, n_iter=10):\n",
        "    \"\"\"\n",
        "    Nested Random Search per modelli sklearn e XGBoost\n",
        "    \"\"\"\n",
        "    outer_cv = KFold(n_splits=outer_folds, shuffle=True, random_state=42)\n",
        "    results = []\n",
        "\n",
        "    for train_idx, test_idx in outer_cv.split(X_data):\n",
        "        X_inner_train, X_inner_test = X_data.iloc[train_idx], X_data.iloc[test_idx]\n",
        "        y_inner_train, y_inner_test = y_data.iloc[train_idx], y_data.iloc[test_idx]\n",
        "\n",
        "        best_val_mse = float('inf')\n",
        "        best_params = None\n",
        "\n",
        "        for params in ParameterSampler(param_dist, n_iter=n_iter, random_state=42):\n",
        "            inner_cv = KFold(n_splits=inner_folds, shuffle=True, random_state=42)\n",
        "            val_mses = []\n",
        "\n",
        "            for subtrain_idx, val_idx in inner_cv.split(X_inner_train):\n",
        "                X_subtrain, X_val = X_inner_train.iloc[subtrain_idx], X_inner_train.iloc[val_idx]\n",
        "                y_subtrain, y_val = y_inner_train.iloc[subtrain_idx], y_inner_train.iloc[val_idx]\n",
        "\n",
        "                model = model_builder(**params)\n",
        "                model.fit(X_subtrain, y_subtrain)\n",
        "                val_pred = model.predict(X_val)\n",
        "                val_mse = mean_squared_error(y_val, val_pred)\n",
        "                val_mses.append(val_mse)\n",
        "\n",
        "            mean_val_mse = np.mean(val_mses)\n",
        "            if mean_val_mse < best_val_mse:\n",
        "                best_val_mse = mean_val_mse\n",
        "                best_params = params\n",
        "\n",
        "        # Riaddestramento con los mejores parámetros\n",
        "        final_model = model_builder(**best_params)\n",
        "        final_model.fit(X_inner_train, y_inner_train)\n",
        "        test_pred = final_model.predict(X_inner_test)\n",
        "        test_mse = mean_squared_error(y_inner_test, test_pred)\n",
        "\n",
        "        results.append((best_params, {}, test_mse))\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ0kfSVbTrf8"
      },
      "source": [
        "## Esecuzione del Nested Random Search su MLP e KAN\n",
        "\n",
        "In questa sezione viene eseguita la **ricerca di iperparametri tramite Nested Random Search** per due diverse architetture di modelli:\n",
        "**MLP (Multi-Layer Perceptron)** e **KAN (Kolmogorov–Arnold Networks)**.\n",
        "\n",
        "### Definizione degli spazi degli iperparametri:\n",
        "\n",
        "* `mlp_param_dist`: contiene combinazioni di dimensioni dei layer nascosti, tassi di dropout, learning rate, batch size e numero massimo di epoche per il training del modello MLP.\n",
        "* `kan_param_dist`: definisce i parametri strutturali del modello KAN come larghezza dei layer (`width`), numero di punti griglia (`grid`), grado delle funzioni di base (`k`), e parametri di training.\n",
        "\n",
        "### Esecuzione:\n",
        "\n",
        "* Viene eseguita la funzione `nested_random_search` separatamente per ciascun modello.\n",
        "* I risultati di ogni fold (configurazioni migliori e relativa test loss) vengono stampati a video per permettere un confronto diretto tra le due architetture.\n",
        "\n",
        "Questo confronto sistematico consente di determinare **quale modello e configurazione di iperparametri offra le migliori prestazioni** su un problema di regressione, valutato con Cross-Validation stratificata e early stopping.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr9JgetBBjP6"
      },
      "source": [
        "---\n",
        "\n",
        "**Scelta del numero di iterazioni per RandomizedSearchCV con MLP grid**\n",
        "\n",
        "Il grid ha:\n",
        "\n",
        "- Configurazioni Totali:\n",
        "$$\n",
        "M = 72\n",
        "$$\n",
        "\n",
        "Supponiamo di voler avere una probabilità \\( P = 0.90 \\) di includere almeno una delle migliori \\( k = 10 \\) configurazioni tra queste 72.\n",
        "\n",
        "Usiamo la formula:\n",
        "\n",
        "$$\n",
        "n = \\frac{\\ln(1 - P)}{\\ln\\left(1 - \\frac{k}{M}\\right)}\n",
        "$$\n",
        "\n",
        "Calcoliamo:\n",
        "\n",
        "$$\n",
        "n = \\frac{\\ln(1 - 0.90)}{\\ln\\left(1 - \\frac{10}{72}\\right)} = \\frac{\\ln(0.10)}{\\ln\\left(\\frac{62}{72}\\right)} = \\frac{-2.3026}{\\ln(\\frac{62}{72})} \\approx \\frac{2.3026}{0.1495} \\approx 15.40\n",
        "$$\n",
        "\n",
        "Quindi, con **15 iterazioni** di Randomized Search, si ha circa il 90% di probabilità di testare almeno una delle 10 migliori configurazioni, risparmiando molto rispetto a un Grid Search completo con 72 combinazioni.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCVTDcIRBjP6"
      },
      "source": [
        "**Scelta del numero di iterazioni per RandomizedSearchCV con KAN grid**\n",
        "\n",
        "Il grid ha:\n",
        "\n",
        "- Configurazioni Totali:\n",
        "$$\n",
        "M = 32\n",
        "$$\n",
        "\n",
        "Supponiamo di voler avere una probabilità \\( P = 0.90 \\) di includere almeno una delle migliori \\( k = 10 \\) configurazioni tra queste 32.\n",
        "\n",
        "Usiamo la formula:\n",
        "\n",
        "$$\n",
        "n = \\frac{\\ln(1 - P)}{\\ln\\left(1 - \\frac{k}{M}\\right)}\n",
        "$$\n",
        "\n",
        "Calcoliamo:\n",
        "\n",
        "$$\n",
        "n = \\frac{\\ln(1 - 0.90)}{\\ln\\left(1 - \\frac{10}{32}\\right)} = \\frac{\\ln(0.10)}{\\ln\\left(\\frac{22}{32}\\right)} = \\frac{-2.3026}{\\ln(\\frac{22}{32})} \\approx \\frac{2.3026}{0.3747} \\approx 6.15\n",
        "$$\n",
        "\n",
        "Quindi, con **6 iterazioni** di Randomized Search, si ha circa il 90% di probabilità di testare almeno una delle 10 migliori configurazioni, risparmiando molto rispetto a un Grid Search completo con 32 combinazioni.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoeJAJN1BjP6"
      },
      "source": [
        "**Scelta del numero di iterazioni per RandomizedSearchCV con RandomForest grid**\n",
        "\n",
        "Il grid ha:\n",
        "\n",
        "- Configurazioni Totali:\n",
        "$$\n",
        "M = 144\n",
        "$$\n",
        "\n",
        "Supponiamo di voler avere una probabilità \\( P = 0.90 \\) di includere almeno una delle migliori \\( k = 10 \\) configurazioni tra queste 144.\n",
        "\n",
        "Usiamo la formula:\n",
        "\n",
        "$$\n",
        "n = \\frac{\\ln(1 - P)}{\\ln\\left(1 - \\frac{k}{M}\\right)}\n",
        "$$\n",
        "\n",
        "Calcoliamo:\n",
        "\n",
        "$$\n",
        "n = \\frac{\\ln(1 - 0.90)}{\\ln\\left(1 - \\frac{10}{144}\\right)} = \\frac{\\ln(0.10)}{\\ln\\left(\\frac{134}{144}\\right)} = \\frac{-2.3026}{\\ln(\\frac{134}{144})} \\approx \\frac{2.3026}{0.0720} \\approx 31.98\n",
        "$$\n",
        "\n",
        "Quindi, con **32 iterazioni** di Randomized Search, si ha circa il 90% di probabilità di testare almeno una delle 10 migliori configurazioni, risparmiando molto rispetto a un Grid Search completo con 144 combinazioni.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kyapXgaBjP7"
      },
      "source": [
        "**Scelta del numero di iterazioni per RandomizedSearchCV con XGBoost grid**\n",
        "\n",
        "Il grid ha:\n",
        "\n",
        "- Configurazioni Totali:\n",
        "$$\n",
        "M = 2916\n",
        "$$\n",
        "\n",
        "Supponiamo di voler avere una probabilità \\( P = 0.90 \\) di includere almeno una delle migliori \\( k = 10 \\) configurazioni tra queste 2916.\n",
        "\n",
        "Usiamo la formula:\n",
        "\n",
        "$$\n",
        "n = \\frac{\\ln(1 - P)}{\\ln\\left(1 - \\frac{k}{M}\\right)}\n",
        "$$\n",
        "\n",
        "Calcoliamo:\n",
        "\n",
        "$$\n",
        "n = \\frac{\\ln(1 - 0.90)}{\\ln\\left(1 - \\frac{10}{2916}\\right)} = \\frac{\\ln(0.10)}{\\ln\\left(\\frac{2906}{2916}\\right)} = \\frac{-2.3026}{\\ln(\\frac{2906}{2916})} \\approx \\frac{2.3026}{0.0034} \\approx 677.23\n",
        "$$\n",
        "\n",
        "Quindi, con **677 iterazioni** di Randomized Search, si ha circa il 90% di probabilità di testare almeno una delle 10 migliori configurazioni, risparmiando molto rispetto a un Grid Search completo con 2916 combinazioni.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUxxZlxRBjP7"
      },
      "source": [
        "**Da dove viene la formula per stimare il numero di iterazioni nel Randomized Search?**\n",
        "\n",
        "Per stimare quante iterazioni (`n`) sono necessarie per avere una certa probabilità \\(P\\) di includere almeno una configurazione tra le \\(k\\) migliori (su \\(M\\) totali), usiamo la seguente logica probabilistica:\n",
        "\n",
        "1. Probabilità di *non* pescare una top-\\(k\\) in un singolo tentativo.\n",
        "Se ci sono \\(M\\) configurazioni totali e \\(k\\) di esse sono “quasi ottimali”, la probabilità di *non* sceglierne una buona è:\n",
        "$$\n",
        "1 - \\frac{k}{M}\n",
        "$$\n",
        "\n",
        "2. Probabilità di non pescarne *nessuna* in \\(n\\) tentativi indipendenti\n",
        "$$\n",
        "\\left(1 - \\frac{k}{M} \\right)^n\n",
        "$$\n",
        "\n",
        "3. Probabilità di pescare **almeno una** delle top-\\(k\\)\n",
        "$$\n",
        "P(\\text{≥1 top-}k) = 1 - \\left(1 - \\frac{k}{M} \\right)^n\n",
        "$$\n",
        "\n",
        "4. Ricavare \\(n\\) dalla formula\n",
        "$$\n",
        "1 - \\left(1 - \\frac{k}{M} \\right)^n = P\n",
        "\\quad \\Longrightarrow \\quad\n",
        "n = \\frac{\\ln(1 - P)}{\\ln\\left(1 - \\frac{k}{M} \\right)}\n",
        "$$\n",
        "\n",
        "5. Approssimazione per $$ k \\ll M $$\n",
        "Poiché $$ \\ln(1 - x) \\approx -x $$ per \\(x\\) piccolo:\n",
        "$$\n",
        "n \\approx - \\frac{\\ln(1 - P)}{k/M}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b5b54e2-7eb9-42ad-9cfc-b6b6c4a85c33"
      },
      "outputs": [],
      "source": [
        "input_dim = X_train_tensor.shape[1]\n",
        "mlp_param_dist = {\n",
        "    'input_dim': [input_dim],\n",
        "    'hidden_sizes': [(32,32), (64,64), (128,)],\n",
        "    'dropout': [0.1, 0.2, 0.5],\n",
        "    'lr': [1e-3, 1e-4],\n",
        "    'batch_size': [32],\n",
        "    'l2_lambda': [0.0, 1e-5, 1e-4, 1e-3]\n",
        "}\n",
        "\n",
        "kan_param_dist = {\n",
        "    'input_dim': [input_dim],\n",
        "    'width': [(8,4), (16,8)],\n",
        "    'grid': [5, 10],\n",
        "    'k': [2, 4],\n",
        "    'seed': [0],\n",
        "    'lr': [1e-3],\n",
        "    'batch_size': [32],\n",
        "    'l2_lambda': [0.0, 1e-5, 1e-4, 1e-3]\n",
        "}\n",
        "\n",
        "rf_param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 500],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [10, 20, 30],\n",
        "    'min_samples_leaf': [5, 10],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'random_state': [42]\n",
        "}\n",
        "\n",
        "xgb_param_dist = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5, 6],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
        "    'reg_alpha': [0.5, 1.0, 2.0],\n",
        "    'reg_lambda': [2.0, 5.0, 10.0],\n",
        "    'random_state': [42]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9qtLVNow-4q"
      },
      "outputs": [],
      "source": [
        "# ---------- Run Nested Random Search ----------\n",
        "print(\"=== Nested Random Search Results ===\\n\")\n",
        "\n",
        "print(\"MLP Results:\")\n",
        "mlp_results = nested_random_search_neural(\n",
        "    lambda **p: MLP(**{k: v for k, v in p.items() if k in ['input_dim', 'hidden_sizes', 'dropout']}),\n",
        "    mlp_param_dist,\n",
        "    full_dataset,\n",
        "    n_iter=15)\n",
        "for i, (model_p, train_p, loss) in enumerate(mlp_results):\n",
        "    print(f\"Fold {i+1} - Model: {model_p}, Train: {train_p}, Test Loss: {loss:.4f}\")\n",
        "\n",
        "print(\"\\nKAN Results:\")\n",
        "kan_results = nested_random_search_neural(\n",
        "    lambda **p: build_kan(**{k: v for k, v in p.items() if k in ['input_dim', 'width', 'grid', 'k', 'seed']}),\n",
        "    kan_param_dist,\n",
        "    full_dataset,\n",
        "    n_iter=6)\n",
        "for i, (model_p, train_p, loss) in enumerate(kan_results):\n",
        "    print(f\"Fold {i+1} - Model: {model_p}, Train: {train_p}, Test Loss: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI7N7RMKw7tK"
      },
      "outputs": [],
      "source": [
        "print(\"\\nRandom Forest Results:\")\n",
        "rf_results = nested_random_search_sklearn(build_random_forest, rf_param_dist, X_train_enc, y_train, n_iter=32)\n",
        "for i, (model_p, _, loss) in enumerate(rf_results):\n",
        "    print(f\"Fold {i+1} - Params: {model_p}, Test MSE: {loss:.4f}\")\n",
        "\n",
        "print(\"\\nXGBoost Results:\")\n",
        "xgb_results = nested_random_search_sklearn(build_xgboost, xgb_param_dist, X_train_enc, y_train, n_iter=677)\n",
        "for i, (model_p, _, loss) in enumerate(xgb_results):\n",
        "    print(f\"Fold {i+1} - Params: {model_p}, Test MSE: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUySFSMoTrf9"
      },
      "source": [
        "## Valutazione Finale dei Migliori Modelli: MLP vs KAN\n",
        "\n",
        "Questa sezione si occupa di confrontare i **migliori modelli trovati** durante la ricerca annidata (`nested_random_search`) per le due architetture:\n",
        "\n",
        "* Viene definita la funzione `evaluate_model`, che calcola l'**MSE (Mean Squared Error)** di un modello su un `DataLoader`.\n",
        "* Si identificano i **migliori modelli MLP e KAN**, selezionando quelli con la più bassa *test loss* tra i risultati di cross-validation.\n",
        "* I modelli vengono **riaddestrati** usando gli stessi dati di test (dell'ultimo fold esterno) per analizzare:\n",
        "\n",
        "  * **Train loss** ad ogni epoca;\n",
        "  * **Validation loss** ad ogni epoca.\n",
        "\n",
        "Questa fase è utile per:\n",
        "\n",
        "* Verificare se il modello si **adatta bene** al test set senza overfitting;\n",
        "* Raccogliere dati da **visualizzare graficamente** (es. curva di apprendimento) per analizzare il comportamento delle due architetture nel tempo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7684d29a-0e27-4d0f-bc71-ffb2690d073d"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_neural(model, data_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in data_loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            loss = criterion(model(Xb), yb)\n",
        "            total_loss += loss.item() * Xb.size(0)\n",
        "    return total_loss / len(data_loader.dataset)\n",
        "\n",
        "def count_params(model):\n",
        "    if isinstance(model, MLP):\n",
        "        try:\n",
        "            return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        except Exception:\n",
        "            return 0\n",
        "\n",
        "    elif isinstance(model, KAN):\n",
        "        try:\n",
        "            if not model.width or len(model.width) < 2:\n",
        "                return 0\n",
        "            else:\n",
        "                sum_edge_terms = 0\n",
        "                for i in range(len(model.width) - 1):\n",
        "                    Nl = model.width[i]\n",
        "                    Nl_plus_1 = model.width[i+1]\n",
        "                    if isinstance(Nl, list): Nl = Nl[0]\n",
        "                    if isinstance(Nl_plus_1, list): Nl_plus_1 = Nl_plus_1[0]\n",
        "                    G = model.grid\n",
        "                    k = model.k\n",
        "                    sum_edge_terms += Nl * Nl_plus_1 * (G + k - 1)\n",
        "                return sum_edge_terms\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating KAN parameters: {e}\")\n",
        "            return 0\n",
        "\n",
        "    elif isinstance(model, RandomForestRegressor):\n",
        "        total_nodes = 0\n",
        "        if hasattr(model, 'estimators_'):\n",
        "            for tree in model.estimators_:\n",
        "                if hasattr(tree, 'tree_'):\n",
        "                    total_nodes += tree.tree_.node_count\n",
        "            return total_nodes\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    elif isinstance(model, xgb.XGBRegressor):\n",
        "        total_nodes = 0\n",
        "\n",
        "        try:\n",
        "            booster = model.get_booster()\n",
        "            tree_dumps = booster.get_dump(dump_format='json')\n",
        "\n",
        "            def count_nodes_in_json_tree(node):\n",
        "                count = 1\n",
        "                if 'children' in node:\n",
        "                    for child in node['children']:\n",
        "                        count += count_nodes_in_json_tree(child)\n",
        "                return count\n",
        "\n",
        "            for tree_dump_str in tree_dumps:\n",
        "                tree_json = json.loads(tree_dump_str)\n",
        "                total_nodes += count_nodes_in_json_tree(tree_json)\n",
        "\n",
        "            return total_nodes\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating exact XGBoost complexity: {e}\")\n",
        "            return 0\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def get_predictions_neural(model, data_loader):\n",
        "    model.eval()\n",
        "    preds, true = [], []\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in data_loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            preds.append(model(Xb).cpu().numpy())\n",
        "            true.append(yb.cpu().numpy())\n",
        "    return np.vstack(true), np.vstack(preds)\n",
        "\n",
        "def compute_confidence_interval(data, confidence=0.95):\n",
        "    n = len(data)\n",
        "    if n <= 1:\n",
        "        return np.mean(data) if n > 0 else np.nan, np.nan, np.nan\n",
        "    mean, se = np.mean(data), stats.sem(data)\n",
        "    h = se * stats.t.ppf((1 + confidence) / 2., n-1)\n",
        "    return mean, mean - h, mean + h\n",
        "\n",
        "\n",
        "def compute_metrics_neural(model, data_loader):\n",
        "    y_true, y_pred = get_predictions_neural(model, data_loader)\n",
        "    y_true_flat = y_true.flatten()\n",
        "    y_pred_flat = y_pred.flatten()\n",
        "\n",
        "    mse_scores = (y_true_flat - y_pred_flat)**2\n",
        "    mae_scores = np.abs(y_true_flat - y_pred_flat)\n",
        "    mape_scores = np.abs((y_true_flat - y_pred_flat) / y_true_flat) * 100\n",
        "    mape_scores = mape_scores[np.isfinite(mape_scores) & (y_true_flat != 0)]\n",
        "\n",
        "    mse, mse_ci_lower, mse_ci_upper = compute_confidence_interval(mse_scores)\n",
        "    r2 = r2_score(y_true_flat, y_pred_flat)\n",
        "    mae, mae_ci_lower, mae_ci_upper = compute_confidence_interval(mae_scores)\n",
        "    mape, mape_ci_lower, mape_ci_upper = compute_confidence_interval(mape_scores)\n",
        "    max_err = max_error(y_true_flat, y_pred_flat)\n",
        "    n = len(y_true_flat)\n",
        "    k = data_loader.dataset[0][0].shape[0]\n",
        "    p = count_params(model)\n",
        "    try:\n",
        "        r2 = r2_score(y_true_flat, y_pred_flat)\n",
        "        if n - k - 1 > 0:\n",
        "            r2_adj = 1 - (1 - r2) * (n - 1) / (n - k - 1)\n",
        "        else:\n",
        "             r2_adj = r2\n",
        "    except ZeroDivisionError:\n",
        "        r2_adj = r2\n",
        "    return (mse, mse_ci_lower, mse_ci_upper), r2, r2_adj, (mae, mae_ci_lower, mae_ci_upper), (mape, mape_ci_lower, mape_ci_upper), max_err, p\n",
        "\n",
        "def compute_metrics_sklearn(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_test_np = y_test.values.flatten()\n",
        "    y_pred_np = y_pred.flatten()\n",
        "\n",
        "    min_len = min(len(y_test_np), len(y_pred_np))\n",
        "    y_test_np = y_test_np[:min_len]\n",
        "    y_pred_np = y_pred_np[:min_len]\n",
        "\n",
        "\n",
        "    mse_scores = (y_test_np - y_pred_np)**2\n",
        "    mae_scores = np.abs(y_test_np - y_pred_np)\n",
        "    mape_scores = np.abs((y_test_np - y_pred_np) / y_test_np) * 100\n",
        "    mape_scores = mape_scores[np.isfinite(mape_scores) & (y_test_np != 0)]\n",
        "\n",
        "\n",
        "    mse, mse_ci_lower, mse_ci_upper = compute_confidence_interval(mse_scores)\n",
        "    r2 = r2_score(y_test_np, y_pred_np)\n",
        "    mae, mae_ci_lower, mae_ci_upper = compute_confidence_interval(mae_scores)\n",
        "    mape, mape_ci_lower, mape_ci_upper = compute_confidence_interval(mape_scores)\n",
        "    max_err = max_error(y_test_np, y_pred_np)\n",
        "    n = len(y_test_np)\n",
        "    k = X_test.shape[1]\n",
        "    try:\n",
        "         if n - k - 1 > 0:\n",
        "            r2_adj = 1 - (1 - r2) * (n - 1) / (n - k - 1)\n",
        "         else:\n",
        "             r2_adj = r2\n",
        "    except (ZeroDivisionError, ValueError):\n",
        "        r2_adj = r2\n",
        "    p = count_params(model)\n",
        "    return (mse, mse_ci_lower, mse_ci_upper), r2, r2_adj, (mae, mae_ci_lower, mae_ci_upper), (mape, mape_ci_lower, mape_ci_upper), max_err, p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG_luOrkTrf9"
      },
      "source": [
        "## Valutazione Finale e Confronto tra MLP e KAN\n",
        "\n",
        "In questa sezione, vengono confrontati i modelli MLP (Multi-Layer Perceptron) e KAN (Kolmogorov–Arnold Networks) utilizzando metriche di regressione e visualizzazioni grafiche per analizzare le loro prestazioni.\n",
        "\n",
        "### Metriche di Valutazione\n",
        "\n",
        "Vengono calcolate le seguenti metriche sul test set:\n",
        "\n",
        "* **MSE (Mean Squared Error)**: misura l'errore quadratico medio tra le predizioni del modello e i valori reali. Un valore più basso indica una migliore accuratezza del modello.\n",
        "\n",
        "* **R² (Coefficiente di Determinazione)**: indica la proporzione della varianza nei dati dipendenti che è prevedibile dalle variabili indipendenti. Un valore più alto (fino a 1) suggerisce una migliore capacità predittiva.\n",
        "\n",
        "* **R² Aggiustato**: modifica il R² standard penalizzando l'aggiunta di variabili indipendenti non significative, fornendo una misura più accurata della bontà del modello, specialmente quando si confrontano modelli con un numero diverso di predittori.&#x20;\n",
        "\n",
        "* **Numero di Parametri Addestrabili**: indica la complessità del modello; modelli con un numero inferiore di parametri sono generalmente preferibili se le prestazioni sono comparabili, poiché tendono a generalizzare meglio e sono meno suscettibili all'overfitting.\n",
        "\n",
        "### Visualizzazioni\n",
        "\n",
        "1. **Curve di Loss per Epoca**: grafici che mostrano l'andamento della loss di training e di validazione per ciascun modello nel corso delle epoche, utili per identificare fenomeni di overfitting o underfitting.\n",
        "\n",
        "2. **Confronto tramite Grafici a Barre**:\n",
        "\n",
        "   * **Numero di Parametri**: confronta la complessità dei modelli.\n",
        "   * **R² Aggiustato**: valuta la capacità predittiva tenendo conto della complessità del modello.\n",
        "   * **MSE di Test**: misura l'accuratezza delle predizioni sui dati di test.([Cross Validated][1])\n",
        "\n",
        "Queste analisi forniscono una panoramica completa delle prestazioni e della complessità dei modelli MLP e KAN, facilitando la selezione del modello più adatto per il problema in esame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2dcb82a-9300-43b4-bd27-4e1c1f47edc1"
      },
      "outputs": [],
      "source": [
        "# Selezione dei migliori modelli\n",
        "best_mlp_idx = min(range(len(mlp_results)), key=lambda i: mlp_results[i][2])\n",
        "best_mlp_params, best_mlp_train, _ = mlp_results[best_mlp_idx]\n",
        "\n",
        "best_kan_idx = min(range(len(kan_results)), key=lambda i: kan_results[i][2])\n",
        "best_kan_params, best_kan_train, _ = kan_results[best_kan_idx]\n",
        "\n",
        "best_rf_idx = min(range(len(rf_results)), key=lambda i: rf_results[i][2])\n",
        "best_rf_params, _, _ = rf_results[best_rf_idx]\n",
        "\n",
        "best_xgb_idx = min(range(len(xgb_results)), key=lambda i: xgb_results[i][2])\n",
        "best_xgb_params, _, _ = xgb_results[best_xgb_idx]\n",
        "\n",
        "# Creazione dei modelli finali\n",
        "mlp_model = MLP(**best_mlp_params).to(device)\n",
        "kan_model = build_kan(**best_kan_params).to(device)\n",
        "rf_model = build_random_forest(**best_rf_params)\n",
        "xgb_model = build_xgboost(**best_xgb_params)\n",
        "\n",
        "# Addestramento dei modelli sklearn\n",
        "rf_model.fit(X_train_enc.values, y_train.values)\n",
        "xgb_model.fit(X_train_enc.values, y_train.values)\n",
        "\n",
        "# Preparazione dei loaders per i modelli neurali\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "train_idx, _ = list(outer_cv.split(range(len(full_dataset))))[-1]\n",
        "train_loader = DataLoader(\n",
        "    Subset(full_dataset, train_idx),\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Addestramento dei modelli neurali\n",
        "criterion = nn.MSELoss()\n",
        "stopper_mlp = EarlyStopper(patience=10, min_delta=1e-4)\n",
        "stopper_kan = EarlyStopper(patience=10, min_delta=1e-4)\n",
        "\n",
        "# Training MLP\n",
        "optimizer_mlp = optim.Adam(mlp_model.parameters(), lr=best_mlp_train['lr'])\n",
        "for epoch in range(1000):\n",
        "    train_loss_mlp = train_epoch(mlp_model, train_loader, optimizer_mlp, criterion, l2_lambda=best_mlp_train.get('l2_lambda', 0.0))\n",
        "    val_loss_mlp = eval_loss(mlp_model, test_loader, criterion)\n",
        "    if stopper_mlp.early_stop(val_loss_mlp):\n",
        "        print(f\"MLP Early stopping at epoch {epoch}\")\n",
        "        break\n",
        "\n",
        "# Training KAN\n",
        "optimizer_kan = optim.Adam(kan_model.parameters(), lr=best_kan_train['lr'])\n",
        "for epoch in range(1000):\n",
        "    train_loss_kan = train_epoch(kan_model, train_loader, optimizer_kan, criterion, l2_lambda=best_kan_train.get('l2_lambda', 0.0))\n",
        "    val_loss_kan = eval_loss(kan_model, test_loader, criterion)\n",
        "    if stopper_kan.early_stop(val_loss_kan):\n",
        "        print(f\"KAN Early stopping at epoch {epoch}\")\n",
        "        break\n",
        "\n",
        "# Calcolo delle metriche\n",
        "(mse_mlp_test, mse_mlp_test_ci_lower, mse_mlp_test_ci_upper), r2_mlp_test, r2_adj_mlp_test, (mae_mlp_test, mae_mlp_test_ci_lower, mae_mlp_test_ci_upper), (mape_mlp_test, mape_mlp_test_ci_lower, mape_mlp_test_ci_upper), max_err_mlp_test, params_mlp = compute_metrics_neural(mlp_model, test_loader)\n",
        "(mse_kan_test, mse_kan_test_ci_lower, mse_kan_test_ci_upper), r2_kan_test, r2_adj_kan_test, (mae_kan_test, mae_kan_test_ci_lower, mae_kan_test_ci_upper), (mape_kan_test, mape_kan_test_ci_lower, mape_kan_test_ci_upper), max_err_kan_test, params_kan = compute_metrics_neural(kan_model, test_loader)\n",
        "(mse_rf_test, mse_rf_test_ci_lower, mse_rf_test_ci_upper), r2_rf_test, r2_adj_rf_test, (mae_rf_test, mae_rf_test_ci_lower, mae_rf_test_ci_upper), (mape_rf_test, mape_rf_test_ci_lower, mape_rf_test_ci_upper), max_err_rf_test, params_rf = compute_metrics_sklearn(rf_model, X_test_enc, y_test)\n",
        "(mse_xgb_test, mse_xgb_test_ci_lower, mse_xgb_test_ci_upper), r2_xgb_test, r2_adj_xgb_test, (mae_xgb_test, mae_xgb_test_ci_lower, mae_xgb_test_ci_upper), (mape_xgb_test, mape_xgb_test_ci_lower, mape_xgb_test_ci_upper), max_err_xgb_test, params_xgb = compute_metrics_sklearn(xgb_model, X_test_enc, y_test)\n",
        "\n",
        "(mse_mlp_train, mse_mlp_train_ci_lower, mse_mlp_train_ci_upper), r2_mlp_train, r2_adj_mlp_train, (mae_mlp_train, mae_mlp_train_ci_lower, mae_mlp_train_ci_upper), (mape_mlp_train, mape_mlp_train_ci_lower, mape_mlp_train_ci_upper), max_err_mlp_train, _ = compute_metrics_neural(mlp_model, train_loader)\n",
        "(mse_kan_train, mse_kan_train_ci_lower, mse_kan_train_ci_upper), r2_kan_train, r2_adj_kan_train, (mae_kan_train, mae_kan_train_ci_lower, mae_kan_train_ci_upper), (mape_kan_train, mape_kan_train_ci_lower, mape_kan_train_ci_upper), max_err_kan_train, _ = compute_metrics_neural(kan_model, train_loader)\n",
        "(mse_rf_train, mse_rf_train_ci_lower, mse_rf_train_ci_upper), r2_rf_train, r2_adj_rf_train, (mae_rf_train, mae_rf_train_ci_lower, mae_rf_train_ci_upper), (mape_rf_train, mape_rf_train_ci_lower, mape_rf_train_ci_upper), max_err_rf_train, _ = compute_metrics_sklearn(rf_model, X_train_enc, y_train)\n",
        "(mse_xgb_train, mse_xgb_train_ci_lower, mse_xgb_train_ci_upper), r2_xgb_train, r2_adj_xgb_train, (mae_xgb_train, mae_xgb_train_ci_lower, mae_xgb_train_ci_upper), (mape_xgb_train, mape_xgb_train_ci_lower, mape_xgb_train_ci_upper), max_err_xgb_train, _ = compute_metrics_sklearn(xgb_model, X_train_enc, y_train)\n",
        "\n",
        "# Crea Dataframe dei risultati\n",
        "models = ['MLP', 'KAN', 'Random Forest', 'XGBoost']\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': models,\n",
        "    'MSE_Train': [mse_mlp_train, mse_kan_train, mse_rf_train, mse_xgb_train],\n",
        "    'MSE_Train_CI_Lower': [mse_mlp_train_ci_lower, mse_kan_train_ci_lower, mse_rf_train_ci_lower, mse_xgb_train_ci_lower],\n",
        "    'MSE_Train_CI_Upper': [mse_mlp_train_ci_upper, mse_kan_train_ci_upper, mse_rf_train_ci_upper, mse_xgb_train_ci_upper],\n",
        "    'MSE_Test': [mse_mlp_test, mse_kan_test, mse_rf_test, mse_xgb_test],\n",
        "    'MSE_Test_CI_Lower': [mse_mlp_test_ci_lower, mse_kan_test_ci_lower, mse_rf_test_ci_lower, mse_xgb_test_ci_lower],\n",
        "    'MSE_Test_CI_Upper': [mse_mlp_test_ci_upper, mse_kan_test_ci_upper, mse_rf_test_ci_upper, mse_xgb_test_ci_upper],\n",
        "    'R²_Train': [r2_mlp_train, r2_kan_train, r2_rf_train, r2_xgb_train],\n",
        "    'R²_Test': [r2_mlp_test, r2_kan_test, r2_rf_test, r2_xgb_test],\n",
        "    'R²_Adjusted_Train': [r2_adj_mlp_train, r2_adj_kan_train, r2_adj_rf_train, r2_adj_xgb_train],\n",
        "    'R²_Adjusted_Test': [r2_adj_mlp_test, r2_adj_kan_test, r2_adj_rf_test, r2_adj_xgb_test],\n",
        "    'MAE_Train': [mae_mlp_train, mae_kan_train, mae_rf_train, mae_xgb_train],\n",
        "    'MAE_Train_CI_Lower': [mae_mlp_train_ci_lower, mae_kan_train_ci_lower, mae_rf_train_ci_lower, mae_xgb_train_ci_lower],\n",
        "    'MAE_Train_CI_Upper': [mae_mlp_train_ci_upper, mae_kan_train_ci_upper, mae_rf_train_ci_upper, mae_xgb_train_ci_upper],\n",
        "    'MAE_Test': [mae_mlp_test, mae_kan_test, mae_rf_test, mae_xgb_test],\n",
        "    'MAE_Test_CI_Lower': [mae_mlp_test_ci_lower, mae_kan_test_ci_lower, mae_rf_test_ci_lower, mae_xgb_test_ci_lower],\n",
        "    'MAE_Test_CI_Upper': [mae_mlp_test_ci_upper, mae_kan_test_ci_upper, mae_rf_test_ci_upper, mae_xgb_test_ci_upper],\n",
        "    'MAPE_Train': [mape_mlp_train, mape_kan_train, mape_rf_train, mape_xgb_train],\n",
        "    'MAPE_Train_CI_Lower': [mape_mlp_train_ci_lower, mape_kan_train_ci_lower, mape_rf_train_ci_lower, mape_xgb_train_ci_lower],\n",
        "    'MAPE_Train_CI_Upper': [mape_mlp_train_ci_upper, mape_kan_train_ci_upper, mape_rf_train_ci_upper, mape_xgb_train_ci_upper],\n",
        "    'MAPE_Test': [mape_mlp_test, mape_kan_test, mape_rf_test, mape_xgb_test],\n",
        "    'MAPE_Test_CI_Lower': [mape_mlp_test_ci_lower, mape_kan_test_ci_lower, mape_rf_test_ci_lower, mape_xgb_test_ci_lower],\n",
        "    'MAPE_Test_CI_Upper': [mape_mlp_test_ci_upper, mape_kan_test_ci_upper, mape_rf_test_ci_upper, mape_xgb_test_ci_upper],\n",
        "    'Max_Error_Train': [max_err_mlp_train, max_err_kan_train, max_err_rf_train, max_err_xgb_train],\n",
        "    'Max_Error_Test': [max_err_mlp_test, max_err_kan_test, max_err_rf_test, max_err_xgb_test],\n",
        "    'Parameters': [params_mlp, params_kan, params_rf, params_xgb]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEUlov0nsue3"
      },
      "outputs": [],
      "source": [
        "def plot_regression_scores(scores):\n",
        "    model_order = scores['Model'].tolist()\n",
        "    palette = sns.color_palette(\"viridis\", len(model_order))\n",
        "    model_colors = {model: palette[i] for i, model in enumerate(model_order)}\n",
        "\n",
        "    fig, axs = plt.subplots(2, 3, figsize=(20, 12))\n",
        "    fig.tight_layout(pad=4.0)\n",
        "\n",
        "    # --- Plot 1: R² Score (Train vs Test) ---\n",
        "    axs[0, 0].set_title('R² Score (Train vs Test)')\n",
        "    axs[0, 0].set_xlabel('R² Score')\n",
        "    axs[0, 0].set_ylabel('Model')\n",
        "    axs[0, 0].set_xlim(0, 1)\n",
        "\n",
        "    bar_height = 0.4\n",
        "    for i, model in enumerate(model_order):\n",
        "        row = scores[scores['Model'] == model].iloc[0]\n",
        "        y_pos = i - bar_height/2\n",
        "\n",
        "        axs[0, 0].barh(\n",
        "            y_pos,\n",
        "            row['R²_Train'],\n",
        "            height=bar_height,\n",
        "            color=model_colors[model],\n",
        "            label=f'{model} - Train' if i == 0 else \"\"\n",
        "        )\n",
        "\n",
        "        y_pos = i + bar_height/2\n",
        "        axs[0, 0].barh(\n",
        "            y_pos,\n",
        "            row['R²_Test'],\n",
        "            height=bar_height,\n",
        "            color=model_colors[model],\n",
        "            alpha=0.6,\n",
        "            hatch='//',\n",
        "            label=f'{model} - Test' if i == 0 else \"\"\n",
        "        )\n",
        "\n",
        "    axs[0, 0].legend(handles=[\n",
        "        Patch(color='gray', label='Train'),\n",
        "        Patch(color='gray', label='Test', hatch='//', alpha=0.6)\n",
        "    ], title='Set', loc='lower right')\n",
        "\n",
        "    axs[0, 0].set_yticks(range(len(model_order)))\n",
        "    axs[0, 0].set_yticklabels(model_order)\n",
        "    axs[0, 0].invert_yaxis()\n",
        "\n",
        "    # --- Helper function for consistent bar plots with CIs ---\n",
        "    def plot_barh_with_ci(ax, data, metric_col, ci_low_col, ci_high_col, title, model_order, model_colors, xlim_max=None):\n",
        "        ax.set_title(title)\n",
        "        data_ordered = data.set_index('Model').loc[model_order].reset_index()\n",
        "\n",
        "        for i, row in data_ordered.iterrows():\n",
        "            val = row.get(metric_col)\n",
        "            if pd.isna(val):\n",
        "                continue\n",
        "\n",
        "            err_low = [val - row.get(ci_low_col, val)] if pd.notna(row.get(ci_low_col)) else [0]\n",
        "            err_high = [row.get(ci_high_col, val) - val] if pd.notna(row.get(ci_high_col)) else [0]\n",
        "\n",
        "            ax.barh(\n",
        "                row['Model'],\n",
        "                val,\n",
        "                xerr=[err_low, err_high],\n",
        "                capsize=5,\n",
        "                color=model_colors[row['Model']]\n",
        "            )\n",
        "\n",
        "        ax.set_xlabel(title.split(' ')[0])\n",
        "        ax.invert_yaxis()\n",
        "        if xlim_max:\n",
        "            ax.set_xlim(0, xlim_max)\n",
        "\n",
        "    # --- Plot 2: MSE Test Score ± CI95% ---\n",
        "    plot_barh_with_ci(axs[0, 1], scores, 'MSE_Test', 'MSE_Test_CI_Lower', 'MSE_Test_CI_Upper',\n",
        "                      'MSE Test ± CI95%', model_order, model_colors)\n",
        "\n",
        "    # --- Plot 3: MAE Test Score ± CI95% ---\n",
        "    plot_barh_with_ci(axs[0, 2], scores, 'MAE_Test', 'MAE_Test_CI_Lower', 'MAE_Test_CI_Upper',\n",
        "                      'MAE Test ± CI95%', model_order, model_colors)\n",
        "\n",
        "    # --- Plot 4: MAPE Test Score ± CI95% ---\n",
        "    plot_barh_with_ci(axs[1, 0], scores, 'MAPE_Test', 'MAPE_Test_CI_Lower', 'MAPE_Test_CI_Upper',\n",
        "                      'MAPE (%) Test ± CI95%', model_order, model_colors)\n",
        "\n",
        "    # --- Plot 5: R² Adjusted Test Score ---\n",
        "    axs[1, 1].set_title('R² Adjusted Test')\n",
        "    scores_ordered = scores.set_index('Model').loc[model_order].reset_index()\n",
        "\n",
        "    bars = axs[1, 1].barh(scores_ordered['Model'], scores_ordered['R²_Adjusted_Test'],\n",
        "                          color=[model_colors[m] for m in scores_ordered['Model']])\n",
        "    axs[1, 1].set_xlabel('R² Adjusted')\n",
        "    axs[1, 1].invert_yaxis()\n",
        "    axs[1, 1].set_xlim(0, 1)\n",
        "\n",
        "    # --- Plot 6: Model Complexity (Parameter Count) ---\n",
        "    axs[1, 2].set_title('Model Complexity (Parameters)')\n",
        "\n",
        "    bars = axs[1, 2].barh(scores_ordered['Model'], scores_ordered['Parameters'],\n",
        "                          color=[model_colors[m] for m in scores_ordered['Model']])\n",
        "    axs[1, 2].set_xlabel('Parameter Count')\n",
        "    axs[1, 2].set_xscale('log')  # Log scale for parameter count\n",
        "    axs[1, 2].invert_yaxis()\n",
        "\n",
        "    for i, (bar, count) in enumerate(zip(bars, scores_ordered['Parameters'])):\n",
        "        if pd.notna(count) and count > 0:\n",
        "            axs[1, 2].text(bar.get_width() * 1.1,\n",
        "                           bar.get_y() + bar.get_height()/2,\n",
        "                           f'{int(count):,}',\n",
        "                           va='center', fontsize=9)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cM35irrjsw_k"
      },
      "outputs": [],
      "source": [
        "print(\"\\n=== TABELLA RIASSUNTIVA ===\")\n",
        "print(results_df.round(4))\n",
        "\n",
        "print(\"\\n=== PLOTTING SCORES ===\")\n",
        "plot_regression_scores(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjExhoteQDIa"
      },
      "outputs": [],
      "source": [
        "# 1) Define metrics and their optimization direction\n",
        "metrics = {\n",
        "    'MSE_Test': 'min',\n",
        "    'R²_Test': 'max',\n",
        "    'R²_Adjusted_Test': 'max',\n",
        "    'MAE_Test': 'min',\n",
        "    'MAPE_Test': 'min',\n",
        "    'Max_Error_Test': 'min'\n",
        "}\n",
        "\n",
        "# 2) Build ranking DataFrame\n",
        "df_ranks = results_df.set_index('Model')\n",
        "ranks = pd.DataFrame(index=df_ranks.index)\n",
        "\n",
        "# Calculate ranks for performance metrics\n",
        "for metric, direction in metrics.items():\n",
        "    if direction == 'max':\n",
        "        # For 'max' metrics (higher is better), rank in descending order (rank 1 is best)\n",
        "        ranks[f\"{metric}_rank\"] = df_ranks[metric].rank(ascending=False, method='average')\n",
        "    elif direction == 'min':\n",
        "        # For 'min' metrics (lower is better), rank in ascending order (rank 1 is best)\n",
        "        ranks[f\"{metric}_rank\"] = df_ranks[metric].rank(ascending=True, method='average')\n",
        "\n",
        "# Calculate complexity rank (lower parameter count is better)\n",
        "ranks['Complexity_rank'] = df_ranks['Parameters'].rank(ascending=True, method='average')\n",
        "\n",
        "# 3) Calculate weighted scores\n",
        "# Performance score (average of performance ranks)\n",
        "performance_cols = [col for col in ranks.columns if col.endswith('_rank') and col != 'Complexity_rank']\n",
        "ranks['performance_score'] = ranks[performance_cols].mean(axis=1)\n",
        "\n",
        "# Method 1: Equal weighting\n",
        "ranks['equal_weight_score'] = ranks['performance_score'] + ranks['Complexity_rank']\n",
        "\n",
        "# Method 2: Complexity heavily weighted (complexity counts 2x)\n",
        "ranks['complexity_weighted_score'] = ranks['performance_score'] + (2 * ranks['Complexity_rank'])\n",
        "\n",
        "# Method 3: Extreme complexity weighting (complexity counts 3x)\n",
        "ranks['extreme_complexity_score'] = ranks['performance_score'] + (3 * ranks['Complexity_rank'])\n",
        "\n",
        "# Method 4: Pareto efficiency approach (performance vs complexity)\n",
        "# Normalize scores to [0,1] for fair comparison\n",
        "performance_norm = (ranks['performance_score'] - ranks['performance_score'].min()) / (ranks['performance_score'].max() - ranks['performance_score'].min())\n",
        "complexity_norm = (ranks['Complexity_rank'] - ranks['Complexity_rank'].min()) / (ranks['Complexity_rank'].max() - ranks['Complexity_rank'].min())\n",
        "ranks['pareto_score'] = 0.4 * performance_norm + 0.6 * complexity_norm  # 60% weight on complexity\n",
        "\n",
        "# Display results for each method\n",
        "methods = {\n",
        "    'Equal Weight (1:1)': 'equal_weight_score',\n",
        "    'Complexity Weighted (1:2)': 'complexity_weighted_score',\n",
        "    'Extreme Complexity (1:3)': 'extreme_complexity_score',\n",
        "    'Pareto Approach (40:60)': 'pareto_score'\n",
        "}\n",
        "\n",
        "results_summary = pd.DataFrame(index=df_ranks.index)\n",
        "results_summary['Performance_Score'] = ranks['performance_score']\n",
        "results_summary['Complexity_Rank'] = ranks['Complexity_rank']\n",
        "results_summary['Parameters'] = df_ranks['Parameters']\n",
        "\n",
        "print(\"---\")\n",
        "print(\"## Best Models by Weighting Scheme\")\n",
        "print(\"---\")\n",
        "best_models_summary_data = {\n",
        "    'Weighting Scheme': [],\n",
        "    'Best Model(s)': []\n",
        "}\n",
        "\n",
        "for method_name, score_col in methods.items():\n",
        "    # For all these scores, a lower value is better\n",
        "    best_model = ranks[score_col].idxmin()\n",
        "    best_models_summary_data['Weighting Scheme'].append(method_name)\n",
        "    best_models_summary_data['Best Model(s)'].append(best_model)\n",
        "\n",
        "summary_df = pd.DataFrame(best_models_summary_data)\n",
        "print(summary_df.to_markdown(index=False))\n",
        "\n",
        "print(\"\\n---\")\n",
        "print(\"## Detailed Ranking Table\")\n",
        "print(\"---\")\n",
        "\n",
        "# Create comprehensive ranking table\n",
        "ranking_display = pd.DataFrame(index=df_ranks.index)\n",
        "ranking_display['Parameters'] = df_ranks['Parameters'].astype(int)\n",
        "ranking_display['Avg_Performance_Rank'] = ranks['performance_score'].round(2)\n",
        "ranking_display['Complexity_Rank'] = ranks['Complexity_rank'].astype(int)\n",
        "\n",
        "for method_name, score_col in methods.items():\n",
        "    ranking_display[f'{method_name.split()[0]}_Rank'] = ranks[score_col].rank().astype(int)\n",
        "\n",
        "# Sort by complexity-weighted score (our recommended approach for balancing performance and complexity)\n",
        "ranking_display_sorted = ranking_display.sort_values('Complexity_Rank')\n",
        "print(ranking_display_sorted.to_markdown())\n",
        "\n",
        "print(\"\\n---\")\n",
        "print(\"## Recommendation\")\n",
        "print(\"---\")\n",
        "\n",
        "# Our recommended model (complexity weighted approach)\n",
        "recommended_model = ranks['complexity_weighted_score'].idxmin()\n",
        "recommended_score = ranks.loc[recommended_model, 'complexity_weighted_score']\n",
        "recommended_params = df_ranks.loc[recommended_model, 'Parameters']\n",
        "# Assuming MSE_Test is a key metric to show for regression models\n",
        "recommended_mse = df_ranks.loc[recommended_model, 'MSE_Test']\n",
        "\n",
        "print(f\"**RECOMMENDED MODEL:** {recommended_model}\")\n",
        "print(f\"**Reason:** This model offers the best balance between predictive performance and model complexity.\")\n",
        "print(f\"**Parameters:** {int(recommended_params):,}\")\n",
        "print(f\"**MSE Test Score:** {recommended_mse:.4f}\")\n",
        "print(f\"**Complexity-Weighted Rank Score:** {recommended_score:.3f}\")\n",
        "\n",
        "print(f\"\\n**TOP 3 MODELS** (Based on Complexity-Weighted Ranking):\")\n",
        "top_3 = ranks.sort_values('complexity_weighted_score').head(3)\n",
        "for i, (model, row) in enumerate(top_3.iterrows(), 1):\n",
        "    params = int(df_ranks.loc[model, 'Parameters'])\n",
        "    mse_score = df_ranks.loc[model, 'MSE_Test']\n",
        "    print(f\" {i}. **{model}** | Parameters: {params:>8,} | MSE: {mse_score:.4f} | Score: {row['complexity_weighted_score']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa8trmzvic2F",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Ablation Study MLP e KAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU2FUaltieQj"
      },
      "outputs": [],
      "source": [
        "class RegressionPruningAblationStudy:\n",
        "    def __init__(self, device='cpu'):\n",
        "        self.device = device\n",
        "        self.pruning_results = []\n",
        "\n",
        "    def get_model_sparsity(self, model):\n",
        "        \"\"\"Calcola la sparsità del modello (solo componenti MLP/KAN)\"\"\"\n",
        "        if isinstance(model, MLP):\n",
        "            # Per MLP, calcola sparsità di tutti i layer Linear\n",
        "            total_params = 0\n",
        "            zero_params = 0\n",
        "\n",
        "            for module in model.modules():\n",
        "                if isinstance(module, torch.nn.Linear):\n",
        "                    if hasattr(module, 'weight'):\n",
        "                        total_params += module.weight.numel()\n",
        "                        zero_params += float(torch.sum(module.weight == 0))\n",
        "                    if hasattr(module, 'bias') and module.bias is not None:\n",
        "                        total_params += module.bias.numel()\n",
        "                        zero_params += float(torch.sum(module.bias == 0))\n",
        "\n",
        "            return zero_params / total_params if total_params > 0 else 0.0\n",
        "\n",
        "        elif hasattr(model, 'width'):  # KAN model\n",
        "            try:\n",
        "                if not model.width or len(model.width) < 2:\n",
        "                    return 0.0\n",
        "\n",
        "                # Calcola parametri totali KAN\n",
        "                total_params = count_params(model)\n",
        "                zero_params = 0\n",
        "\n",
        "                # Conta i parametri zero nella componente KAN\n",
        "                for i in range(len(model.width) - 1):\n",
        "                    if i < len(model.act_fun):\n",
        "                        layer = model.act_fun[i]\n",
        "                        # Accedi ai coefficienti spline (coef parameter)\n",
        "                        if hasattr(layer, 'coef') and layer.coef is not None:\n",
        "                            zero_params += float(torch.sum(layer.coef == 0))\n",
        "\n",
        "                return zero_params / total_params if total_params > 0 else 0.0\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Error calculating KAN sparsity: {e}\")\n",
        "                return 0.0\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "    def count_active_parameters(self, model):\n",
        "        \"\"\"Conta i parametri attivi nel modello\"\"\"\n",
        "        if isinstance(model, MLP):\n",
        "            active_params = 0\n",
        "            for module in model.modules():\n",
        "                if isinstance(module, torch.nn.Linear):\n",
        "                    if hasattr(module, 'weight'):\n",
        "                        active_params += float(torch.sum(module.weight != 0))\n",
        "                    if hasattr(module, 'bias') and module.bias is not None:\n",
        "                        active_params += float(torch.sum(module.bias != 0))\n",
        "            return int(active_params)\n",
        "\n",
        "        elif hasattr(model, 'width'):  # KAN model\n",
        "            try:\n",
        "                active_params = 0\n",
        "                for i in range(len(model.width) - 1):\n",
        "                    if i < len(model.act_fun):\n",
        "                        layer = model.act_fun[i]\n",
        "                        if hasattr(layer, 'coef') and layer.coef is not None:\n",
        "                            active_params += float(torch.sum(layer.coef != 0))\n",
        "                return int(active_params)\n",
        "            except:\n",
        "                return count_params(model)\n",
        "        else:\n",
        "            return count_params(model)\n",
        "\n",
        "    def apply_l1_pruning(self, model, pruning_ratio):\n",
        "      if pruning_ratio == 0.0:\n",
        "          return copy.deepcopy(model)\n",
        "\n",
        "      pruned_model = copy.deepcopy(model)\n",
        "\n",
        "      if isinstance(model, MLP):\n",
        "          modules_to_prune = []\n",
        "          for module in pruned_model.modules():\n",
        "              if isinstance(module, torch.nn.Linear):\n",
        "                  modules_to_prune.append((module, 'weight'))\n",
        "                  if hasattr(module, 'bias') and module.bias is not None:\n",
        "                      modules_to_prune.append((module, 'bias'))\n",
        "\n",
        "          if modules_to_prune:\n",
        "              prune.global_unstructured(\n",
        "                  modules_to_prune,\n",
        "                  pruning_method=prune.L1Unstructured,\n",
        "                  amount=pruning_ratio,\n",
        "              )\n",
        "              for module, param_name in modules_to_prune:\n",
        "                  prune.remove(module, param_name)\n",
        "\n",
        "          print(f\"  Applied L1 pruning to MLP with ratio: {pruning_ratio:.3f}\")\n",
        "          return pruned_model\n",
        "\n",
        "      else:  # KAN\n",
        "          try:\n",
        "              # Collect all trainable parameters\n",
        "              all_params = []\n",
        "              param_refs = []\n",
        "\n",
        "              for name, param in pruned_model.named_parameters():\n",
        "                  if param.requires_grad:\n",
        "                      all_params.append(param.data.flatten())\n",
        "                      param_refs.append((name, param))\n",
        "\n",
        "              if not all_params:\n",
        "                  print(f\"  No trainable parameters found\")\n",
        "                  return model\n",
        "\n",
        "              # Concatenate all parameters\n",
        "              all_params_tensor = torch.cat(all_params)\n",
        "\n",
        "              # Only use non-zero parameters for threshold calculation\n",
        "              nonzero_mask = torch.abs(all_params_tensor) > 1e-10  # Small epsilon for numerical stability\n",
        "              nonzero_params = all_params_tensor[nonzero_mask]\n",
        "\n",
        "              if len(nonzero_params) == 0:\n",
        "                  print(f\"  Model already completely sparse\")\n",
        "                  return pruned_model\n",
        "\n",
        "              # Calculate threshold from non-zero parameters only\n",
        "              abs_nonzero = torch.abs(nonzero_params)\n",
        "              threshold = torch.quantile(abs_nonzero, pruning_ratio).item()\n",
        "\n",
        "              if threshold == 0.0:\n",
        "                  # Fallback: use smallest non-zero value as threshold\n",
        "                  threshold = abs_nonzero.min().item() * 1.001  # Slightly above minimum\n",
        "\n",
        "              print(f\"  Threshold: {threshold:.8f}, Non-zero params: {len(nonzero_params)}/{len(all_params_tensor)}\")\n",
        "\n",
        "              # Apply pruning to each parameter\n",
        "              total_pruned = 0\n",
        "              original_nonzero = len(nonzero_params)\n",
        "\n",
        "              for name, param in param_refs:\n",
        "                  # Create mask: keep if |param| >= threshold\n",
        "                  mask = torch.abs(param.data) >= threshold\n",
        "\n",
        "                  # Count parameters that will be pruned\n",
        "                  will_be_pruned = torch.sum((torch.abs(param.data) > 1e-10) & (~mask)).item()\n",
        "                  total_pruned += will_be_pruned\n",
        "\n",
        "                  # Apply mask\n",
        "                  param.data = param.data * mask\n",
        "\n",
        "              actual_ratio = total_pruned / original_nonzero if original_nonzero > 0 else 0\n",
        "              print(f\"  Applied L1 pruning to KAN: {total_pruned}/{original_nonzero} params pruned (ratio: {actual_ratio:.3f})\")\n",
        "\n",
        "              return pruned_model\n",
        "\n",
        "          except Exception as e:\n",
        "              print(f\"  Error during KAN pruning: {e}\")\n",
        "              return model\n",
        "\n",
        "    def evaluate_pruned_model(self, model, model_name, test_loader, train_loader):\n",
        "        \"\"\"Valuta le prestazioni di un modello pruned per regressione\"\"\"\n",
        "        model.eval()\n",
        "\n",
        "        def get_predictions(data_loader):\n",
        "            preds, true = [], []\n",
        "            with torch.no_grad():\n",
        "                for Xb, yb in data_loader:\n",
        "                    Xb, yb = Xb.to(self.device), yb.to(self.device)\n",
        "                    outputs = model(Xb)\n",
        "                    preds.append(outputs.cpu().numpy())\n",
        "                    true.append(yb.cpu().numpy())\n",
        "            return np.vstack(true).flatten(), np.vstack(preds).flatten()\n",
        "\n",
        "        # Predizioni su test set\n",
        "        y_true_test, y_pred_test = get_predictions(test_loader)\n",
        "\n",
        "        # Predizioni su train set\n",
        "        y_true_train, y_pred_train = get_predictions(train_loader)\n",
        "\n",
        "        # Calcola metriche per test set\n",
        "        mse_test = mean_squared_error(y_true_test, y_pred_test)\n",
        "        mae_test = mean_absolute_error(y_true_test, y_pred_test)\n",
        "        r2_test = r2_score(y_true_test, y_pred_test)\n",
        "        max_err_test = max_error(y_true_test, y_pred_test)\n",
        "\n",
        "        # MAPE test\n",
        "        mape_test = np.mean(np.abs((y_true_test - y_pred_test) / y_true_test)) * 100\n",
        "        mape_test = mape_test if np.isfinite(mape_test) else np.nan\n",
        "\n",
        "        # Calcola metriche per train set\n",
        "        mse_train = mean_squared_error(y_true_train, y_pred_train)\n",
        "        mae_train = mean_absolute_error(y_true_train, y_pred_train)\n",
        "        r2_train = r2_score(y_true_train, y_pred_train)\n",
        "        max_err_train = max_error(y_true_train, y_pred_train)\n",
        "\n",
        "        # MAPE train\n",
        "        mape_train = np.mean(np.abs((y_true_train - y_pred_train) / y_true_train)) * 100\n",
        "        mape_train = mape_train if np.isfinite(mape_train) else np.nan\n",
        "\n",
        "        return {\n",
        "            'model_name': model_name,\n",
        "            'mse_test': mse_test,\n",
        "            'mae_test': mae_test,\n",
        "            'r2_test': r2_test,\n",
        "            'max_error_test': max_err_test,\n",
        "            'mape_test': mape_test,\n",
        "            'mse_train': mse_train,\n",
        "            'mae_train': mae_train,\n",
        "            'r2_train': r2_train,\n",
        "            'max_error_train': max_err_train,\n",
        "            'mape_train': mape_train\n",
        "        }\n",
        "\n",
        "    def run_pruning_study(self, model, model_name, test_loader, train_loader,\n",
        "                         pruning_ratios=[0.0, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 0.95]):\n",
        "        \"\"\"\n",
        "        Conduce lo studio di ablazione con L1 pruning per modelli di regressione\n",
        "        \"\"\"\n",
        "        print(f\"\\n=== L1 Pruning Study for {model_name} ===\")\n",
        "\n",
        "        # Parametri originali\n",
        "        original_params = count_params(model)\n",
        "        print(f\"Original Parameters: {original_params:,}\")\n",
        "\n",
        "        for pruning_ratio in pruning_ratios:\n",
        "            print(f\"\\nTesting pruning ratio: {pruning_ratio:.4f}\")\n",
        "\n",
        "            # Applica pruning\n",
        "            pruned_model = self.apply_l1_pruning(model, pruning_ratio)\n",
        "\n",
        "            # Calcola sparsità e parametri attivi\n",
        "            sparsity = self.get_model_sparsity(pruned_model)\n",
        "            active_params = self.count_active_parameters(pruned_model)\n",
        "\n",
        "            # Valuta prestazioni\n",
        "            metrics = self.evaluate_pruned_model(\n",
        "                pruned_model, model_name, test_loader, train_loader\n",
        "            )\n",
        "\n",
        "            # Calcola compression ratio\n",
        "            compression_ratio = original_params / active_params if active_params > 0 else float('inf')\n",
        "\n",
        "            # Salva risultati\n",
        "            result = {\n",
        "                'model_name': model_name,\n",
        "                'pruning_ratio': pruning_ratio,\n",
        "                'sparsity': sparsity,\n",
        "                'original_params': original_params,\n",
        "                'active_params': active_params,\n",
        "                'compression_ratio': compression_ratio,\n",
        "                'mse_test': metrics['mse_test'],\n",
        "                'mae_test': metrics['mae_test'],\n",
        "                'r2_test': metrics['r2_test'],\n",
        "                'max_error_test': metrics['max_error_test'],\n",
        "                'mape_test': metrics['mape_test'],\n",
        "                'mse_train': metrics['mse_train'],\n",
        "                'mae_train': metrics['mae_train'],\n",
        "                'r2_train': metrics['r2_train'],\n",
        "                'max_error_train': metrics['max_error_train'],\n",
        "                'mape_train': metrics['mape_train']\n",
        "            }\n",
        "\n",
        "            self.pruning_results.append(result)\n",
        "\n",
        "            print(f\"  Sparsity: {sparsity:.3f}\")\n",
        "            print(f\"  Active params: {active_params:,} / {original_params:,}\")\n",
        "            print(f\"  Compression: {compression_ratio:.2f}x\")\n",
        "            print(f\"  Test MSE: {metrics['mse_test']:.4f}\")\n",
        "            print(f\"  Test R²: {metrics['r2_test']:.4f}\")\n",
        "            print(f\"  Test MAE: {metrics['mae_test']:.4f}\")\n",
        "\n",
        "    def plot_pruning_results(self, figsize=(20, 12)):\n",
        "        \"\"\"\n",
        "        Visualizza i risultati dello studio di pruning per regressione\n",
        "        \"\"\"\n",
        "        if not self.pruning_results:\n",
        "            print(\"No pruning results to plot. Run pruning study first.\")\n",
        "            return\n",
        "\n",
        "        df = pd.DataFrame(self.pruning_results)\n",
        "\n",
        "        fig, axes = plt.subplots(3, 4, figsize=figsize)\n",
        "        fig.suptitle('L1 Pruning Study', fontsize=16, fontweight='bold')\n",
        "\n",
        "        models = df['model_name'].unique()\n",
        "        colors = sns.color_palette(\"husl\", len(models))\n",
        "\n",
        "        # Plot 1: MSE vs Pruning Ratio\n",
        "        ax = axes[0, 0]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            ax.plot(model_data['pruning_ratio'], model_data['mse_test'],\n",
        "                   marker='o', label=f'{model} (Test)', color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Pruning Ratio')\n",
        "        ax.set_ylabel('MSE')\n",
        "        ax.set_title('MSE vs Pruning Ratio')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_yscale('log')\n",
        "\n",
        "        # Plot 2: R² vs Pruning Ratio\n",
        "        ax = axes[0, 1]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            ax.plot(model_data['pruning_ratio'], model_data['r2_test'],\n",
        "                   marker='o', label=f'{model} (Test)', color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Pruning Ratio')\n",
        "        ax.set_ylabel('R² Score')\n",
        "        ax.set_title('R² vs Pruning Ratio')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 3: MAE vs Pruning Ratio\n",
        "        ax = axes[0, 2]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            ax.plot(model_data['pruning_ratio'], model_data['mae_test'],\n",
        "                   marker='o', label=f'{model} (Test)', color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Pruning Ratio')\n",
        "        ax.set_ylabel('MAE')\n",
        "        ax.set_title('MAE vs Pruning Ratio')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 4: MAPE vs Pruning Ratio\n",
        "        ax = axes[0, 3]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            valid_mape_test = model_data[model_data['mape_test'].notna()]\n",
        "            valid_mape_train = model_data[model_data['mape_train'].notna()]\n",
        "            if len(valid_mape_test) > 0:\n",
        "                ax.plot(valid_mape_test['pruning_ratio'], valid_mape_test['mape_test'],\n",
        "                       marker='o', label=f'{model} (Test)', color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Pruning Ratio')\n",
        "        ax.set_ylabel('MAPE (%)')\n",
        "        ax.set_title('MAPE vs Pruning Ratio')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 5: Performance vs Compression Ratio\n",
        "        ax = axes[1, 0]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            finite_mask = np.isfinite(model_data['compression_ratio'])\n",
        "            if finite_mask.any():\n",
        "                ax.scatter(model_data.loc[finite_mask, 'compression_ratio'],\n",
        "                          model_data.loc[finite_mask, 'r2_test'],\n",
        "                          label=model, color=colors[i], s=50, alpha=0.7)\n",
        "        ax.set_xlabel('Compression Ratio (x)')\n",
        "        ax.set_ylabel('R² Test Score')\n",
        "        ax.set_title('Performance vs Compression')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_xscale('log')\n",
        "\n",
        "        # Plot 6: Sparsity vs Performance\n",
        "        ax = axes[1, 1]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            ax.plot(model_data['sparsity'], model_data['r2_test'],\n",
        "                   marker='d', label=model, color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Sparsity')\n",
        "        ax.set_ylabel('R² Test Score')\n",
        "        ax.set_title('Performance vs Sparsity')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 7: Parameters Count vs Pruning\n",
        "        ax = axes[1, 2]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            ax.plot(model_data['pruning_ratio'], model_data['active_params'],\n",
        "                   marker='o', label=model, color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Pruning Ratio')\n",
        "        ax.set_ylabel('Active Parameters')\n",
        "        ax.set_title('Active Parameters vs Pruning')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_yscale('log')\n",
        "\n",
        "        # Plot 8: Performance Retention\n",
        "        ax = axes[1, 3]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model].sort_values('pruning_ratio')\n",
        "            baseline_r2 = model_data.iloc[0]['r2_test']\n",
        "            performance_retention = model_data['r2_test'] / baseline_r2\n",
        "            ax.plot(model_data['pruning_ratio'], performance_retention,\n",
        "                   marker='s', label=model, color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Pruning Ratio')\n",
        "        ax.set_ylabel('R² Retention (Relative)')\n",
        "        ax.set_title('Performance Retention vs Pruning')\n",
        "        ax.axhline(y=0.95, color='red', linestyle='--', alpha=0.7, label='95% threshold')\n",
        "        ax.axhline(y=0.90, color='orange', linestyle='--', alpha=0.7, label='90% threshold')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 9: Max Error vs Pruning\n",
        "        ax = axes[2, 0]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            ax.plot(model_data['pruning_ratio'], model_data['max_error_test'],\n",
        "                   marker='o', label=f'{model} (Test)', color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Pruning Ratio')\n",
        "        ax.set_ylabel('Max Error')\n",
        "        ax.set_title('Max Error vs Pruning Ratio')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_yscale('log')\n",
        "\n",
        "        # Plot 10: Compression Efficiency\n",
        "        ax = axes[2, 1]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            ax.plot(model_data['pruning_ratio'], model_data['compression_ratio'],\n",
        "                   marker='o', label=model, color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Pruning Ratio')\n",
        "        ax.set_ylabel('Compression Ratio (x)')\n",
        "        ax.set_title('Compression Efficiency')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_yscale('log')\n",
        "\n",
        "        axes[2, 2].axis('off')\n",
        "        axes[2, 3].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def generate_pruning_report(self):\n",
        "        \"\"\"\n",
        "        Genera un report dettagliato dei risultati del pruning per regressione\n",
        "        \"\"\"\n",
        "        if not self.pruning_results:\n",
        "            print(\"No pruning results available. Run pruning study first.\")\n",
        "            return\n",
        "\n",
        "        df = pd.DataFrame(self.pruning_results)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*90)\n",
        "        print(\"L1 PRUNING STUDY - DETAILED REPORT\")\n",
        "        print(\"=\"*90)\n",
        "\n",
        "        for model_name in df['model_name'].unique():\n",
        "            model_data = df[df['model_name'] == model_name].sort_values('pruning_ratio')\n",
        "\n",
        "            print(f\"\\n{model_name} Results:\")\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "            # Baseline metrics\n",
        "            baseline_row = model_data.iloc[0]\n",
        "            baseline_r2 = baseline_row['r2_test']\n",
        "            baseline_mse = baseline_row['mse_test']\n",
        "            original_params = baseline_row['original_params']\n",
        "\n",
        "            print(f\"Original Parameters: {original_params:,}\")\n",
        "            print(f\"Baseline Test R²: {baseline_r2:.4f}\")\n",
        "            print(f\"Baseline Test MSE: {baseline_mse:.4f}\")\n",
        "\n",
        "            # Find degradation point (>5% loss in R²)\n",
        "            degradation_point = None\n",
        "            for _, row in model_data.iterrows():\n",
        "                r2_loss = (baseline_r2 - row['r2_test']) / abs(baseline_r2) if baseline_r2 != 0 else 0\n",
        "                if r2_loss > 0.05:  # 5% degradation threshold\n",
        "                    degradation_point = row['pruning_ratio']\n",
        "                    break\n",
        "\n",
        "            if degradation_point:\n",
        "                print(f\"Significant degradation starts at: {degradation_point:.1%} pruning\")\n",
        "            else:\n",
        "                print(\"No significant degradation observed within tested range\")\n",
        "\n",
        "            # Best trade-off point (maximum compression with <2% R² loss)\n",
        "            best_tradeoff = None\n",
        "            for _, row in model_data.iterrows():\n",
        "                r2_loss = (baseline_r2 - row['r2_test']) / abs(baseline_r2) if baseline_r2 != 0 else 0\n",
        "                if r2_loss <= 0.02 and row['pruning_ratio'] > 0:\n",
        "                    best_tradeoff = row\n",
        "\n",
        "            if best_tradeoff is not None:\n",
        "                print(f\"\\nBest trade-off point:\")\n",
        "                print(f\"  Pruning ratio: {best_tradeoff['pruning_ratio']:.1%}\")\n",
        "                print(f\"  Compression: {best_tradeoff['compression_ratio']:.1f}x\")\n",
        "                print(f\"  Test R²: {best_tradeoff['r2_test']:.4f}\")\n",
        "                print(f\"  Test MSE: {best_tradeoff['mse_test']:.4f}\")\n",
        "                print(f\"  R² loss: {((baseline_r2 - best_tradeoff['r2_test'])/abs(baseline_r2)*100):.1f}%\")\n",
        "\n",
        "            # Maximum compression achieved\n",
        "            max_compression = model_data['compression_ratio'].replace([np.inf, -np.inf], np.nan).max()\n",
        "            if not np.isnan(max_compression):\n",
        "                print(f\"\\nMaximum compression achieved: {max_compression:.1f}x\")\n",
        "\n",
        "        # Comparative summary table\n",
        "        print(f\"\\n{'='*90}\")\n",
        "        print(\"COMPARATIVE SUMMARY TABLE - PRUNING EFFECTIVENESS\")\n",
        "        print(\"=\"*90)\n",
        "\n",
        "        summary_rows = []\n",
        "        for model_name in df['model_name'].unique():\n",
        "            model_data = df[df['model_name'] == model_name]\n",
        "            baseline = model_data[model_data['pruning_ratio'] == 0.0].iloc[0]\n",
        "\n",
        "            # Find results at different pruning thresholds\n",
        "            for target_ratio in [0.3, 0.5, 0.7, 0.9]:\n",
        "                closest = model_data.iloc[(model_data['pruning_ratio'] - target_ratio).abs().argsort()].iloc[0]\n",
        "                if abs(closest['pruning_ratio'] - target_ratio) < 0.1:  # If close enough\n",
        "                    r2_loss = ((baseline['r2_test'] - closest['r2_test']) / abs(baseline['r2_test'])) * 100 if baseline['r2_test'] != 0 else 0\n",
        "                    mse_increase = ((closest['mse_test'] - baseline['mse_test']) / baseline['mse_test']) * 100\n",
        "                    summary_rows.append({\n",
        "                        'Model': model_name,\n",
        "                        'Pruning_Ratio': f\"{target_ratio:.0%}\",\n",
        "                        'Compression': f\"{closest['compression_ratio']:.1f}x\",\n",
        "                        'R²_Test': f\"{closest['r2_test']:.4f}\",\n",
        "                        'MSE_Test': f\"{closest['mse_test']:.2f}\",\n",
        "                        'R²_Loss': f\"{r2_loss:.1f}%\",\n",
        "                        'MSE_Increase': f\"{mse_increase:.1f}%\"\n",
        "                    })\n",
        "\n",
        "        if summary_rows:\n",
        "            summary_df = pd.DataFrame(summary_rows)\n",
        "            print(summary_df.to_string(index=False))\n",
        "\n",
        "print(\"Iniziando L1 Pruning Study per modelli di regressione...\")\n",
        "print(\"METODOLOGIA:\")\n",
        "print(\"- MLP: L1 norm pruning su tutti i layer Linear\")\n",
        "print(\"- KAN: L1 norm pruning sui coefficienti spline\")\n",
        "print(\"- Metriche: MSE, MAE, R², MAPE, Max Error\\n\")\n",
        "\n",
        "# Inizializza la classe per lo studio di pruning\n",
        "regression_pruning_study = RegressionPruningAblationStudy(device=device)\n",
        "\n",
        "# Definisci i livelli di pruning da testare\n",
        "pruning_ratios_uniform = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
        "\n",
        "# Esegui pruning study su MLP\n",
        "if 'mlp_model' in locals():\n",
        "    print(\"Trovato modello MLP - Eseguendo L1 pruning study...\")\n",
        "    regression_pruning_study.run_pruning_study(\n",
        "        model=mlp_model,\n",
        "        model_name='MLP',\n",
        "        test_loader=test_loader,\n",
        "        train_loader=train_loader,\n",
        "        pruning_ratios=pruning_ratios_uniform\n",
        "    )\n",
        "\n",
        "# Esegui pruning study su KAN\n",
        "if 'kan_model' in locals():\n",
        "    print(\"Trovato modello KAN - Eseguendo L1 pruning study...\")\n",
        "    regression_pruning_study.run_pruning_study(\n",
        "        model=kan_model,\n",
        "        model_name='KAN',\n",
        "        test_loader=test_loader,\n",
        "        train_loader=train_loader,\n",
        "        pruning_ratios=pruning_ratios_uniform\n",
        "    )\n",
        "\n",
        "# Visualizza i risultati\n",
        "regression_pruning_study.plot_pruning_results()\n",
        "\n",
        "# Genera report dettagliato\n",
        "regression_pruning_study.generate_pruning_report()\n",
        "\n",
        "# Salva i risultati in DataFrame per ulteriori analisi\n",
        "pruning_results_df = pd.DataFrame(regression_pruning_study.pruning_results)\n",
        "print(f\"\\nPruning results saved to 'pruning_results_df' with {len(pruning_results_df)} entries\")\n",
        "print(\"\\nPruning results:\")\n",
        "display(pruning_results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vB7ChvAv17b",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Ablation Study Random Forest e XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVZgauhTv4qd"
      },
      "outputs": [],
      "source": [
        "class EnsemblePruningAblationStudy:\n",
        "    def __init__(self):\n",
        "        self.ensemble_results = []\n",
        "\n",
        "    def calculate_tree_importance_rf(self, model, X_val, y_val):\n",
        "        \"\"\"\n",
        "        Calculate tree importance for Random Forest using validation performance\n",
        "        \"\"\"\n",
        "        tree_importances = []\n",
        "\n",
        "        for i, tree in enumerate(model.estimators_):\n",
        "            # Make predictions with single tree\n",
        "            tree_pred = tree.predict(X_val)\n",
        "\n",
        "            # Calculate individual tree performance (negative MSE for ranking)\n",
        "            tree_mse = mean_squared_error(y_val, tree_pred)\n",
        "            tree_r2 = r2_score(y_val, tree_pred)\n",
        "\n",
        "            # Use R² as importance metric (higher is better)\n",
        "            tree_importances.append({\n",
        "                'tree_idx': i,\n",
        "                'importance': tree_r2,\n",
        "                'mse': tree_mse,\n",
        "                'r2': tree_r2\n",
        "            })\n",
        "\n",
        "        # Sort by importance (R² descending)\n",
        "        tree_importances.sort(key=lambda x: x['importance'], reverse=True)\n",
        "        return tree_importances\n",
        "\n",
        "    def calculate_tree_importance_xgb(self, model, X_val, y_val):\n",
        "        \"\"\"\n",
        "        Calculate cumulative importance for XGBoost trees using incremental R² improvement\n",
        "        \"\"\"\n",
        "        booster = model.get_booster()\n",
        "        n_estimators = model.n_estimators\n",
        "        dval = xgb.DMatrix(X_val)\n",
        "        tree_importances = []\n",
        "\n",
        "        for i in range(n_estimators):\n",
        "            # Predictions from first i+1 trees\n",
        "            pred_i = booster.predict(dval, iteration_range=(0, i+1))\n",
        "            r2_i = r2_score(y_val, pred_i)\n",
        "            if i == 0:\n",
        "                improvement = r2_i\n",
        "            else:\n",
        "                pred_prev = booster.predict(dval, iteration_range=(0, i))\n",
        "                r2_prev = r2_score(y_val, pred_prev)\n",
        "                improvement = r2_i - r2_prev\n",
        "\n",
        "            tree_importances.append({\n",
        "                'tree_idx': i,\n",
        "                'importance': improvement,\n",
        "                'cumulative_r2': r2_i,\n",
        "                'cumulative_mse': mean_squared_error(y_val, pred_i)\n",
        "            })\n",
        "        return tree_importances\n",
        "\n",
        "    def apply_rank_based_pruning_rf(self, model, pruning_ratio, X_val, y_val):\n",
        "        \"\"\"\n",
        "        Apply rank-based pruning to Random Forest\n",
        "        \"\"\"\n",
        "        if pruning_ratio == 0.0:\n",
        "            return copy.deepcopy(model)\n",
        "\n",
        "        # Calculate tree importances\n",
        "        tree_importances = self.calculate_tree_importance_rf(model, X_val, y_val)\n",
        "\n",
        "        # Determine how many trees to keep\n",
        "        n_trees = len(model.estimators_)\n",
        "        n_keep = max(1, int(n_trees * (1 - pruning_ratio)))\n",
        "\n",
        "        # Select top trees\n",
        "        top_trees_idx = [item['tree_idx'] for item in tree_importances[:n_keep]]\n",
        "\n",
        "        # Create pruned model\n",
        "        pruned_model = copy.deepcopy(model)\n",
        "        pruned_model.estimators_ = [model.estimators_[i] for i in top_trees_idx]\n",
        "        pruned_model.n_estimators = len(pruned_model.estimators_)\n",
        "\n",
        "        return pruned_model\n",
        "\n",
        "    def apply_cumulative_pruning_xgb(self, model, pruning_ratio, X_val, y_val):\n",
        "        \"\"\"\n",
        "        Apply post-training cumulative pruning to XGBoost by limiting predictions to first n_keep trees\n",
        "        \"\"\"\n",
        "        if pruning_ratio <= 0.0:\n",
        "            return copy.deepcopy(model)\n",
        "\n",
        "        # Calculate tree importances to find cutoff\n",
        "        tree_importances = self.calculate_tree_importance_xgb(model, X_val, y_val)\n",
        "        n_trees = len(tree_importances)\n",
        "        n_keep = max(1, int(n_trees * (1 - pruning_ratio)))\n",
        "\n",
        "        # Get original booster\n",
        "        original_booster = model.get_booster()\n",
        "\n",
        "        # Create pruned model wrapper\n",
        "        pruned_model = copy.deepcopy(model)\n",
        "        pruned_model.n_estimators = n_keep\n",
        "\n",
        "        def predict_pruned(self, X):\n",
        "            dmat = xgb.DMatrix(X)\n",
        "            return original_booster.predict(dmat, iteration_range=(0, n_keep))\n",
        "        pruned_model.predict = types.MethodType(predict_pruned, pruned_model)\n",
        "\n",
        "        return pruned_model\n",
        "\n",
        "    def count_ensemble_components(self, model):\n",
        "        \"\"\"Count the number of components in ensemble model\"\"\"\n",
        "        if isinstance(model, RandomForestRegressor):\n",
        "            return len(model.estimators_) if hasattr(model, 'estimators_') else model.n_estimators\n",
        "        elif isinstance(model, xgb.XGBRegressor):\n",
        "            return model.n_estimators\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def calculate_ensemble_sparsity(self, original_count, pruned_count):\n",
        "        \"\"\"Calculate sparsity as fraction of components removed\"\"\"\n",
        "        return (original_count - pruned_count) / original_count if original_count > 0 else 0.0\n",
        "\n",
        "    def evaluate_ensemble_model(self, model, model_name, X_test, y_test, X_train, y_train):\n",
        "        \"\"\"Evaluate ensemble model performance\"\"\"\n",
        "\n",
        "        # Test predictions\n",
        "        y_pred_test = model.predict(X_test)\n",
        "        y_test_np = y_test.values.flatten() if hasattr(y_test, 'values') else y_test.flatten()\n",
        "        y_pred_test = y_pred_test.flatten()\n",
        "\n",
        "        # Train predictions\n",
        "        y_pred_train = model.predict(X_train)\n",
        "        y_train_np = y_train.values.flatten() if hasattr(y_train, 'values') else y_train.flatten()\n",
        "        y_pred_train = y_pred_train.flatten()\n",
        "\n",
        "        # Ensure same length\n",
        "        min_len_test = min(len(y_test_np), len(y_pred_test))\n",
        "        y_test_np = y_test_np[:min_len_test]\n",
        "        y_pred_test = y_pred_test[:min_len_test]\n",
        "\n",
        "        min_len_train = min(len(y_train_np), len(y_pred_train))\n",
        "        y_train_np = y_train_np[:min_len_train]\n",
        "        y_pred_train = y_pred_train[:min_len_train]\n",
        "\n",
        "        # Calculate test metrics\n",
        "        mse_test = mean_squared_error(y_test_np, y_pred_test)\n",
        "        mae_test = mean_absolute_error(y_test_np, y_pred_test)\n",
        "        r2_test = r2_score(y_test_np, y_pred_test)\n",
        "        max_err_test = max_error(y_test_np, y_pred_test)\n",
        "\n",
        "        # MAPE test (handle division by zero)\n",
        "        mape_test = np.mean(np.abs((y_test_np - y_pred_test) / y_test_np)) * 100\n",
        "        mape_test = mape_test if np.isfinite(mape_test) else np.nan\n",
        "\n",
        "        # Calculate train metrics\n",
        "        mse_train = mean_squared_error(y_train_np, y_pred_train)\n",
        "        mae_train = mean_absolute_error(y_train_np, y_pred_train)\n",
        "        r2_train = r2_score(y_train_np, y_pred_train)\n",
        "        max_err_train = max_error(y_train_np, y_pred_train)\n",
        "\n",
        "        # MAPE train\n",
        "        mape_train = np.mean(np.abs((y_train_np - y_pred_train) / y_train_np)) * 100\n",
        "        mape_train = mape_train if np.isfinite(mape_train) else np.nan\n",
        "\n",
        "        return {\n",
        "            'model_name': model_name,\n",
        "            'mse_test': mse_test,\n",
        "            'mae_test': mae_test,\n",
        "            'r2_test': r2_test,\n",
        "            'max_error_test': max_err_test,\n",
        "            'mape_test': mape_test,\n",
        "            'mse_train': mse_train,\n",
        "            'mae_train': mae_train,\n",
        "            'r2_train': r2_train,\n",
        "            'max_error_train': max_err_train,\n",
        "            'mape_train': mape_train\n",
        "        }\n",
        "\n",
        "    def run_ensemble_pruning_study(self, model, model_name, X_train, y_train, X_test, y_test, X_val, y_val,\n",
        "                                 pruning_ratios=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]):\n",
        "        \"\"\"\n",
        "        Run ensemble pruning study\n",
        "        \"\"\"\n",
        "        print(f\"\\n=== Ensemble Pruning Study for {model_name} ===\")\n",
        "\n",
        "        # Original component count\n",
        "        original_components = self.count_ensemble_components(model)\n",
        "        print(f\"Original {model_name} components: {original_components}\")\n",
        "\n",
        "        for pruning_ratio in pruning_ratios:\n",
        "            print(f\"\\nTesting pruning ratio: {pruning_ratio:.4f}\")\n",
        "\n",
        "            if isinstance(model, RandomForestRegressor):\n",
        "                # Apply rank-based pruning\n",
        "                pruned_model = self.apply_rank_based_pruning_rf(model, pruning_ratio, X_val, y_val)\n",
        "            elif isinstance(model, xgb.XGBRegressor):\n",
        "                # Apply cumulative pruning\n",
        "                pruned_model = self.apply_cumulative_pruning_xgb(model, pruning_ratio, X_val, y_val)\n",
        "            else:\n",
        "                print(f\"Unsupported model type: {type(model)}\")\n",
        "                continue\n",
        "\n",
        "            # Count components after pruning\n",
        "            pruned_components = self.count_ensemble_components(pruned_model)\n",
        "            sparsity = self.calculate_ensemble_sparsity(original_components, pruned_components)\n",
        "            compression_ratio = original_components / pruned_components if pruned_components > 0 else float('inf')\n",
        "\n",
        "            # Evaluate performance\n",
        "            metrics = self.evaluate_ensemble_model(\n",
        "                pruned_model, model_name, X_test, y_test, X_train, y_train\n",
        "            )\n",
        "\n",
        "            # Store results\n",
        "            result = {\n",
        "                'model_name': model_name,\n",
        "                'pruning_ratio': pruning_ratio,\n",
        "                'sparsity': sparsity,\n",
        "                'original_components': original_components,\n",
        "                'active_components': pruned_components,\n",
        "                'compression_ratio': compression_ratio,\n",
        "                'mse_test': metrics['mse_test'],\n",
        "                'mae_test': metrics['mae_test'],\n",
        "                'r2_test': metrics['r2_test'],\n",
        "                'max_error_test': metrics['max_error_test'],\n",
        "                'mape_test': metrics['mape_test'],\n",
        "                'mse_train': metrics['mse_train'],\n",
        "                'mae_train': metrics['mae_train'],\n",
        "                'r2_train': metrics['r2_train'],\n",
        "                'max_error_train': metrics['max_error_train'],\n",
        "                'mape_train': metrics['mape_train']\n",
        "            }\n",
        "\n",
        "            self.ensemble_results.append(result)\n",
        "\n",
        "            print(f\"  Active components: {pruned_components} / {original_components}\")\n",
        "            print(f\"  Compression: {compression_ratio:.2f}x\")\n",
        "            print(f\"  Test MSE: {metrics['mse_test']:.4f}\")\n",
        "            print(f\"  Test R²: {metrics['r2_test']:.4f}\")\n",
        "            print(f\"  Test MAE: {metrics['mae_test']:.4f}\")\n",
        "\n",
        "    def plot_ensemble_pruning_results(self, figsize=(20, 12)):\n",
        "        \"\"\"\n",
        "        Plot ensemble pruning results\n",
        "        \"\"\"\n",
        "        if not self.ensemble_results:\n",
        "            print(\"No ensemble pruning results to plot. Run ensemble pruning study first.\")\n",
        "            return\n",
        "\n",
        "        df = pd.DataFrame(self.ensemble_results)\n",
        "\n",
        "        fig, axes = plt.subplots(3, 4, figsize=figsize)\n",
        "        fig.suptitle('Ensemble Pruning Study - Random Forest (Rank-Based) & XGBoost (Cumulative)',\n",
        "                    fontsize=16, fontweight='bold')\n",
        "\n",
        "        models = df['model_name'].unique()\n",
        "        colors = sns.color_palette(\"Set1\", len(models))\n",
        "\n",
        "        # Plot 1: MSE vs Pruning Ratio\n",
        "        ax = axes[0, 0]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            ax.plot(model_data['pruning_ratio'], model_data['mse_test'],\n",
        "                   marker='o', label=f'{model} (Test)', color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Pruning Ratio')\n",
        "        ax.set_ylabel('MSE')\n",
        "        ax.set_title('MSE vs Pruning Ratio')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_yscale('log')\n",
        "\n",
        "        # Plot 2: R² vs Pruning Ratio\n",
        "        ax = axes[0, 1]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            ax.plot(model_data['pruning_ratio'], model_data['r2_test'],\n",
        "                   marker='o', label=f'{model} (Test)', color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Pruning Ratio')\n",
        "        ax.set_ylabel('R² Score')\n",
        "        ax.set_title('R² vs Pruning Ratio')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 3: MAE vs Pruning Ratio\n",
        "        ax = axes[0, 2]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            ax.plot(model_data['pruning_ratio'], model_data['mae_test'],\n",
        "                   marker='o', label=f'{model} (Test)', color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Pruning Ratio')\n",
        "        ax.set_ylabel('MAE')\n",
        "        ax.set_title('MAE vs Pruning Ratio')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 4: MAPE vs Pruning Ratio\n",
        "        ax = axes[0, 3]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            valid_mape_test = model_data[model_data['mape_test'].notna()]\n",
        "            if len(valid_mape_test) > 0:\n",
        "                ax.plot(valid_mape_test['pruning_ratio'], valid_mape_test['mape_test'],\n",
        "                       marker='o', label=f'{model} (Test)', color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Pruning Ratio')\n",
        "        ax.set_ylabel('MAPE (%)')\n",
        "        ax.set_title('MAPE vs Pruning Ratio')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 5: Performance vs Compression Ratio\n",
        "        ax = axes[1, 0]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            finite_mask = np.isfinite(model_data['compression_ratio'])\n",
        "            if finite_mask.any():\n",
        "                ax.scatter(model_data.loc[finite_mask, 'compression_ratio'],\n",
        "                          model_data.loc[finite_mask, 'r2_test'],\n",
        "                          label=model, color=colors[i], s=50, alpha=0.7)\n",
        "        ax.set_xlabel('Compression Ratio (x)')\n",
        "        ax.set_ylabel('R² Test Score')\n",
        "        ax.set_title('Performance vs Compression')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_xscale('log')\n",
        "\n",
        "        # Plot 6: Sparsity vs Performance\n",
        "        ax = axes[1, 1]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            ax.plot(model_data['sparsity'], model_data['r2_test'],\n",
        "                   marker='d', label=model, color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Sparsity (Fraction Removed)')\n",
        "        ax.set_ylabel('R² Test Score')\n",
        "        ax.set_title('Performance vs Sparsity')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 7: Active Components vs Pruning\n",
        "        ax = axes[1, 2]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            ax.plot(model_data['pruning_ratio'], model_data['active_components'],\n",
        "                   marker='o', label=model, color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Pruning Ratio')\n",
        "        ax.set_ylabel('Active Components (Trees/Estimators)')\n",
        "        ax.set_title('Active Components vs Pruning')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_yscale('log')\n",
        "\n",
        "        # Plot 8: Performance Retention\n",
        "        ax = axes[1, 3]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model].sort_values('pruning_ratio')\n",
        "            if len(model_data) > 0:\n",
        "                baseline_r2 = model_data.iloc[0]['r2_test']\n",
        "                if baseline_r2 != 0:\n",
        "                    performance_retention = model_data['r2_test'] / baseline_r2\n",
        "                    ax.plot(model_data['pruning_ratio'], performance_retention,\n",
        "                           marker='s', label=model, color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Pruning Ratio')\n",
        "        ax.set_ylabel('R² Retention (Relative)')\n",
        "        ax.set_title('Performance Retention vs Pruning')\n",
        "        ax.axhline(y=0.95, color='red', linestyle='--', alpha=0.7, label='95% threshold')\n",
        "        ax.axhline(y=0.90, color='orange', linestyle='--', alpha=0.7, label='90% threshold')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 9: Max Error vs Pruning\n",
        "        ax = axes[2, 0]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            ax.plot(model_data['pruning_ratio'], model_data['max_error_test'],\n",
        "                   marker='o', label=f'{model} (Test)', color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Pruning Ratio')\n",
        "        ax.set_ylabel('Max Error')\n",
        "        ax.set_title('Max Error vs Pruning Ratio')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_yscale('log')\n",
        "\n",
        "        # Plot 10: Compression Efficiency\n",
        "        ax = axes[2, 1]\n",
        "        for i, model in enumerate(models):\n",
        "            model_data = df[df['model_name'] == model]\n",
        "            finite_mask = np.isfinite(model_data['compression_ratio'])\n",
        "            if finite_mask.any():\n",
        "                ax.plot(model_data.loc[finite_mask, 'pruning_ratio'],\n",
        "                       model_data.loc[finite_mask, 'compression_ratio'],\n",
        "                       marker='o', label=model, color=colors[i], linewidth=2)\n",
        "        ax.set_xlabel('Pruning Ratio')\n",
        "        ax.set_ylabel('Compression Ratio (x)')\n",
        "        ax.set_title('Compression Efficiency')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_yscale('log')\n",
        "\n",
        "        axes[2, 2].axis('off')\n",
        "        axes[2, 3].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def generate_ensemble_pruning_report(self):\n",
        "        \"\"\"\n",
        "        Generate detailed ensemble pruning report\n",
        "        \"\"\"\n",
        "        if not self.ensemble_results:\n",
        "            print(\"No ensemble pruning results available. Run ensemble pruning study first.\")\n",
        "            return\n",
        "\n",
        "        df = pd.DataFrame(self.ensemble_results)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*100)\n",
        "        print(\"ENSEMBLE PRUNING STUDY - DETAILED REPORT\")\n",
        "        print(\"Random Forest: Rank-Based Pruning | XGBoost: Cumulative Pruning\")\n",
        "        print(\"=\"*100)\n",
        "\n",
        "        for model_name in df['model_name'].unique():\n",
        "            model_data = df[df['model_name'] == model_name].sort_values('pruning_ratio')\n",
        "\n",
        "            print(f\"\\n{model_name} Results:\")\n",
        "            print(\"-\" * 70)\n",
        "\n",
        "            # Baseline metrics\n",
        "            baseline_row = model_data.iloc[0]\n",
        "            baseline_r2 = baseline_row['r2_test']\n",
        "            baseline_mse = baseline_row['mse_test']\n",
        "            original_components = baseline_row['original_components']\n",
        "\n",
        "            print(f\"Original Components: {original_components}\")\n",
        "            print(f\"Baseline Test R²: {baseline_r2:.4f}\")\n",
        "            print(f\"Baseline Test MSE: {baseline_mse:.4f}\")\n",
        "\n",
        "            # Pruning method description\n",
        "            if model_name == 'Random Forest':\n",
        "                print(\"Pruning Method: Rank-Based (keeping best performing trees)\")\n",
        "            elif model_name == 'XGBoost':\n",
        "                print(\"Pruning Method: Cumulative (early stopping based approach)\")\n",
        "\n",
        "            # Find significant degradation point\n",
        "            degradation_point = None\n",
        "            for _, row in model_data.iterrows():\n",
        "                r2_loss = (baseline_r2 - row['r2_test']) / abs(baseline_r2) if baseline_r2 != 0 else 0\n",
        "                if r2_loss > 0.05:  # 5% degradation threshold\n",
        "                    degradation_point = row['pruning_ratio']\n",
        "                    break\n",
        "\n",
        "            if degradation_point:\n",
        "                print(f\"Significant degradation starts at: {degradation_point:.1%} pruning\")\n",
        "            else:\n",
        "                print(\"No significant degradation observed within tested range\")\n",
        "\n",
        "            # Best trade-off point\n",
        "            best_tradeoff = None\n",
        "            for _, row in model_data.iterrows():\n",
        "                r2_loss = (baseline_r2 - row['r2_test']) / abs(baseline_r2) if baseline_r2 != 0 else 0\n",
        "                if r2_loss <= 0.02 and row['pruning_ratio'] > 0:\n",
        "                    best_tradeoff = row\n",
        "\n",
        "            if best_tradeoff is not None:\n",
        "                print(f\"\\nBest trade-off point:\")\n",
        "                print(f\"  Pruning ratio: {best_tradeoff['pruning_ratio']:.1%}\")\n",
        "                print(f\"  Compression: {best_tradeoff['compression_ratio']:.1f}x\")\n",
        "                print(f\"  Active components: {best_tradeoff['active_components']}/{original_components}\")\n",
        "                print(f\"  Test R²: {best_tradeoff['r2_test']:.4f}\")\n",
        "                print(f\"  Test MSE: {best_tradeoff['mse_test']:.4f}\")\n",
        "                print(f\"  R² loss: {((baseline_r2 - best_tradeoff['r2_test'])/abs(baseline_r2)*100):.1f}%\")\n",
        "\n",
        "            # Maximum compression achieved\n",
        "            max_compression = model_data['compression_ratio'].replace([np.inf, -np.inf], np.nan).max()\n",
        "            if not np.isnan(max_compression):\n",
        "                print(f\"\\nMaximum compression achieved: {max_compression:.1f}x\")\n",
        "\n",
        "        # Comparative analysis\n",
        "        print(f\"\\n{'='*100}\")\n",
        "        print(\"COMPARATIVE ANALYSIS - ENSEMBLE PRUNING METHODS\")\n",
        "        print(\"=\"*100)\n",
        "\n",
        "        summary_rows = []\n",
        "        for model_name in df['model_name'].unique():\n",
        "            model_data = df[df['model_name'] == model_name]\n",
        "            baseline = model_data[model_data['pruning_ratio'] == 0.0].iloc[0]\n",
        "\n",
        "            for target_ratio in [0.3, 0.5, 0.7, 0.9]:\n",
        "                closest = model_data.iloc[(model_data['pruning_ratio'] - target_ratio).abs().argsort()]\n",
        "                if len(closest) > 0 and abs(closest.iloc[0]['pruning_ratio'] - target_ratio) < 0.1:\n",
        "                    row = closest.iloc[0]\n",
        "                    r2_loss = ((baseline['r2_test'] - row['r2_test']) / abs(baseline['r2_test'])) * 100 if baseline['r2_test'] != 0 else 0\n",
        "                    mse_increase = ((row['mse_test'] - baseline['mse_test']) / baseline['mse_test']) * 100\n",
        "\n",
        "                    summary_rows.append({\n",
        "                        'Model': model_name,\n",
        "                        'Pruning_Ratio': f\"{target_ratio:.0%}\",\n",
        "                        'Components_Kept': f\"{row['active_components']}/{row['original_components']}\",\n",
        "                        'Compression': f\"{row['compression_ratio']:.1f}x\",\n",
        "                        'R²_Test': f\"{row['r2_test']:.4f}\",\n",
        "                        'MSE_Test': f\"{row['mse_test']:.2f}\",\n",
        "                        'R²_Loss': f\"{r2_loss:.1f}%\",\n",
        "                        'MSE_Increase': f\"{mse_increase:.1f}%\"\n",
        "                    })\n",
        "\n",
        "        if summary_rows:\n",
        "            summary_df = pd.DataFrame(summary_rows)\n",
        "            print(summary_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvLmzSLp3ven"
      },
      "outputs": [],
      "source": [
        "print(\"ENSEMBLE PRUNING ABLATION STUDY\")\n",
        "print(\"Random Forest: Rank-Based Pruning | XGBoost: Cumulative Pruning\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Initialize ensemble pruning study\n",
        "ensemble_study = EnsemblePruningAblationStudy()\n",
        "\n",
        "# Define pruning ratios\n",
        "pruning_ratios_ensemble = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
        "\n",
        "X_train_arr = X_train_enc.values\n",
        "y_train_arr = y_train.values\n",
        "X_val_arr = X_val_enc.values\n",
        "y_val_arr = y_val.values\n",
        "X_test_arr = X_test_enc.values\n",
        "y_test_arr = y_test.values\n",
        "\n",
        "# Random Forest pruning study\n",
        "if 'rf_model' in globals() or 'rf_model' in locals():\n",
        "    print(\"Found Random Forest model - Running Rank-Based pruning study...\")\n",
        "    ensemble_study.run_ensemble_pruning_study(\n",
        "        model=rf_model,\n",
        "        model_name='Random Forest',\n",
        "        X_train=X_train_arr,\n",
        "        y_train=y_train_arr,\n",
        "        X_test=X_test_arr,\n",
        "        y_test=y_test_arr,\n",
        "        X_val=X_val_arr,\n",
        "        y_val=y_val_arr,\n",
        "        pruning_ratios=pruning_ratios_ensemble\n",
        "    )\n",
        "else:\n",
        "    print(\"Random Forest model not found. Please ensure 'rf_model' is available.\")\n",
        "\n",
        "# XGBoost pruning study\n",
        "if 'xgb_model' in globals() or 'xgb_model' in locals():\n",
        "    print(\"Found XGBoost model - Running Cumulative pruning study...\")\n",
        "    ensemble_study.run_ensemble_pruning_study(\n",
        "        model=xgb_model,\n",
        "        model_name='XGBoost',\n",
        "        X_train=X_train_arr,\n",
        "        y_train=y_train_arr,\n",
        "        X_test=X_test_arr,\n",
        "        y_test=y_test_arr,\n",
        "        X_val=X_val_arr,\n",
        "        y_val=y_val_arr,\n",
        "        pruning_ratios=pruning_ratios_ensemble\n",
        "    )\n",
        "else:\n",
        "    print(\"XGBoost model not found. Please ensure 'xgb_model' is available.\")\n",
        "\n",
        "# Plot and report\n",
        "ensemble_study.plot_ensemble_pruning_results()\n",
        "ensemble_study.generate_ensemble_pruning_report()\n",
        "\n",
        "# Save results\n",
        "ensemble_results_df = pd.DataFrame(ensemble_study.ensemble_results)\n",
        "print(f\"\\nEnsemble pruning results saved with {len(ensemble_results_df)} entries\")\n",
        "print(\"\\nPruning results:\")\n",
        "display(ensemble_results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I53d9FOY2S9j",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Ablation Study Comparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S59iLrWz2U2N"
      },
      "outputs": [],
      "source": [
        "# Combined Analysis: Neural Networks vs Ensemble Methods\n",
        "def compare_all_pruning_methods():\n",
        "    \"\"\"\n",
        "    Compare pruning effectiveness across all model types\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*120)\n",
        "    print(\"COMPREHENSIVE PRUNING COMPARISON: NEURAL NETWORKS vs ENSEMBLE METHODS\")\n",
        "    print(\"=\"*120)\n",
        "\n",
        "    # Collect data from both studies\n",
        "    all_models_comparison = []\n",
        "\n",
        "    # Neural network results (if available)\n",
        "    for _, result in pruning_results_df.iterrows():\n",
        "        if result['pruning_ratio'] in [0.0, 0.3, 0.5, 0.7, 0.9]:\n",
        "            all_models_comparison.append({\n",
        "                'Model': result['model_name'],\n",
        "                'Type': 'Neural Network',\n",
        "                'Pruning_Method': 'L1 Norm',\n",
        "                'Pruning_Ratio': result['pruning_ratio'],\n",
        "                'R²_Test': result['r2_test'],\n",
        "                'MSE_Test': result['mse_test'],\n",
        "                'MAPE_Test': result['mape_test'],\n",
        "                'MAE_Test': result['mae_test'],\n",
        "                'Compression': result['compression_ratio'],\n",
        "                'Components': f\"{result['active_params']}/{result['original_params']}\"\n",
        "            })\n",
        "\n",
        "    # Ensemble results\n",
        "    for _, result in ensemble_results_df.iterrows():\n",
        "        if result['pruning_ratio'] in [0.0, 0.3, 0.5, 0.7, 0.9]:\n",
        "            pruning_method = 'Rank-Based' if result['model_name'] == 'Random Forest' else 'Cumulative'\n",
        "            all_models_comparison.append({\n",
        "                'Model': result['model_name'],\n",
        "                'Type': 'Ensemble',\n",
        "                'Pruning_Method': pruning_method,\n",
        "                'Pruning_Ratio': result['pruning_ratio'],\n",
        "                'R²_Test': result['r2_test'],\n",
        "                'MSE_Test': result['mse_test'],\n",
        "                'MAPE_Test': result['mape_test'],\n",
        "                'MAE_Test': result['mae_test'],\n",
        "                'Compression': result['compression_ratio'],\n",
        "                'Components': f\"{result['active_components']}/{result['original_components']}\"\n",
        "            })\n",
        "\n",
        "    if all_models_comparison:\n",
        "        comparison_df = pd.DataFrame(all_models_comparison)\n",
        "\n",
        "        # Create pivot table for better visualization\n",
        "        pivot_r2 = comparison_df.pivot_table(\n",
        "            values='R²_Test',\n",
        "            index=['Model', 'Type', 'Pruning_Method'],\n",
        "            columns='Pruning_Ratio',\n",
        "            fill_value=np.nan\n",
        "        )\n",
        "        pivot_mse = comparison_df.pivot_table(\n",
        "            values='MSE_Test',\n",
        "            index=['Model', 'Type', 'Pruning_Method'],\n",
        "            columns='Pruning_Ratio',\n",
        "            fill_value=np.nan\n",
        "        )\n",
        "        pivot_mape = comparison_df.pivot_table(\n",
        "            values='MAPE_Test',\n",
        "            index=['Model', 'Type', 'Pruning_Method'],\n",
        "            columns='Pruning_Ratio',\n",
        "            fill_value=np.nan\n",
        "        )\n",
        "        pivot_mae = comparison_df.pivot_table(\n",
        "            values='MAE_Test',\n",
        "            index=['Model', 'Type', 'Pruning_Method'],\n",
        "            columns='Pruning_Ratio',\n",
        "            fill_value=np.nan\n",
        "        )\n",
        "\n",
        "        print(\"\\nR² Performance Across Pruning Levels:\")\n",
        "        print(pivot_r2.round(4))\n",
        "\n",
        "        print(\"\\nMSE Performance Across Pruning Levels:\")\n",
        "        print(pivot_mse.round(4))\n",
        "\n",
        "        print(\"\\nMAPE Performance Across Pruning Levels:\")\n",
        "        print(pivot_mape.round(4))\n",
        "\n",
        "        print(\"\\nMAE Performance Across Pruning Levels:\")\n",
        "        print(pivot_mae.round(4))\n",
        "\n",
        "        pruning_levels = [0.3, 0.5, 0.7, 0.9]\n",
        "\n",
        "        print(f\"\\n{'='*120}\")\n",
        "        print(\"PERFORMANCE RETENTION AT DIFFERENT PRUNING LEVELS\")\n",
        "        print(\"=\"*120)\n",
        "\n",
        "        for pruning_level in pruning_levels:\n",
        "            print(f\"\\n{'-'*60}\")\n",
        "            print(f\"PERFORMANCE RETENTION AT {int(pruning_level*100)}% PRUNING\")\n",
        "            print(f\"{'-'*60}\")\n",
        "\n",
        "            retention_summary = []\n",
        "            for model in comparison_df['Model'].unique():\n",
        "                model_data = comparison_df[comparison_df['Model'] == model]\n",
        "                baseline = model_data[model_data['Pruning_Ratio'] == 0.0]\n",
        "                pruned = model_data[model_data['Pruning_Ratio'] == pruning_level]\n",
        "\n",
        "                if len(baseline) > 0 and len(pruned) > 0:\n",
        "                    baseline_r2 = baseline.iloc[0]['R²_Test']\n",
        "                    pruned_r2 = pruned.iloc[0]['R²_Test']\n",
        "                    retention = pruned_r2 / baseline_r2 if baseline_r2 != 0 else 0\n",
        "\n",
        "                    retention_summary.append({\n",
        "                        'Model': model,\n",
        "                        'Type': baseline.iloc[0]['Type'],\n",
        "                        'Method': baseline.iloc[0]['Pruning_Method'],\n",
        "                        'Baseline_R²': baseline_r2,\n",
        "                        'Pruned_R²': pruned_r2,\n",
        "                        'Retention': retention,\n",
        "                        'Compression': pruned.iloc[0]['Compression']\n",
        "                    })\n",
        "\n",
        "            if retention_summary:\n",
        "                retention_df = pd.DataFrame(retention_summary).sort_values('Retention', ascending=False)\n",
        "                print(retention_df.round(4))\n",
        "\n",
        "            best_model = retention_df.iloc[0]\n",
        "            print(f\"\\nBEST PRUNING METHOD AT {int(pruning_level*100)}% LEVEL:\")\n",
        "            print(f\"Model: {best_model['Model']} ({best_model['Type']})\")\n",
        "            print(f\"Method: {best_model['Method']}\")\n",
        "            print(f\"Performance Retention: {best_model['Retention']:.1%}\")\n",
        "            print(f\"Compression Achieved: {best_model['Compression']:.1f}x\")\n",
        "\n",
        "    else:\n",
        "        print(\"No pruning results available for comparison.\")\n",
        "\n",
        "# Run comprehensive comparison\n",
        "compare_all_pruning_methods()\n",
        "\n",
        "print(\"\\n\" + \"=\"*120)\n",
        "print(\"ABLATION STUDY COMPLETE\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "t2-yNkVyOo0p",
        "t-RXbQ6GTCu3",
        "1LQEB6jT7pJo",
        "vo6B5sH0Oo1A",
        "AUYVpfq6Oo1F",
        "Yl65f1wtOo1G",
        "OOiglnqCTrf7",
        "nyNK9pF4Trf7",
        "VZ0kfSVbTrf8",
        "wUySFSMoTrf9",
        "Aa8trmzvic2F",
        "_vB7ChvAv17b",
        "I53d9FOY2S9j"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
