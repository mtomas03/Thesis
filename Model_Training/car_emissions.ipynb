{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHZsdOd5Oo0n"
      },
      "source": [
        "# Previsioni delle quantità di CO<sub>2</sub> emesse da veicoli"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2-yNkVyOo0p"
      },
      "source": [
        "## Caricamento dei dati\n",
        "Per questo progetto sono stati utilizzati tre dataset differenti. <br>\n",
        "Quindi sono necessarie tre esplorazioni separate dei dati e un'omogeneizzazione dei dati, al fine di ottenere un unico dataset per l'addestramento. <br>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pykan"
      ],
      "metadata": {
        "id": "gWDykHeoOrVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soWzXv-ZniK1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import KFold, ParameterSampler, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import sklearn.metrics as metrics\n",
        "import xgboost as xgb\n",
        "\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
        "from kan import KAN\n",
        "import random\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G0GLTGzK4YK"
      },
      "outputs": [],
      "source": [
        "import os.path\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "DATASETS = {\n",
        "    \"car_emissions_spain2022.csv\": \"https://raw.githubusercontent.com/pietroolivi/dia-datasets/main/car_emissions_spain2022.csv\",\n",
        "    \"car_emissions_canada2014.csv\": \"https://raw.githubusercontent.com/pietroolivi/dia-datasets/main/car_emissions_canada2014/car_emissions_canada2014.csv\",\n",
        "    \"car_emissions_uk2013.csv\": \"https://raw.githubusercontent.com/pietroolivi/dia-datasets/main/car_emissions_uk2013.csv\"\n",
        "}\n",
        "\n",
        "for filename, dataset in DATASETS.items():\n",
        "    if not os.path.exists(filename):\n",
        "      urlretrieve(dataset, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V--ZSglqSBnO"
      },
      "outputs": [],
      "source": [
        "spain_emissions = pd.read_csv(\"car_emissions_spain2022.csv\")\n",
        "spain_emissions.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1eqQSaVSBSI"
      },
      "outputs": [],
      "source": [
        "canada_emissions = pd.read_csv(\"car_emissions_canada2014.csv\")\n",
        "canada_emissions.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeugoMUnLhQb"
      },
      "outputs": [],
      "source": [
        "uk_emissions = pd.read_csv(\"car_emissions_uk2013.csv\", low_memory=False)\n",
        "uk_emissions.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-RXbQ6GTCu3"
      },
      "source": [
        "# **Esplorazione dei singoli dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTm4gnAdOo0s"
      },
      "source": [
        "# Esplorazione del dataset `uk_emissions`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amXIdtMSOo0s"
      },
      "source": [
        "Il dataset in questione è stato reso fruibile dalla Vehicle Certification Agency (VCA) del Department for Transport britannico, al fine di reperire informazioni inerenti a tutte le vetture nuove in vendita nel Regno Unito nel lasso temporale 2000-2013, e quelle usate immatricolate per la prima volta a partire dal 1° marzo 2001. Il termine *nuova* si riferisce ad una qualsiasi automobile allora disponibile per l'acquisto o il leasing presso un concessionario e che non fosse stata precedentemente registrata. Sempre citando la [documentazione](https://www.gov.uk/co2-and-vehicle-tax-tools), abbiamo che entrambi i veicoli nuovi ed usati possono essere cercati per trovarne i corrispondenti:\n",
        "- Fuel consumption and CO<sub>2</sub> emissions (by make and model)\n",
        "- vehicle tax information (by make, model, registration date and current tax tables)\n",
        "- The cost of tax for all vehicle types\n",
        "\n",
        "Mentre sono disponibili solamente per le macchine nuove le seguenti informazioni:\n",
        "\n",
        "- Tax band, including Band A (exempt from tax)\n",
        "- Fuel economy\n",
        "- Annual fuel running costs\n",
        "- Company car taxation, based on CO<sub>2</sub> bands\n",
        "- Alternative fuel types\n",
        "\n",
        "Potremmo quindi inziare l'analisi del dataset verificando la veridicità di quest'ultimo ragguaglio, ossia controllando che le auto usate assumano valore NaN in corrispondenza delle colonne sopracitate. Sfortunatamente non disponiamo di una variabile che distingua esplicitamente i mezzi nuovi da quelli usati, ma sappiamo che le osservazioni con `date_of_change` (assumendo si riferisca alla data del passaggio di proprietà) diverso da NaN indicano una vettura sicuramente di seconda mano. Quindi sebbene queste rappresentino un sottoinsieme delle usate (mancherebbero quelle usate da un unico proprietario) eseguiamo il test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hwsVe7QOo0s"
      },
      "outputs": [],
      "source": [
        "used_cars_subset = uk_emissions.loc[~uk_emissions[\"date_of_change\"].isna()]\n",
        "columns_supposedly_nan = used_cars_subset[[\"tax_band\",\n",
        "                                           \"standard_12_months\",\n",
        "                                           \"standard_6_months\",\n",
        "                                           \"first_year_12_months\",\n",
        "                                           \"first_year_6_months\",\n",
        "                                           \"fuel_cost_12000_miles\"]]\n",
        "print(columns_supposedly_nan)\n",
        "columns_supposedly_nan.isna().all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqKLU1TeOo0t"
      },
      "source": [
        "Abbiamo appurato l'attendibilità della documentazione riguardo al valore degli attributi supposti NaN nelle auto usate. Ci rimane da esaminare l'assenza di tipi di carburante alternativi (contraddistinti dal valore _Petrol/E85(Flex Fuel)_) nella feature categorica `fuel_type` in tali osservazioni:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0VFqbUzOo0t"
      },
      "outputs": [],
      "source": [
        "used_cars_subset[\"fuel_type\"].isin([\"Petrol / E85 (Flex Fuel)\"]).any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAnzC2DuOo0t"
      },
      "source": [
        "Possiamo ritenerci soddisfatti. Sarebbe ora lecito chiedersi quali siano i marchi automobilistici più popolari nel dataset. Soddisfiamo la nostra curiosità visualizzando i primi dieci in ordine decrescente per numero di comparse in un diagramma a torta, condensando i restanti brand nello spicchio `Others` per motivi di comprensibilità."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0574FPnOo0t"
      },
      "outputs": [],
      "source": [
        "# n.b., i termini \"manufacturer\" e \"brand\" sono utilizzati come sinonimi\n",
        "print(\"[\" + str(uk_emissions[\"manufacturer\"].nunique()) \\\n",
        "      + \"] different manufacturers and [\"               \\\n",
        "      + str(uk_emissions[\"manufacturer\"].count())       \\\n",
        "      + \"] total cars are registered\")\n",
        "manufacturers = uk_emissions[\"manufacturer\"].value_counts()\n",
        "majority_brands = manufacturers[:10]\n",
        "minority_brands = manufacturers[10:]\n",
        "# oppure raggruppando i brand che rappresentano meno del 5%\n",
        "# minority_brands_perc = manufacturers[manufacturers < uk_emissions[\"manufacturer\"].count() * 5 / 100]\n",
        "majority_brands[\"Others\"] = minority_brands.sum()\n",
        "my_explode = np.append(np.zeros(majority_brands.count() - 1), 0.1)\n",
        "majority_brands.plot.pie(title = \"TOP 10 BRANDS\", explode = my_explode, shadow = True, autopct = \"%.2f%%\", figsize=(6, 6));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjUkjt3zOo0t"
      },
      "outputs": [],
      "source": [
        "print(\"OTHERS: 11th to 62nd brand in descending order of popularity:\\n\")\n",
        "percentages = minority_brands.to_numpy() * 100 / uk_emissions[\"manufacturer\"].count()\n",
        "list_of_series = [minority_brands.index.values, minority_brands.values, percentages]\n",
        "minority_df = pd.DataFrame({\"manufacturer\"  : minority_brands.index.values,\n",
        "                            \"# occurrences\" : minority_brands.values,\n",
        "                            \"percentage\"    : percentages})\n",
        "n_brands = uk_emissions[\"manufacturer\"].nunique()\n",
        "minority_df.index = range(11, n_brands + 1)\n",
        "print(minority_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NKYtFfNOo0t"
      },
      "source": [
        "Vediamo ora all'interno di ciascuno dei brand graficati in precedenza quale sia il modello con più occorrenze registrate, servendoci di un istogramma dove ci cureremo di mantenere l'ordine dei produttori secondo le percentuali dianzi calcolate, per una maggiore leggibilità."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhYQNwJ7Oo0u"
      },
      "outputs": [],
      "source": [
        "brands_and_models = uk_emissions[[\"manufacturer\", \"model\"]].copy()\n",
        "brands_and_models = brands_and_models[brands_and_models.manufacturer.isin(majority_brands.index)]\n",
        "print(\"Manufacturers left after screening: [\" + str(brands_and_models.manufacturer.nunique()) + \"]\")\n",
        "majority_brands = majority_brands.drop(\"Others\")\n",
        "brands_and_models = brands_and_models.value_counts([\"manufacturer\", \"model\"]) \\\n",
        "        .reset_index(name = \"count\")                                          \\\n",
        "        .sort_values([\"count\"], ascending = False)                            \\\n",
        "        .drop_duplicates([\"manufacturer\"])                                    \\\n",
        "        .set_index([\"manufacturer\"])                                          \\\n",
        "        .reindex(majority_brands.index) # ri-ordiniamo secondo la classifica dei brand stilata in precedenza\n",
        "brands_and_models[\"car\"] = brands_and_models.index + \"\\n\" + brands_and_models[\"model\"] # concateniamo le stringhe\n",
        "brands_and_models.plot.bar(title = \"MOST POPULAR MODEL FOR EACH OF THE TOP 10 BRANDS \", x = \"car\", y = \"count\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVC8MAZQOo0u"
      },
      "source": [
        "Rimarcherei come un marchio automobilistico possa ripetersi più volte nel dataframe per via degli ipotetici diversi modelli ad esso associati, mentre le molteplici apparizioni di uno stesso modello sono giustificate da una o più differenze di valori in variabili attinenti a specifiche tecniche quali la `engine_capacity` o il `fuel_type`. Potremmo infatti trovare, e.g., una _Ford Courier_ sia a benzina (petrol) con cilindrata (engine_capacity) di 1299 cm<sup>3</sup> che a diesel con cilndrata di 1753 cm<sup>3</sup>. Andiamo ad estrarre qualche insight, facendo attenzione a non assumere che non vi possano essere modelli omonimi tra brand diversi (contando quindi i valori unici in coppia con il relativo brand). Di seguito ignoreremo le le differenze di trasmissione."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i87neem1Oo0u"
      },
      "outputs": [],
      "source": [
        "n_cars = len(uk_emissions[[\"manufacturer\", \"model\", \"description\"]].copy().drop_duplicates())\n",
        "n_models = len(uk_emissions[[\"manufacturer\", \"model\"]].copy().drop_duplicates())\n",
        "n_brands = len(uk_emissions[[\"manufacturer\"]].copy().drop_duplicates())\n",
        "print(\"Average number of engine variants per model: [{:.2f}]\".format(n_cars / n_models))\n",
        "print(\"Average number of models per manufacturer:  [{:.2f}]\".format(n_models / n_brands))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF-ocdbDOo0u"
      },
      "source": [
        "Indaghiamo la relazione tra la classi dello [Standard europeo sulle emissioni inquinanti](https://en.wikipedia.org/wiki/European_emission_standards) e lo sprigionamento di CO delle vetture, per mezzo di un diagramma a scatola e baffi. Osserviamo come le medie dei box siano ordinate. La presenza di outliers, assieme al fatto che uno stesso range di valori di monossido di carbonio possa appartenere a più classi, sono chiari indicatori di come il CO non sia, ragionevolmente, l'unico inquinante tenuto in considerazione per determinare l'appartenenza ad una certa categoria `euro_standard`. Com'è infatti possibile verificare nella pagina a cui rinvia l'hyperlink, THC, NMHC, NH<sub>3</sub> e NO<sub>x</sub> sono alcuni tra gli altri composti valutati."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYJMLeACOo0u"
      },
      "outputs": [],
      "source": [
        "quartiles_first = uk_emissions.boxplot(column = \"co_emissions\", by = \"euro_standard\", showmeans = True);\n",
        "quartiles_first.set_ylabel(\"co_emissions\");\n",
        "quartiles_first.set_title(\"\");\n",
        "plt.ylim(0, 2500);\n",
        "plt.suptitle(\"\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpYhjw_HOo0u"
      },
      "source": [
        "Similmente a quanto fatto sopra andiamo, attraverso un diagramma degli estremi e dei quartili, ad analizzare l'eventuale legame tra `tax_band` e `co2_emissions`. Questa volta notiamo tuttavia come il valore massimo di diossido di carbonio (in g/km) di una certa fascia corrisponda al minimo di quella successiva. In effetti, come riportato nella [guida](https://assets.publishing.service.gov.uk/media/6603f64b13397a0011e419be/v149-rates-of-vehicle-tax-for-cars-motorcycles-light-goods-vehicles-and-private-light-goods-vehicles.pdf) redatta dalla Driver and Vehicle Licensing Agency (DVLA), la CO<sub>2</sub> risulterebbe essere, assieme al `fuel_type`, l'unico elemento considerato nel decretare gli scaglioni di tasse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAPGNmnuOo0v"
      },
      "outputs": [],
      "source": [
        "quartiles_second = uk_emissions.boxplot(column = \"co2\", by = \"tax_band\", showmeans=True, figsize = (10, 16));\n",
        "quartiles_second.set_ylabel(\"co2_emissions\");\n",
        "quartiles_second.set_title(\"\");\n",
        "plt.suptitle(\"\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYbenazWOo0v"
      },
      "source": [
        "Concludiamo l'esplorazione di questo dataset con un grafico a dispersione che leghi l'`engine_capacity` (volume del motore in cm<sup>3</sup>) di ciascuna vettura con i relativi `combined_metric` (consumi in l/100km). Come ci aspettavamo, in linea di massima, al crescere del primo aumenta anche il secondo ed il trend potrebbe, come suggerisce anche l'indice di correlazione di Pearson tra le due colonne, essere approssimato in maniera soddisfacente da una retta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRjBuptIOo0v"
      },
      "outputs": [],
      "source": [
        "uk_emissions.plot.scatter(\"engine_capacity\", \"combined_metric\", s=7, c=\"red\");\n",
        "print(\"Pearson correlation coefficient: [{:.2f}]\".format(uk_emissions[\"engine_capacity\"].corr(uk_emissions[\"combined_metric\"])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4ytHD44Vng_",
        "tags": []
      },
      "source": [
        "# Esplorazione del dataset `spain_emissions`\n",
        "### Rimozione delle righe riguardanti veicoli elettrici\n",
        "\n",
        "All'interno del dataset proveniente dal ministero spagnolo sono presenti anche dati riguardanti macchine elettriche. Questa tipologia di dato non è interessante per l'obiettivo del modello, ovvero la quantità di CO<sub>2</sub> emessa.\n",
        "\n",
        "La cella seguente analizza i valori delle righe che hanno `engine_type` \"Eléctricos puros\", estraendo solo le colonne sul minimo e massimo di consumo di litri di carburante e sul minimo e massimo di emissioni di CO<sub>2</sub> per km percorso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dBbENl8YDCh"
      },
      "outputs": [],
      "source": [
        "columns = [\"emissions_min_gCO2_km\", \"emissions_max_gCO2_km\"]\n",
        "spain_emissions.loc[spain_emissions[\"engine_type\"] == \"Eléctricos puros\", columns].isna().all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm9sZvHQZPNm"
      },
      "source": [
        "Come era previdibile, tutti i valori delle emissioni di CO<sub>2</sub> per km nelle righe riguardanti i veicoli elettrici sono mancanti, quindi le rispettive righe possono essere eliminate, poichè non utili per l'addestramento del modello, il cui obiettivo è la previsione dell'emissione di CO<sub>2</sub> per veicoli a motore termico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2z_hiy2aFIx"
      },
      "outputs": [],
      "source": [
        "electric_cars_index = spain_emissions.loc[spain_emissions[\"engine_type\"] == \"Eléctricos puros\"].index\n",
        "spain_emissions = spain_emissions.drop(electric_cars_index)\n",
        "spain_emissions[\"engine_type\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNuiQXUhOo0v"
      },
      "source": [
        "\n",
        "Come si può notare dall'output della cella precedente, la colonna `engine_type` non contiene il valore \"Eléctricos puros\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o55p1KJtOo0w"
      },
      "source": [
        "### Rimozione delle colonne contenenti solo valori `NaN`\n",
        "Nel dataset dell'emissioni di CO<sub>2</sub> proveniente dalla Spagna la colonne `type_hybrid`, `electric_consumption_kwh_100km`, `battery_capacity_kwh ` contengono solo valori `NaN`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08Up5_wkOo0w"
      },
      "outputs": [],
      "source": [
        "all_nan_columns = [\"type_hybrid\", \"electric_consumption_kwh_100km\", \"battery_capacity_kwh\"]\n",
        "spain_emissions[all_nan_columns].isna().values.all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hFP7Xz9Oo0w"
      },
      "outputs": [],
      "source": [
        "spain_emissions = spain_emissions.drop(all_nan_columns, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boGfbrNrOo0w"
      },
      "source": [
        "### Rimozione delle righe senza un valore valido di trasmissione\n",
        "La colonna `transmission` contiene il tipo di trasmissione del veicolo, quindi la modalità di cambio della marcia, se automatica o manuale, che nella colonna sono rispettivamente \"A\" e \"M\". L'output della prossima cella mostra che sono presenti 35 righe con valori di trasmissioni non validi, poichè nel dataset spagnolo \"SC\" sta per \"Sin clasificasion\", ovvero non classificato. Perciò le righe con valori di trasmissione non validi, essendo un numero molto ridotto, verrano eliminate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-g3B3B7kOo0w"
      },
      "outputs": [],
      "source": [
        "spain_emissions[\"transmission\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqnay60eOo0w"
      },
      "outputs": [],
      "source": [
        "valid_transmissions = spain_emissions[\"transmission\"].isin([\"A\", \"M\"])\n",
        "spain_emissions[\"transmission\"] =  spain_emissions.loc[valid_transmissions, \"transmission\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "1ERHBFS0Oo00"
      },
      "source": [
        "# Esplorazione del dataset `canada_emissions`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "57K0_N3aOo00"
      },
      "source": [
        "### Gestione dimensioni motore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ0ZcdDSOo00"
      },
      "source": [
        "All'interno del dataset proveniente dal ministero canadese sono presenti le dimensioni in L (Litri) del motore dei vari veicoli. Decidiamo di trasformarle in cm$^3$ rinominando quindi la feature Engine_cm3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oup7GfbHOo01"
      },
      "outputs": [],
      "source": [
        "canada_emissions = canada_emissions.rename(columns={\"Engine size (L)\": \"Engine_cm3\"})\n",
        "canada_emissions[\"Engine_cm3\"] = canada_emissions[\"Engine_cm3\"] * 1000\n",
        "canada_emissions.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "_FElap24Oo01"
      },
      "source": [
        "### Trattamento valori mancanti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uutRF7HNOo01"
      },
      "source": [
        "Con la cella seguente verifico se il dataset contiene dei dati mancanti (nan)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLOT__jSOo01"
      },
      "outputs": [],
      "source": [
        "canada_emissions.isna().values.any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ZD6_igOo01"
      },
      "source": [
        "Visto che il risultato è false non c'è alcun valore mancante da gestire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "B2RKQBd4Oo01"
      },
      "source": [
        "### Grafici\n",
        "Questa sezione contiene alcuni grafici che evidenziano alcuni aspetti del dataframe `canada_emissions`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLJ--h89Oo01"
      },
      "source": [
        "L'istogramma seguente mostra la distribuzione delle emissioni di CO$_2$ nel dataframe canadese. I valori si concentrano principalmente nell'intervallo [150,350]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDj2ZX6iOo01"
      },
      "outputs": [],
      "source": [
        "canada_emissions[\"CO2 emissions (g/km)\"].plot.hist(bins=20,title=\"CO\\u2082 emissions distribution\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-D2LWmvOo01"
      },
      "source": [
        "L'istogramma seguente mostra le dimensioni dei motori dei vari veicoli nel dataframe canadese. I valori si concentrano principalmente nell'intervallo [1500,6000]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuCbWDz4Oo02"
      },
      "outputs": [],
      "source": [
        "canada_emissions[\"Engine_cm3\"].plot.hist(bins=20,title=\"Engine size\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxyB5EAPOo02"
      },
      "source": [
        "Il seguente grafico a torta mostra il numero di cilindri (in percentuale) dei vari veicoli nel dataframe canadese. La maggior parte di essi ha 6 cilindri."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L688ujZAOo02"
      },
      "outputs": [],
      "source": [
        "canada_emissions[\"Cylinders\"].value_counts().plot.pie(title=\"Cylinders number\" , shadow=True, figsize=(6,6), labels=None)\n",
        "labels = [str(cylinder) + \" cylinders\" for cylinder in canada_emissions[\"Cylinders\"].value_counts().index]\n",
        "plt.legend(labels);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRjBn9caOo02"
      },
      "source": [
        "Il seguente grafico a barre mostra i vari tipi di veicoli presenti nel dataset canadese con la relativa frequenza."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucKXZGT0Oo02"
      },
      "outputs": [],
      "source": [
        "canada_vehicle_class = canada_emissions[\"Vehicle class\"].value_counts()\n",
        "plt.bar(canada_vehicle_class.index, canada_vehicle_class.values)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.title(\"Vehicle class\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LQEB6jT7pJo"
      },
      "source": [
        "# **Omogeneizzazione ed unione dei dati**\n",
        "Avendo reperito tre set di dati ciascuno da una fonte differente, sebbene questi concernano il medesimo dominio e condividano pertanto una considerevole quantità di attributi, potremmo essere erroneamente portati a compiere un troncamento delle colonne, conservando esclusivamente quelle appartenenti all'intersezione delle tre tabelle, tuttavia così facendo andremmo a trascurare il caso-limite in cui le features eliminate dovessero essere le uniche legate, attraverso un relazione non randomica, a quella indagata. Una soluzione più scrupolosa consisterebbe, al contrario, nell'**unione** degli **attributi**, colmando opportunamente le celle vuote formatesi. In effetti, come visto a lezione, i valori NAN possono essere sostituiti, tra gli altri, da (a seconda che le colonne siano di tipo categorico o numerico):\n",
        "- media\n",
        "- moda\n",
        "- mediana\n",
        "\n",
        "Questo ragionamento va ad ogni modo applicato nei limiti del ragionevole: se una variabile dovesse essere presente solamente in uno dei tre dataset, sarebbe piuttosto fuorviante \"inventare\" i 2/3  dei valori da essa assunti (ipotizzando i dataset di egual dimensione). Decidiamo quindi di mantenere le colonne presenti in almeno due dataset su tre. In aggiunta, le stesse variabili in comune, malgrado facciano riferimento allo stesso concetto, si manifestano saltuariamente sotto denominazioni diverse, ed a loro volta i valori da queste assunti potrebbero avere formato dissimile (e.g. capitalizzazione delle lettere nel caso testuale o numero di cifre significative in quello numerico).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL4XLfx-Oo02"
      },
      "source": [
        "## Omogeneizzazione di `uk_emissions`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhT4DqRHOo03"
      },
      "source": [
        "Rimuoviamo le colonne proprie di questo dataset, per moderare la presenza di NaN o dati sostitutivi in quello risultante dall'unione:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQOZ1qaYOo03"
      },
      "outputs": [],
      "source": [
        "uk_emissions = uk_emissions.drop(columns = [\"file\", \"description\", \"euro_standard\", \"tax_band\", \"transmission\", \"urban_metric\",\n",
        "                                            \"extra_urban_metric\", \"urban_imperial\", \"extra_urban_imperial\", \"combined_imperial\",\n",
        "                                            \"noise_level\", \"thc_emissions\", \"co_emissions\", \"nox_emissions\", \"thc_nox_emissions\",\n",
        "                                            \"particulates_emissions\", \"fuel_cost_12000_miles\", \"fuel_cost_6000_miles\", \"standard_12_months\",\n",
        "                                            \"standard_6_months\", \"first_year_12_months\", \"first_year_6_months\", \"date_of_change\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_8OAkEOOo03"
      },
      "source": [
        "Trasformiamo i nomi delle variabili in quelli concordati con gli altri componenti del gruppo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgV8XA7eOo03"
      },
      "outputs": [],
      "source": [
        "uk_emissions.columns = uk_emissions.columns.str.capitalize()\n",
        "uk_emissions.rename(columns = {\"Engine_capacity\" : \"Engine_cm3\",\n",
        "                               \"Combined_metric\" : \"Fuel_consumption\",\n",
        "                               \"Co2\" : \"CO2_Emissions\"}, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4kvU0mLOo03"
      },
      "source": [
        "Ci troviamo ora dinnanzi ad una delle principali complicazioni indotte dall'utilizzo di più dataset. L'obbiettivo sarebbe quello di manipolare i nomi delle vetture in modo tale da garantire la consistenza semantica del dataset finale: non vorremmo che, e.g., le automobili _BMW 3 Series_ e _Bmw Series 3_ siano considerate differenti, perlomeno sugli attributi `Manufacturer`e `Model`, anche per consentire all'algoritmo di machine learning di trarre conclusioni rispetto al modello specifico. Il problema non si pone per variabili numeriche come i consumi o la cilindrata, dove siamo interessati più al range di appartenenza piuttosto che ai valori precisi. Vista la mancanza di un pattern universale e siccome risulterebbe eccessivamente gravoso indagare tutte le ~90'000 osservazioni, ci limiteremo ad uniformare quantomeno un campione di automobili analizzato."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMbZukvvOo03"
      },
      "outputs": [],
      "source": [
        "uk_emissions.dropna(inplace = True)\n",
        "uk_emissions[\"Model\"] = uk_emissions[\"Model\"].replace(\"[\\(\\[].*?[\\)\\]]\", \"\", regex = True)\n",
        "uk_emissions[\"Model\"] = uk_emissions.apply(lambda row : row[\"Model\"].replace(str(row[\"Manufacturer\"]), ''), axis=1)\n",
        "uk_emissions[\"Model\"] = uk_emissions[\"Model\"].str.split(\" \").str[0].str.replace(\",\", \"\")\n",
        "uk_emissions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuiMr8EpOo03"
      },
      "source": [
        "## Omogeneizzazione di `spain_emissions`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "d6DB5TuYOo03"
      },
      "source": [
        "### Traduzione spagnolo-inglese\n",
        "Il dataset proveniente dalla Spagna contiene due colonne in spagnolo, `engine_type` e `market_segment`. Quindi è necessaria una traduzione dallo spagnolo all'inglese per entrambe le colonne, così da adattarle agli altri due dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABlBvHjAOo04"
      },
      "source": [
        "Definisco una funzione per sostituire i valori di una colonna di un dataframe con dei nuovi valori passati come argomento, in questo caso la rispettiva traduzione in inglese, tramite una funzione di mapping fornita da pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP7tT8pZOo04"
      },
      "outputs": [],
      "source": [
        "def get_column_mapped_values(column, new_values):\n",
        "    mapping = dict(zip(column.unique(), new_values))\n",
        "    return column.map(mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fQGsCaNOo04"
      },
      "outputs": [],
      "source": [
        "#Traduzione della colonna engine_type\n",
        "spanish_engine_type = spain_emissions[\"engine_type\"].unique()\n",
        "english_engine_type = [\"Petrol\", \"Diesel\", \"Plug-in hybrid\", \"Petrol hybrid\", \"Natural gas\",\n",
        "                       \"Diesel Hybrid\", \"Liquefied petroleum gas(LPG)\", \"Fuel cell\", \"Extended range\"]\n",
        "\n",
        "spain_emissions[\"engine_type\"] = get_column_mapped_values(spain_emissions[\"engine_type\"], english_engine_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dsKmIqCOo04"
      },
      "source": [
        "Per la traduzione della colonna `market_segment` si fa riferimento al dataset canadese, il quale contiene una colonna per la classificazione dei veicoli, `Vehicle class`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GeAZDvfOo04"
      },
      "outputs": [],
      "source": [
        "canada_emissions[\"Vehicle class\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxQEEtJMOo04"
      },
      "outputs": [],
      "source": [
        "#Traduzione della colonna market_segment\n",
        "english_market_segment = [\"Minicompact\", \"Compact\", \"Small off-road\", \"Mid-size\", \"Sport utility vehicle\", \"Full-size\",\n",
        "                          \"Mid-size off-road\", \"Full-size off-road\", \"Minivan\", \"Luxury\", \"Minivan\", \"Van: Passenger\"] \\\n",
        "                        + ([\"Van: Cargo\"] * 2) + ([\"Lorry\"] * 7)\n",
        "\n",
        "spain_emissions[\"market_segment\"] = get_column_mapped_values(spain_emissions[\"market_segment\"], english_market_segment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVg-6t3bOo05"
      },
      "source": [
        "### Calcolo medie del consumo di carburante e delle emissioni di CO<sub>2</sub>\n",
        "Sia per il consumo di carburante che per le emissioni di CO<sub>2</sub> sono presenti i valori di minimo, di massimo e la media\n",
        "WLTP (<i>Worldwide harmonized Light vehicles Test Procedure</i>), ovvero le misure ottenute dal test standard a livello mondiale per il controllo delle emissioni e dei consumi dei veicoli.\n",
        "Da questi tre valori ne verrà calcolata la media così da avere una sola colonna per i consumi di carburante e una sola colonna per i consumi di CO<sub>2</sub>, la variabile target da predire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSO4Ibj6Oo05"
      },
      "source": [
        "Prima di poter precedere è necessario controllare che in tutte le righe del dataframe sia presente almeno uno dei tre valori richiesti e che sia diverso da 0, sia per calcolare la media del consumo che delle emissioni.\n",
        "<br>Nella cella successiva si può vedere esattamente in quante righe sono mancanti questi valori necessari."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ugu2rhoOo05"
      },
      "outputs": [],
      "source": [
        "def isnaOrIsZero(dataframe):\n",
        "    return dataframe.isna() | dataframe.eq(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5rxPNZkOo05"
      },
      "outputs": [],
      "source": [
        "consumption_columns = [\"consumption_min_l_100km\", \"consumption_max_l_100km\", \"avg_wltp_consumption_l_100km\"]\n",
        "emissions_columns = [\"emissions_min_gCO2_km\", \"emissions_max_gCO2_km\", \"avg_wltp_emissions_gCO2_km\"]\n",
        "\n",
        "rows_no_consumption = isnaOrIsZero(spain_emissions[consumption_columns]).all(axis=1)\n",
        "number_rows_missing_consumption = rows_no_consumption.sum()\n",
        "print(\"Rows with no consumption_l_100km:\", number_rows_missing_consumption)\n",
        "\n",
        "rows_no_emissions = isnaOrIsZero(spain_emissions[emissions_columns]).all(axis=1)\n",
        "number_rows_missing_emissions = rows_no_emissions.sum()\n",
        "print(\"Rows with no emissions_gCO2_km:\", number_rows_missing_emissions)\n",
        "\n",
        "rows_no_emissions_consumptions = (rows_no_consumption & rows_no_emissions)\n",
        "number_rows_missing_emissions_consumptions = rows_no_emissions_consumptions.sum()\n",
        "print(\"Rows with no emissions_gCO2_km and no consumption_l_km:\", number_rows_missing_emissions_consumptions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYJfR_TgOo06"
      },
      "source": [
        "Come riportato nell'output della cella precedente, ci sono <strong>1560</strong> righe senza alcun valore di consumo di carburante, <strong>1562</strong> righe senza alcun valore di emissioni di CO<sub>2</sub> e <strong>1560</strong> in cui è assente sia il consumo di carburante che le emissioni di CO<sub>2</sub>. <br>\n",
        "Nella cella successiva vengono calcolate le medie di carburante ed emissioni di ciascuna riga e vengono inserite in due nuove colonne `consumption_l_100km`, `emissions_gCO2_km`. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC5T5vQbOo06"
      },
      "outputs": [],
      "source": [
        "mean_consumption = \"consumption_l_100km\"\n",
        "mean_emissions = \"emissions_gCO2_km\"\n",
        "spain_emissions[mean_consumption] = spain_emissions[consumption_columns].mean(axis=1)\n",
        "spain_emissions[mean_emissions] = spain_emissions[emissions_columns].mean(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI9Ura_nOo06"
      },
      "outputs": [],
      "source": [
        "spain_emissions = spain_emissions.drop(consumption_columns + emissions_columns, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjzhUqA-Oo07"
      },
      "source": [
        "Quindi vengono sostituiti i valori mancanti e i valori posti a 0, poichè considerati anch'essi mancanti, siccome le categorie di veicoli considerate dovrebbero presentare dei consumi di carburante e delle emissioni di CO<sub>2</sub> positivi. <br>\n",
        "La cella successiva mostra le categorie di veicoli in cui sono assenti sia i consumi di carburante che le emissioni. Le due categorie con più occorrenze sono i \"Van: Cargo\" e \"Lorry\", due mezzi molto pesanti e con valori differenti rispetto ad altre categorie, quindi sarebbe più corretto riempire i valori assenti o posti a 0, con i mediani delle due rispettive categorie. Mentre per le restanti categorie si può utilizzare direttamente il mediano di tutta la colonna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zcfxz-9_Oo07"
      },
      "outputs": [],
      "source": [
        "most_missing_market_segments = spain_emissions.loc[rows_no_emissions_consumptions, \"market_segment\"].value_counts()[:5]\n",
        "most_missing_market_segments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHsboYlxOo07"
      },
      "source": [
        "Le celle successive evidenziano la necessità di usare, come valore per riempire i valori NaN o posti a 0 delle categorie di veicoli \"Van: Cargo\" e \"Lorry\", i rispettivi mediani, anzichè usare direttamente il mediano di tutta la colonna, vista l'ampia differenza causata dalla presenza di veicoli di diverse dimensioni e consumi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KEcetpDOo07"
      },
      "outputs": [],
      "source": [
        "columns = [mean_consumption, mean_emissions]\n",
        "market_segments = [\"Van: Cargo\", \"Lorry\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaCCoSGROo08"
      },
      "outputs": [],
      "source": [
        "all_median = pd.DataFrame(spain_emissions[columns].median(), columns = [\"All\"]).T\n",
        "van_cargo_lorries = spain_emissions.loc[spain_emissions[\"market_segment\"].isin(market_segments), [\"market_segment\"] + columns]\n",
        "van_cargo_lorries_median = van_cargo_lorries[van_cargo_lorries.ne(0)].groupby(\"market_segment\").median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxZ-kF83Oo08"
      },
      "outputs": [],
      "source": [
        "pd.concat([all_median, van_cargo_lorries_median]).style.set_caption(\"Market segments medians\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RsTV5XbOo08"
      },
      "outputs": [],
      "source": [
        "def fillnaZeroes(market_segment, columns):\n",
        "    vehicles = spain_emissions.loc[spain_emissions[\"market_segment\"] == market_segment, columns].replace(0, np.nan)\n",
        "    vehicles = vehicles.fillna(vehicles.median())\n",
        "    return vehicles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGTEfQkLOo08"
      },
      "outputs": [],
      "source": [
        "for market_segment in market_segments:\n",
        "    spain_emissions.loc[spain_emissions[\"market_segment\"] == market_segment, columns] = fillnaZeroes(market_segment, columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyCFN7nnOo08"
      },
      "outputs": [],
      "source": [
        "other_market_segments = set(spain_emissions[\"market_segment\"].unique()) - set(market_segments)\n",
        "spain_emissions[columns] = spain_emissions[columns].replace(0, np.nan).fillna(spain_emissions[columns].median())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiGs11JcOo08"
      },
      "source": [
        "### Utilizzo di valori espliciti per il tipo di trasmissione\n",
        "Il dataset spagnolo per indicare la tipologia di trasmissione utilizza solamente \"A\" e \"M\". Per adattarlo agli altri dataset e per renderlo più chiaro si è deciso di mappare i rispettivi valori con la versione estesa, ovvero \"Automatic\", \"Manual\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUc6aLrvOo09"
      },
      "outputs": [],
      "source": [
        "renaming_dict = {\"A\": \"Automatic\", \"M\": \"Manual\"}\n",
        "spain_emissions[\"transmission\"] = spain_emissions[\"transmission\"].map(renaming_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvrReqjZOo09"
      },
      "source": [
        "### Inserimento dell'anno del modello del veicolo\n",
        "I dataset canadesi e britannici presentano entrambi una colonna per l'anno del modello(`Model year` in `canada_emissions` e `year` in `uk_emissions`), una feature che può essere importante per la predezioni delle emissioni prodotte. Quindi a partire dagli altri due dataset, viene estratta la colonna dell'anno."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eJTH1qzOo09"
      },
      "source": [
        "Prima di procedere all'inserimento è necessario un adattamento della colonna `model`, poichè nel dataset `spain_emissions` ciascun valore è formato dal nome della casa automobilistica, ovvero il valore della colonna `make`, dal nome effettivo del modello e da altre informazioni aggiuntive sul modello. Quindi, si procede all'eliminazione della casa automobilistica e delle informazioni aggiuntive per adattarlo alla colonna del modello degli altri due dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9gsPU6jOo09"
      },
      "source": [
        "La prossime due celle rimuovono suffissi non presenti negli altri due dataset, eliminando le parole contenute nella variabile locale `useless_words`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XwbVr9fOo09"
      },
      "outputs": [],
      "source": [
        "useless_words = {\"Canarias\", \"Vehículos\", \"Turismos\", \"Comerciales\", \"Nuevo\", \"NUEVO\", \"Turismos\"}\n",
        "# Per rimuovere suffissi fuorvianti, non presenti negli altri dataset, nei nomi delle case automobilistiche\n",
        "def remove_useless_suffix(make):\n",
        "    make_words = make.split()\n",
        "    make_words = set(make_words) - useless_words\n",
        "    return \" \".join(make_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYT-oHzEOo09"
      },
      "outputs": [],
      "source": [
        "spain_emissions[\"make\"] = spain_emissions[\"make\"].apply(remove_useless_suffix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpy4TQoAOo09"
      },
      "source": [
        "Di seguito, l'adattamento del nome del modello eliminando la casa automobilistica e le informazioni aggiuntive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGbZUNDpOo09"
      },
      "outputs": [],
      "source": [
        "# Per rimuovere il nome della casa automobilistica e le informazioni aggiuntive dal nome del modello\n",
        "def remove_manufacturer_and_addional_info(make_model):\n",
        "    make = make_model[\"make\"]\n",
        "    model = make_model[\"model\"]\n",
        "    removedManufacturer = model.replace(make, \"\").split()\n",
        "    model = [word for word in removedManufacturer if word not in useless_words][0]\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dB56vfGOo09"
      },
      "outputs": [],
      "source": [
        "spain_emissions[\"model\"] = spain_emissions[[\"make\", \"model\"]].apply(remove_manufacturer_and_addional_info, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CibwxyfXOo09"
      },
      "source": [
        "Dopo l'adattamento del nome della casa automobilistica e del nome del modello del veicolo, si può procedere all'effettivo inserimento dell'anno in base ai valori dell'anno nei dataset `uk_emissions` e `canada_emissions`. I valori dell'anno che risultano non presenti a seguito del join con `uk_emissions` verranno prelevati dal secondo dataset `canada_emissions`. In caso dei valori risultassero ancora mancanti, tali righe verranno scartate dal dataset, poichè prive di un'informazione rilevante ai fini dell'addestramento del modello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUxEM-dfOo0-"
      },
      "outputs": [],
      "source": [
        "spain_emissions = (\n",
        "    pd.merge(\n",
        "        spain_emissions,\n",
        "        uk_emissions[[\"Manufacturer\", \"Model\", \"Year\"]],\n",
        "        how = \"left\",\n",
        "        left_on = [\"make\", \"model\"],\n",
        "        right_on =  [\"Manufacturer\", \"Model\"]\n",
        "    )\n",
        "    .drop_duplicates()\n",
        ")[list(spain_emissions.columns) + [\"Year\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1s_AZFuOo0-"
      },
      "outputs": [],
      "source": [
        "spain_emissions_year_na = spain_emissions[spain_emissions[\"Year\"].isna()].drop(\"Year\", axis=1)\n",
        "spain_emissions_year_canada = (\n",
        "    pd.merge(\n",
        "        spain_emissions_year_na,\n",
        "        canada_emissions[[\"Make\", \"Model\", \"Model year\"]],\n",
        "        how = \"left\",\n",
        "        left_on = [\"make\", \"model\"],\n",
        "        right_on =  [\"Make\", \"Model\"]\n",
        "    )\n",
        "    .drop_duplicates()\n",
        "    .rename(columns = {\"Model year\": \"Year\"})\n",
        ")[list(spain_emissions.columns)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8qt966rOo0-"
      },
      "source": [
        "La cella a seguire inserisce i valori dell'anno ottenuti dal join con `canada_emissions` al posto dei valori mancanti a seguito del join con `uk_emissions`. Infine, le righe in cui la colonna `year` risulta ancora mancante dopo i due join verranno scartate.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgiwX1ITOo0-"
      },
      "outputs": [],
      "source": [
        "spain_emissions[\"Year\"] = spain_emissions[\"Year\"].fillna(spain_emissions_year_canada[\"Year\"])\n",
        "spain_emissions = spain_emissions.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ4A1fl_Oo0-"
      },
      "source": [
        "### Grafici di `spain_emissions`\n",
        "Questa sezione contiene alcuni grafici che evidenziano alcuni aspetti del dataframe risultante `spain_emissions`.value_countsunique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOBOJftmOo0-"
      },
      "source": [
        "L'istogramma seguente mostra la distribuzione delle emissioni di CO<sub>2</sub> nel dataset spagnolo. I valori si concentrano principalmente nell'intervallo [100, 200]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og-EKmVyOo0-"
      },
      "outputs": [],
      "source": [
        "spain_emissions[\"emissions_gCO2_km\"].plot.hist(bins=20,title=\"CO\\u2082 emissions distribution\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbDfdnCLOo0-"
      },
      "source": [
        "Il seguente grafico mostra la correlazione tra il consumo di carburante e le emissioni di CO<sub>2</sub>. Si evince che esiste una dipendenza tra i due valori, fatta eccezione per alcuni punti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_vTAN-ROo0_"
      },
      "outputs": [],
      "source": [
        "spain_emissions.plot.scatter(\"consumption_l_100km\", \"emissions_gCO2_km\", title=\"Fuel consumption and CO\\u2082 emissions correlation\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYrm_C8JOo0_"
      },
      "source": [
        "Nel grafico a torta è rappresentata la distribuzione delle categorie di veicoli. Una metà è occupata da sole 4 categorie, mentre le altre 8 si spartiscono il restante 50%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAWSXomjOo0_"
      },
      "outputs": [],
      "source": [
        "spain_emissions[\"market_segment\"].value_counts()[:-1].plot.pie(autopct=\"%.2f%%\", title=\"Market segments distribution\", shadow=True, label=\"\", figsize=(10,10));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKPiXXCWOo0_"
      },
      "source": [
        "Nel seguente grafico è mostrata la relazione tra ciascuna categoria di veicoli e le emissioni di CO<sub>2</sub> corrispondenti. Sono presenti molti outlier sia nella parte inferiore che nella parte superiore di ciascun boxplot. Si può notare come i le medie dei valori di veicoli più pesanti e più inquinanti come \"Lorry\", \"Van: Cargo\" e \"Luxury\" siano molto più alti delle medie dei valori corrispondenti ai veicoli più leggeri e meno inquinanti come \"Compact\", \"Minicompact\" e \"Mid-size\". Questa osservazione è vera solo per le medie e i mediani, siccome i valori di ciascun boxplot coprono una buona parte dell'asse y, quindi alcuni veicoli \"Compact\" hanno valori più alti di alcuni \"Lorry\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1KCi4KBOo0_"
      },
      "outputs": [],
      "source": [
        "spain_emissions.boxplot(column=\"emissions_gCO2_km\", by=\"market_segment\", showmeans=True, figsize=(18, 6)).set_title(\"CO\\u2082 emissions grouped by market segment\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-9wNyXxOo0_"
      },
      "source": [
        "Mentre nel grafico successivo vengono mostrati gli stessi valori, ma in relazione alla tipologia di motore. Quasi tutti boxplot hanno i valori di media e mediana che si assestano tra 150 e 200, presentando però anche in questo caso molti outlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOOr3jYzOo0_"
      },
      "outputs": [],
      "source": [
        "spain_emissions.boxplot(column=\"emissions_gCO2_km\", by=\"engine_type\", showmeans=True, figsize=(18, 6)).set_title(\"CO\\u2082 emissions grouped by market engine type\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVXbZ5OdOo0_"
      },
      "source": [
        "### Scelta delle colonne di `spain_emissions` per l'addestramento\n",
        "Questa ultima parte dell'omogeneizzazione di `spain_emissions` seleziona solo le colonne utilizzate nell'addestramento rinominandole e facendo le ultime modifiche ai valori delle colonne, in modo da utilizzare uno standard comune agli altri dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fj6WOV6uOo1A"
      },
      "outputs": [],
      "source": [
        "old_columns = [\"Year\", \"make\", \"model\", \"engine_displacement_cm3\", \"consumption_l_100km\", \"engine_type\", \"emissions_gCO2_km\", \"transmission\"]\n",
        "new_columns = [\"Year\", \"Manufacturer\", \"Model\", \"Engine_cm3\", \"Fuel_consumption\", \"Fuel_type\", \"CO2_Emissions\", \"Transmission_type\"]\n",
        "columns_dict = dict(zip(old_columns, new_columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohb0w1_MOo1A"
      },
      "outputs": [],
      "source": [
        "spain_emissions = spain_emissions[old_columns].rename(columns = columns_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE39I7-pOo1A"
      },
      "source": [
        "Da questo punto in poi, Liquefied Petroleum Gas (LPG) verrà semplicemente sostituito con LPG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn6zr5VKOo1A"
      },
      "outputs": [],
      "source": [
        "spain_emissions[\"Fuel_type\"] = spain_emissions[\"Fuel_type\"].replace(\"Liquefied petroleum gas(LPG)\", \"LPG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "vo6B5sH0Oo1A"
      },
      "source": [
        "# **Omogeneizzazione di `canada_emissions`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-DdF007Oo1A"
      },
      "source": [
        "### Gestione tipi di carburante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7NgR5oYOo1A"
      },
      "source": [
        "All'interno del dataset proveniente dal ministero canadese sono presenti dati riguardanti il tipo di carburante (colonna \"Fuel type\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-FGFjBEOo1A"
      },
      "source": [
        "La cella seguente mostra il numero di occorrenze di ogni lettera nella colonna Fuel type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7b55yzbOo1A"
      },
      "outputs": [],
      "source": [
        "canada_emissions[\"Fuel type\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csKs6KN7Oo1B"
      },
      "source": [
        "Riportiamo sotto il significato delle lettere.\n",
        "\n",
        "- `X`: Benzina normale (ha un indice di ottano più basso ed è quindi meno resistente alla detonazione)\n",
        "- `Z`: Benzina premium (ha un indice di ottano più alto e offre una maggiore resistenza alla detonazione. È ideale per motori ad alte prestazioni, che hanno un rapporto di compressione                           più elevato e richiedono un carburante più stabile.)\n",
        "- `D`: Diesel\n",
        "- `E`: Etanolo(E85)\n",
        "- `N`: gas naturale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whn4Y92ZOo1B"
      },
      "source": [
        "Per motivi di compatibilità dei dataset è superfluo mantenere la distinzione tra benzina normale e benzina premium. Compattiamo quindi le due lettere X e Z in una parola unica: Petrol.\n",
        "Inoltre trasformiamo anche E in Etanolo, N in Natural gas e D in Diesel per gli stessi motivi di confrontabilità.\n",
        "Prima di iniziare a modificare il dataframe per poter effettuare tutte le doverose modifiche per renderlo confrontabile con gli altri dataset ne salviamo una copia per evitare di perdere quello originale che potrebbe tornare utile."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DoK-CXcOo1B"
      },
      "outputs": [],
      "source": [
        "canada_emissions_copy = canada_emissions.copy()\n",
        "canada_emissions[\"Fuel type\"] = canada_emissions[\"Fuel type\"].replace({'X': 'Petrol', 'Z': 'Petrol', 'D': 'Diesel', 'N': 'Natural Gas', 'E': 'Ethanol'})\n",
        "canada_emissions[\"Fuel type\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk1tD6EcOo1B"
      },
      "source": [
        "Il seguente grafico a torta mostra la percentuale dei diversi tipi di carburante presi in considerazione. Si può notare che la maggior parte dei dati riguardano veicoli a benzina."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uzOp5-rOo1C"
      },
      "outputs": [],
      "source": [
        "fuel_type_colors = {\"Petrol\": \"yellow\", \"Ethanol\": \"red\", \"Diesel\": \"green\", \"Natural Gas\": \"blue\"}\n",
        "canada_fuel_type = canada_emissions[\"Fuel type\"].value_counts()\n",
        "canada_fuel_type.plot.pie(colors = canada_fuel_type.index.map(fuel_type_colors), shadow=True, figsize=(8,8))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ojd2ODGOo1C"
      },
      "source": [
        "### Eliminazione colonne superflue e rename delle feature importanti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_S4JeUIOo1C"
      },
      "source": [
        "E' inoltre doveroso eliminare le feature City, Highway, Combined che indicano rispettivamente il consumo di carburante: nelle strade di città, nelle autostrade e in entrambe. Eliminiamo inoltre la colonna superflua dell'id, quella del tipo veicolo (Vehicle class) e quella del numero di cilindri (Cylinders) del veicolo, non presente negli altri dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBcVRjH1Oo1C"
      },
      "outputs": [],
      "source": [
        "canada_emissions = canada_emissions.drop([\"_id\",\"Highway (L/100 km)\",\"City (L/100 km)\", \"Combined (L/100 km)\", \"Vehicle class\", \"Cylinders\"], axis=1)\n",
        "canada_emissions.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6lSOuxTOo1D"
      },
      "source": [
        "La celle seguente serve solo per modificare i nomi delle feature in modo che siano compatibili con gli altri dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZotE7BNOo1D"
      },
      "outputs": [],
      "source": [
        "canada_emissions = canada_emissions.rename(columns={\"Model year\": \"Year\",\"Make\": \"Manufacturer\",\"Fuel type\": \"Fuel_type\", \"Transmission\": \"Transmission_type\",\"Combined (mpg)\": \"Fuel_consumption\", \"CO2 emissions (g/km)\": \"CO2_Emissions\"})\n",
        "canada_emissions.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "euuorc3ROo1E"
      },
      "source": [
        "### Gestione del tipo di trasmissione"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxLdlUs-Oo1E"
      },
      "source": [
        "Le prossime celle servono per rendere confrontabili con gli altri dataframe i valori riguardanti il tipo di trasmissione. In particolare trasformiamo tutti i valori di trasmissioni inizianti per A in Automatic e tutti quelli inizianti per M in Manual eccetto per i valori AM (che sarebbero automated manual) che verranno eliminati per evitare incomprensioni dato che gli altri dataset distinguono solamente tra cambio manuale e automatico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccW0koy_Oo1E"
      },
      "outputs": [],
      "source": [
        "index_to_drop = canada_emissions[canada_emissions[\"Transmission_type\"].str.startswith(\"AM\")].index\n",
        "canada_emissions = canada_emissions.drop(index_to_drop)\n",
        "canada_emissions[\"Transmission_type\"] = canada_emissions[\"Transmission_type\"].replace({r'^M.*': 'Manual',r'^A.*': 'Automatic' }, regex=True)\n",
        "canada_emissions[\"Transmission_type\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJyJTyyDOo1E"
      },
      "source": [
        "Mostriamo ora i risultati appena ottenuti in un grafico a torta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qECJrp5ROo1E"
      },
      "outputs": [],
      "source": [
        "canada_emissions[\"Transmission_type\"].value_counts().plot.pie(autopct=\"%.2f%%\", shadow=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC1VzvEcOo1E"
      },
      "source": [
        "Come ci aspettavamo grazie allì'uso della funzione `value_counts()` i veicoli a cambio automatico sono la maggioranza."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "oMpQSOcUOo1E"
      },
      "source": [
        "### Dataset risultante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sde9iVB0Oo1F"
      },
      "source": [
        "Adattamento finale del nome del modello eliminando la casa automobilistica e le informazioni aggiuntive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j49IhPfJOo1F"
      },
      "outputs": [],
      "source": [
        "# Per rimuovere il nome della casa automobilistica e le informazioni aggiuntive dal nome del modello\n",
        "def remove_manufacturer(make_model):\n",
        "    make = make_model[\"Manufacturer\"]\n",
        "    model = make_model[\"Model\"]\n",
        "    removedManufacturer = model.replace(make, \"\").split()\n",
        "    model = [word for word in removedManufacturer if word not in useless_words][0]\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBU_JVlBOo1F"
      },
      "outputs": [],
      "source": [
        "canada_emissions[\"Model\"] = canada_emissions[[\"Manufacturer\", \"Model\"]].apply(remove_manufacturer, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib3byipBOo1F"
      },
      "source": [
        "Mostriamo di seguito il dataframe risultante `canada_emissions`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKd3SXIBOo1F"
      },
      "outputs": [],
      "source": [
        "canada_emissions.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUYVpfq6Oo1F"
      },
      "source": [
        "# Unione dei dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6A1rd8PpOo1F"
      },
      "outputs": [],
      "source": [
        "emissions = pd.concat([spain_emissions, canada_emissions, uk_emissions], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwnzNbBOOo1F"
      },
      "source": [
        "Infine, per i contenuti di tipo stringa come `Manufacturer` e `Model`, sarà necessaria una standardizzazione tra i diversi dataset. Lo standard scelto è la maiuscola per il primo carattere e la minuscola per gli altri caratteri."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf4Z0Fq1Oo1F"
      },
      "outputs": [],
      "source": [
        "capitalize_columns = [\"Manufacturer\", \"Model\"]\n",
        "emissions[capitalize_columns] = emissions[capitalize_columns].apply(lambda col: col.str.capitalize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MjjXftvOo1G"
      },
      "source": [
        "Nella prossima cella, mostriamo una breve descrizione in formato tabellare delle feature numeriche del dataset completo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdG1BNRLOo1G"
      },
      "outputs": [],
      "source": [
        "emissions.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "Yl65f1wtOo1G"
      },
      "source": [
        "# Addestramento modelli\n",
        "A seguito dell'esplorazione e dell'omogeneizzazione dei tre dataset, si può procedere all'addestramento dei modelli. I modelli verranno addestrati sulle seguenti feature indipendenti:\n",
        "- `Year`: anno in cui è stato prodotto il veicolo\n",
        "- `Manufacturer`: casa automobilistica che ha prodotto il veicolo\n",
        "- `Model`: nome del modello del veicolo\n",
        "- `Engine_cm3`: volume del motore in cm<sup>3</sup>\n",
        "- `Transmission_type`: tipologia di trasmissione del veicolo, ovvero se il cambio della marcia è automatico o manuale\n",
        "- `Fuel_type`: tipologia di carburante usato nel veicolo. Per esempio può essere benzina, diesel, benzina e ibrida ecc.\n",
        "- `Fuel_consumption`: i litri di carburante consumati dal veicolo ogni 100 km"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBOU8sFDOo1G"
      },
      "source": [
        "La variabile dipendente target dell'addestramento è `CO2_Emissions`, la quantità di CO<sub>2</sub> emessa dal veicolo in grammi per km."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8S8nQpXOo1G"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------- Data Preparation ----------\n",
        "X = emissions.drop(\"CO2_Emissions\", axis=1)\n",
        "y = emissions[\"CO2_Emissions\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Limit the number of samples for faster testing\n",
        "X_train = X_train.sample(n=500, random_state=42)\n",
        "y_train = y_train.loc[X_train.index]\n",
        "X_test = X_test.sample(n=250, random_state=42)\n",
        "y_test = y_test.loc[X_test.index]\n",
        "\n",
        "\n",
        "categorical_features = ['Manufacturer', 'Model', 'Fuel_type', 'Transmission_type']\n",
        "numerical_features = ['Year', 'Engine_cm3', 'Fuel_consumption']\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "encoder.fit(X_train[categorical_features])\n",
        "\n",
        "def encode_df(df):\n",
        "    enc = encoder.transform(df[categorical_features])\n",
        "    enc_df = pd.DataFrame(\n",
        "        enc, columns=encoder.get_feature_names_out(categorical_features), index=df.index\n",
        "    )\n",
        "    return pd.concat([df[numerical_features].reset_index(drop=True),\n",
        "                      enc_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "X_train_enc = encode_df(X_train)\n",
        "X_test_enc = encode_df(X_test)\n",
        "\n",
        "def to_tensor(x_df, y_series):\n",
        "    X_t = torch.tensor(x_df.values, dtype=torch.float32)\n",
        "    y_t = torch.tensor(y_series.values, dtype=torch.float32).unsqueeze(1)\n",
        "    return X_t, y_t\n",
        "\n",
        "X_train_tensor, y_train_tensor = to_tensor(X_train_enc, y_train)\n",
        "X_test_tensor, y_test_tensor = to_tensor(X_test_enc, y_test)\n",
        "\n",
        "# Full training dataset\n",
        "full_dataset = TensorDataset(X_train_tensor, y_train_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOiglnqCTrf7"
      },
      "source": [
        "## Definizione dei Modelli: MLP e KAN\n",
        "\n",
        "In questo blocco vengono definite due architetture di modelli per regressione:\n",
        "\n",
        "* **`MLP` (Multi-Layer Perceptron)**: una rete neurale feed-forward costruita in modo flessibile a partire da:\n",
        "\n",
        "  * `input_dim`: numero di feature in input;\n",
        "  * `hidden_sizes`: lista con il numero di neuroni per ciascun layer nascosto;\n",
        "  * `dropout`: tasso di dropout per regolarizzare l'addestramento.\n",
        "    Ogni layer nascosto è seguito da un'attivazione `ReLU` e un livello di `Dropout`. L'output è uno scalare, indicato per problemi di regressione.\n",
        "\n",
        "* **`build_kan`**: funzione che restituisce un modello **KAN (Kolmogorov–Arnold Networks)**, una rete neurale basata su un'architettura alternativa ai classici MLP, caratterizzata da:\n",
        "\n",
        "  * una struttura definita tramite la lista `width`,\n",
        "  * griglie di punti (`grid`) e grado del polinomio (`k`) per le interpolazioni,\n",
        "  * seme casuale (`seed`) per la riproducibilità e\n",
        "  * assegnazione del modello al corretto `device` (CPU o GPU).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0883e428-9e7f-4561-bc2d-59e7502dce79"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_sizes, dropout):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        dim = input_dim\n",
        "        for hs in hidden_sizes:\n",
        "            layers.append(nn.Linear(dim, hs))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            dim = hs\n",
        "        layers.append(nn.Linear(dim, 1))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def build_kan(input_dim, width, grid, k, seed, device):\n",
        "    return KAN(width=[input_dim] + list(width) + [1], grid=grid, k=k, seed=seed, device=device)\n",
        "\n",
        "def build_random_forest(**params):\n",
        "    return RandomForestRegressor(**params)\n",
        "\n",
        "def build_xgboost(**params):\n",
        "    return xgb.XGBRegressor(**params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyNK9pF4Trf7"
      },
      "source": [
        "## Nested Random Search con Early Stopping\n",
        "\n",
        "Questo blocco di codice implementa una procedura completa di **Nested Random Search** per la selezione di iperparametri di modelli di regressione in PyTorch, integrando una strategia di **Early Stopping** per migliorare l'efficienza del training.\n",
        "\n",
        "* La classe `EarlyStopper` consente di interrompere l'addestramento anticipatamente se la loss di validazione non migliora per un numero di epoche definito (`patience`), riducendo il rischio di overfitting e velocizzando l'ottimizzazione.\n",
        "* Le funzioni `train_epoch` ed `eval_loss` gestiscono rispettivamente il training e la valutazione della loss media su un dataset.\n",
        "* La funzione principale `nested_random_search` esegue una **Nested Cross-Validation**, dove:\n",
        "\n",
        "  * Il ciclo esterno (outer loop) valuta le prestazioni generali del modello su diversi split train/test.\n",
        "  * Il ciclo interno (inner loop) esplora combinazioni casuali di iperparametri tramite `ParameterSampler` per ottimizzare la loss di validazione, utilizzando K-Fold CV.\n",
        "* Per ogni fold esterno, viene selezionata la migliore combinazione di iperparametri trovata all’interno, con successivo riaddestramento sul training set esteso e valutazione finale sul test set.\n",
        "\n",
        "Il risultato è una lista di tuple contenenti i migliori parametri di modello, parametri di training e loss finale per ciascun fold esterno, utile per valutare la **robustezza e generalizzazione** del modello selezionato."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b812d5b-9727-4e5f-91b2-f40696c1c52f"
      },
      "outputs": [],
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=3, min_delta=0.0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "\n",
        "    def early_stop(self, val_loss):\n",
        "        # Se la loss migliora (di almeno min_delta), resettiamo il counter\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            # Se la loss non migliora da 'patience' epoche, dobbiamo fermarci\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for Xb, yb in loader:\n",
        "        Xb, yb = Xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(Xb), yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * Xb.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def eval_loss(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            total_loss += criterion(model(Xb), yb).item() * Xb.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def nested_random_search_neural(model_builder, param_dist, dataset,\n",
        "                               outer_folds=5, inner_folds=3, n_iter=10,\n",
        "                               early_patience=5, early_min_delta=1e-4):\n",
        "    \"\"\"\n",
        "    Esegue Nested Random Search con Randomized Search interno per reti neurali (MLP e KAN)\n",
        "    Args:\n",
        "        model_builder: funzione che crea un modello dato model_params\n",
        "        param_dist: dizionario di liste per ogni iperparametro (model_params + training_params)\n",
        "        dataset: TensorDataset per il training\n",
        "        outer_folds, inner_folds: numeri di fold per CV\n",
        "        n_iter: numero di campioni di Random Search\n",
        "        early_patience: numero di epoche di pazienza per Early Stopping\n",
        "        early_min_delta: miglioramento minimo per considerare un progresso\n",
        "    Returns:\n",
        "        lista di tuple (best_model_params, best_training_params, test_loss) per ogni outer fold\n",
        "    \"\"\"\n",
        "    # Chiavi riservate per training\n",
        "    train_keys = ['lr', 'batch_size', 'max_epochs']\n",
        "    outer_cv = KFold(n_splits=outer_folds, shuffle=True, random_state=42)\n",
        "    results = []\n",
        "\n",
        "    for train_idx, test_idx in outer_cv.split(range(len(dataset))):\n",
        "        inner_train = Subset(dataset, train_idx)\n",
        "        inner_test = Subset(dataset, test_idx)\n",
        "        best_val_loss = float('inf')\n",
        "        best_model_params, best_train_params = None, None\n",
        "\n",
        "        # Random Search interno\n",
        "        for params in ParameterSampler(param_dist, n_iter=n_iter, random_state=42):\n",
        "            # Separa i parametri del modello da quelli di training\n",
        "            model_params = {k: v for k, v in params.items() if k not in train_keys}\n",
        "            train_params = {k: v for k, v in params.items() if k in train_keys}\n",
        "\n",
        "            # Valutazione su inner_folds con Early Stopping\n",
        "            inner_cv = KFold(n_splits=inner_folds, shuffle=True, random_state=42)\n",
        "            val_losses = []\n",
        "            for subtrain_idx, val_idx in inner_cv.split(range(len(inner_train))):\n",
        "                subtrain = Subset(inner_train, subtrain_idx)\n",
        "                valset = Subset(inner_train, val_idx)\n",
        "                train_loader = DataLoader(subtrain, batch_size=train_params['batch_size'], shuffle=True)\n",
        "                val_loader = DataLoader(valset, batch_size=train_params['batch_size'], shuffle=False)\n",
        "\n",
        "                # Costruisci modello\n",
        "                model = model_builder(**model_params).to(device)\n",
        "                optimizer = optim.Adam(model.parameters(), lr=train_params['lr'])\n",
        "                stopper = EarlyStopper(patience=early_patience, min_delta=early_min_delta)\n",
        "\n",
        "                # Training\n",
        "                for epoch in range(train_params['max_epochs']):\n",
        "                    train_epoch(model, train_loader, optimizer, nn.MSELoss())\n",
        "                    val_loss = eval_loss(model, val_loader, nn.MSELoss())\n",
        "                    if stopper.early_stop(val_loss):\n",
        "                        break\n",
        "\n",
        "                # Loss di validazione\n",
        "                val_losses.append(eval_loss(model, val_loader, nn.MSELoss()))\n",
        "\n",
        "            mean_val = np.mean(val_losses)\n",
        "            if mean_val < best_val_loss:\n",
        "                best_val_loss = mean_val\n",
        "                best_model_params = model_params\n",
        "                best_train_params = train_params\n",
        "\n",
        "        # Riaddestramento con i migliori parametri su tutto il sottoinsieme interno con Early Stopping\n",
        "        full_train_loader = DataLoader(inner_train, batch_size=best_train_params['batch_size'], shuffle=True)\n",
        "        test_loader = DataLoader(inner_test, batch_size=best_train_params['batch_size'], shuffle=False)\n",
        "        final_model = model_builder(**best_model_params).to(device)\n",
        "        optimizer = optim.Adam(final_model.parameters(), lr=best_train_params['lr'])\n",
        "        stopper = EarlyStopper(patience=early_patience, min_delta=early_min_delta)\n",
        "\n",
        "        for epoch in range(best_train_params['max_epochs']):\n",
        "            train_epoch(final_model, full_train_loader, optimizer, nn.MSELoss())\n",
        "            val_loss = eval_loss(final_model, full_train_loader, nn.MSELoss())\n",
        "            if stopper.early_stop(val_loss):\n",
        "                break\n",
        "\n",
        "        test_loss = eval_loss(final_model, test_loader, nn.MSELoss())\n",
        "        results.append((best_model_params, best_train_params, test_loss))\n",
        "\n",
        "    return results\n",
        "\n",
        "def nested_random_search_sklearn(model_builder, param_dist, X_data, y_data,\n",
        "                                outer_folds=5, inner_folds=3, n_iter=10):\n",
        "    \"\"\"\n",
        "    Nested Random Search per modelli sklearn e XGBoost\n",
        "    \"\"\"\n",
        "    outer_cv = KFold(n_splits=outer_folds, shuffle=True, random_state=42)\n",
        "    results = []\n",
        "\n",
        "    for train_idx, test_idx in outer_cv.split(X_data):\n",
        "        X_inner_train, X_inner_test = X_data.iloc[train_idx], X_data.iloc[test_idx]\n",
        "        y_inner_train, y_inner_test = y_data.iloc[train_idx], y_data.iloc[test_idx]\n",
        "\n",
        "        best_val_mse = float('inf')\n",
        "        best_params = None\n",
        "\n",
        "        for params in ParameterSampler(param_dist, n_iter=n_iter, random_state=42):\n",
        "            inner_cv = KFold(n_splits=inner_folds, shuffle=True, random_state=42)\n",
        "            val_mses = []\n",
        "\n",
        "            for subtrain_idx, val_idx in inner_cv.split(X_inner_train):\n",
        "                X_subtrain, X_val = X_inner_train.iloc[subtrain_idx], X_inner_train.iloc[val_idx]\n",
        "                y_subtrain, y_val = y_inner_train.iloc[subtrain_idx], y_inner_train.iloc[val_idx]\n",
        "\n",
        "                model = model_builder(**params)\n",
        "                model.fit(X_subtrain, y_subtrain)\n",
        "                val_pred = model.predict(X_val)\n",
        "                val_mse = mean_squared_error(y_val, val_pred)\n",
        "                val_mses.append(val_mse)\n",
        "\n",
        "            mean_val_mse = np.mean(val_mses)\n",
        "            if mean_val_mse < best_val_mse:\n",
        "                best_val_mse = mean_val_mse\n",
        "                best_params = params\n",
        "\n",
        "        # Riaddestramento con i migliori parametri\n",
        "        final_model = model_builder(**best_params)\n",
        "        final_model.fit(X_inner_train, y_inner_train)\n",
        "        test_pred = final_model.predict(X_inner_test)\n",
        "        test_mse = mean_squared_error(y_inner_test, test_pred)\n",
        "\n",
        "        results.append((best_params, {}, test_mse))\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ0kfSVbTrf8"
      },
      "source": [
        "## Esecuzione del Nested Random Search su MLP e KAN\n",
        "\n",
        "In questa sezione viene eseguita la **ricerca di iperparametri tramite Nested Random Search** per due diverse architetture di modelli:\n",
        "**MLP (Multi-Layer Perceptron)** e **KAN (Kolmogorov–Arnold Networks)**.\n",
        "\n",
        "### Definizione degli spazi degli iperparametri:\n",
        "\n",
        "* `mlp_param_dist`: contiene combinazioni di dimensioni dei layer nascosti, tassi di dropout, learning rate, batch size e numero massimo di epoche per il training del modello MLP.\n",
        "* `kan_param_dist`: definisce i parametri strutturali del modello KAN come larghezza dei layer (`width`), numero di punti griglia (`grid`), grado delle funzioni di base (`k`), e parametri di training.\n",
        "\n",
        "### Esecuzione:\n",
        "\n",
        "* Viene eseguita la funzione `nested_random_search` separatamente per ciascun modello.\n",
        "* I risultati di ogni fold (configurazioni migliori e relativa test loss) vengono stampati a video per permettere un confronto diretto tra le due architetture.\n",
        "\n",
        "Questo confronto sistematico consente di determinare **quale modello e configurazione di iperparametri offra le migliori prestazioni** su un problema di regressione, valutato con Cross-Validation stratificata e early stopping.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b5b54e2-7eb9-42ad-9cfc-b6b6c4a85c33"
      },
      "outputs": [],
      "source": [
        "input_dim = X_train_tensor.shape[1]\n",
        "mlp_param_dist = {\n",
        "    'input_dim': [input_dim],\n",
        "    'hidden_sizes': [(32,32), (64,64), (128,)],\n",
        "    'dropout': [0.0, 0.2, 0.5],\n",
        "    'lr': [1e-3, 1e-4],\n",
        "    'batch_size': [32, 64],\n",
        "    'max_epochs': [100, 500, 1000]\n",
        "}\n",
        "\n",
        "kan_param_dist = {\n",
        "    'input_dim': [input_dim],\n",
        "    'width': [(8,4), (16,8)],\n",
        "    'grid': [5, 10],\n",
        "    'k': [2, 4],\n",
        "    'seed': [0],\n",
        "    'device': [device],\n",
        "    'lr': [1e-3],\n",
        "    'batch_size': [32],\n",
        "    'max_epochs': [100, 500, 1000]\n",
        "}\n",
        "\n",
        "rf_param_dist = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'random_state': [42]\n",
        "}\n",
        "\n",
        "# Parametri per XGBoost\n",
        "xgb_param_dist = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "    'reg_alpha': [0, 0.1, 0.5],\n",
        "    'reg_lambda': [1, 1.5, 2],\n",
        "    'random_state': [42]\n",
        "}\n",
        "\n",
        "# ---------- Run Nested Random Search ----------\n",
        "print(\"=== Nested Random Search Results ===\\n\")\n",
        "\n",
        "print(\"MLP Results:\")\n",
        "mlp_results = nested_random_search_neural(lambda **p: MLP(**p), mlp_param_dist, full_dataset)\n",
        "for i, (model_p, train_p, loss) in enumerate(mlp_results):\n",
        "    print(f\"Fold {i+1} - Model: {model_p}, Train: {train_p}, Test Loss: {loss:.4f}\")\n",
        "\n",
        "print(\"\\nKAN Results:\")\n",
        "kan_results = nested_random_search_neural(lambda **p: build_kan(**p), kan_param_dist, full_dataset)\n",
        "for i, (model_p, train_p, loss) in enumerate(kan_results):\n",
        "    print(f\"Fold {i+1} - Model: {model_p}, Train: {train_p}, Test Loss: {loss:.4f}\")\n",
        "\n",
        "print(\"\\nRandom Forest Results:\")\n",
        "rf_results = nested_random_search_sklearn(build_random_forest, rf_param_dist, X_train_enc, y_train)\n",
        "for i, (model_p, _, loss) in enumerate(rf_results):\n",
        "    print(f\"Fold {i+1} - Params: {model_p}, Test MSE: {loss:.4f}\")\n",
        "\n",
        "print(\"\\nXGBoost Results:\")\n",
        "xgb_results = nested_random_search_sklearn(build_xgboost, xgb_param_dist, X_train_enc, y_train)\n",
        "for i, (model_p, _, loss) in enumerate(xgb_results):\n",
        "    print(f\"Fold {i+1} - Params: {model_p}, Test MSE: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUySFSMoTrf9"
      },
      "source": [
        "## Valutazione Finale dei Migliori Modelli: MLP vs KAN\n",
        "\n",
        "Questa sezione si occupa di confrontare i **migliori modelli trovati** durante la ricerca annidata (`nested_random_search`) per le due architetture:\n",
        "\n",
        "* Viene definita la funzione `evaluate_model`, che calcola l'**MSE (Mean Squared Error)** di un modello su un `DataLoader`.\n",
        "* Si identificano i **migliori modelli MLP e KAN**, selezionando quelli con la più bassa *test loss* tra i risultati di cross-validation.\n",
        "* I modelli vengono **riaddestrati** usando gli stessi dati di test (dell'ultimo fold esterno) per analizzare:\n",
        "\n",
        "  * **Train loss** ad ogni epoca;\n",
        "  * **Validation loss** ad ogni epoca.\n",
        "\n",
        "Questa fase è utile per:\n",
        "\n",
        "* Verificare se il modello si **adatta bene** al test set senza overfitting;\n",
        "* Raccogliere dati da **visualizzare graficamente** (es. curva di apprendimento) per analizzare il comportamento delle due architetture nel tempo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7684d29a-0e27-4d0f-bc71-ffb2690d073d"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_neural(model, data_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in data_loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            loss = criterion(model(Xb), yb)\n",
        "            total_loss += loss.item() * Xb.size(0)\n",
        "    return total_loss / len(data_loader.dataset)\n",
        "\n",
        "def count_params(model):\n",
        "    if hasattr(model, 'parameters'):\n",
        "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    else:\n",
        "        # Per Random Forest e XGBoost, utilizziamo un'approssimazione\n",
        "        if hasattr(model, 'n_estimators') and hasattr(model, 'max_depth'):\n",
        "            # Stima approssimativa per Random Forest\n",
        "            return model.n_estimators * (model.max_depth or 10) * X_train_enc.shape[1]\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "def get_predictions_neural(model, data_loader):\n",
        "    model.eval()\n",
        "    preds, true = [], []\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in data_loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            preds.append(model(Xb).cpu().numpy())\n",
        "            true.append(yb.cpu().numpy())\n",
        "    return np.vstack(true), np.vstack(preds)\n",
        "\n",
        "def compute_metrics_neural(model, data_loader):\n",
        "    y_true, y_pred = get_predictions_neural(model, data_loader)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    n = len(y_true)\n",
        "    p = count_params(model)\n",
        "    try:\n",
        "        r2_adj = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "    except ZeroDivisionError:\n",
        "        r2_adj = r2\n",
        "    return mse, r2, r2_adj, p\n",
        "\n",
        "def compute_metrics_sklearn(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    n = len(y_test)\n",
        "    p = count_params(model)\n",
        "    try:\n",
        "        r2_adj = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "    except ZeroDivisionError:\n",
        "        r2_adj = r2\n",
        "    return mse, r2, r2_adj, p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG_luOrkTrf9"
      },
      "source": [
        "## Valutazione Finale e Confronto tra MLP e KAN\n",
        "\n",
        "In questa sezione, vengono confrontati i modelli MLP (Multi-Layer Perceptron) e KAN (Kolmogorov–Arnold Networks) utilizzando metriche di regressione e visualizzazioni grafiche per analizzare le loro prestazioni.\n",
        "\n",
        "### Metriche di Valutazione\n",
        "\n",
        "Vengono calcolate le seguenti metriche sul test set:\n",
        "\n",
        "* **MSE (Mean Squared Error)**: misura l'errore quadratico medio tra le predizioni del modello e i valori reali. Un valore più basso indica una migliore accuratezza del modello.\n",
        "\n",
        "* **R² (Coefficiente di Determinazione)**: indica la proporzione della varianza nei dati dipendenti che è prevedibile dalle variabili indipendenti. Un valore più alto (fino a 1) suggerisce una migliore capacità predittiva.\n",
        "\n",
        "* **R² Aggiustato**: modifica il R² standard penalizzando l'aggiunta di variabili indipendenti non significative, fornendo una misura più accurata della bontà del modello, specialmente quando si confrontano modelli con un numero diverso di predittori.&#x20;\n",
        "\n",
        "* **Numero di Parametri Addestrabili**: indica la complessità del modello; modelli con un numero inferiore di parametri sono generalmente preferibili se le prestazioni sono comparabili, poiché tendono a generalizzare meglio e sono meno suscettibili all'overfitting.\n",
        "\n",
        "### Visualizzazioni\n",
        "\n",
        "1. **Curve di Loss per Epoca**: grafici che mostrano l'andamento della loss di training e di validazione per ciascun modello nel corso delle epoche, utili per identificare fenomeni di overfitting o underfitting.\n",
        "\n",
        "2. **Confronto tramite Grafici a Barre**:\n",
        "\n",
        "   * **Numero di Parametri**: confronta la complessità dei modelli.\n",
        "   * **R² Aggiustato**: valuta la capacità predittiva tenendo conto della complessità del modello.\n",
        "   * **MSE di Test**: misura l'accuratezza delle predizioni sui dati di test.([Cross Validated][1])\n",
        "\n",
        "Queste analisi forniscono una panoramica completa delle prestazioni e della complessità dei modelli MLP e KAN, facilitando la selezione del modello più adatto per il problema in esame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2dcb82a-9300-43b4-bd27-4e1c1f47edc1"
      },
      "outputs": [],
      "source": [
        "# Selezione dei migliori modelli\n",
        "best_mlp_idx = min(range(len(mlp_results)), key=lambda i: mlp_results[i][2])\n",
        "best_mlp_params, best_mlp_train, _ = mlp_results[best_mlp_idx]\n",
        "\n",
        "best_kan_idx = min(range(len(kan_results)), key=lambda i: kan_results[i][2])\n",
        "best_kan_params, best_kan_train, _ = kan_results[best_kan_idx]\n",
        "\n",
        "best_rf_idx = min(range(len(rf_results)), key=lambda i: rf_results[i][2])\n",
        "best_rf_params, _, _ = rf_results[best_rf_idx]\n",
        "\n",
        "best_xgb_idx = min(range(len(xgb_results)), key=lambda i: xgb_results[i][2])\n",
        "best_xgb_params, _, _ = xgb_results[best_xgb_idx]\n",
        "\n",
        "# Creazione dei modelli finali\n",
        "mlp_model = MLP(**best_mlp_params).to(device)\n",
        "kan_model = build_kan(**best_kan_params).to(device)\n",
        "rf_model = build_random_forest(**best_rf_params)\n",
        "xgb_model = build_xgboost(**best_xgb_params)\n",
        "\n",
        "# Addestramento dei modelli sklearn\n",
        "rf_model.fit(X_train_enc, y_train)\n",
        "xgb_model.fit(X_train_enc, y_train)\n",
        "\n",
        "# Preparazione del test set per i modelli neurali\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "_, test_idx = list(outer_cv.split(range(len(full_dataset))))[-1]\n",
        "test_loader = DataLoader(\n",
        "    Subset(full_dataset, test_idx),\n",
        "    batch_size=best_mlp_train['batch_size'],\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Addestramento dei modelli neurali (semplificato per la valutazione finale)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Training MLP\n",
        "optimizer_mlp = optim.Adam(mlp_model.parameters(), lr=best_mlp_train['lr'])\n",
        "train_loader_mlp = DataLoader(Subset(full_dataset, test_idx), batch_size=best_mlp_train['batch_size'], shuffle=True)\n",
        "for epoch in range(best_mlp_train['max_epochs']):\n",
        "    train_epoch(mlp_model, train_loader_mlp, optimizer_mlp, criterion)\n",
        "\n",
        "# Training KAN\n",
        "optimizer_kan = optim.Adam(kan_model.parameters(), lr=best_kan_train['lr'])\n",
        "train_loader_kan = DataLoader(Subset(full_dataset, test_idx), batch_size=best_kan_train['batch_size'], shuffle=True)\n",
        "for epoch in range(best_kan_train['max_epochs']):\n",
        "    train_epoch(kan_model, train_loader_kan, optimizer_kan, criterion)\n",
        "\n",
        "# Calcolo delle metriche\n",
        "mse_mlp, r2_mlp, r2_adj_mlp, params_mlp = compute_metrics_neural(mlp_model, test_loader)\n",
        "mse_kan, r2_kan, r2_adj_kan, params_kan = compute_metrics_neural(kan_model, test_loader)\n",
        "mse_rf, r2_rf, r2_adj_rf, params_rf = compute_metrics_sklearn(rf_model, X_test_enc, y_test)\n",
        "mse_xgb, r2_xgb, r2_adj_xgb, params_xgb = compute_metrics_sklearn(xgb_model, X_test_enc, y_test)\n",
        "\n",
        "# Stampa risultati\n",
        "print(\"\\n=== RISULTATI FINALI ===\")\n",
        "print(f\"MLP:    MSE={mse_mlp:.4f}, R²={r2_mlp:.4f}, R²_adj={r2_adj_mlp:.4f}, params={params_mlp}\")\n",
        "print(f\"KAN:    MSE={mse_kan:.4f}, R²={r2_kan:.4f}, R²_adj={r2_adj_kan:.4f}, params={params_kan}\")\n",
        "print(f\"RF:     MSE={mse_rf:.4f}, R²={r2_rf:.4f}, R²_adj={r2_adj_rf:.4f}, params={params_rf}\")\n",
        "print(f\"XGB:    MSE={mse_xgb:.4f}, R²={r2_xgb:.4f}, R²_adj={r2_adj_xgb:.4f}, params={params_xgb}\")\n",
        "\n",
        "# Visualizzazione comparativa\n",
        "models = ['MLP', 'KAN', 'Random Forest', 'XGBoost']\n",
        "mse_vals = [mse_mlp, mse_kan, mse_rf, mse_xgb]\n",
        "r2_vals = [r2_mlp, r2_kan, r2_rf, r2_xgb]\n",
        "r2_adj_vals = [r2_adj_mlp, r2_adj_kan, r2_adj_rf, r2_adj_xgb]\n",
        "params_vals = [params_mlp, params_kan, params_rf, params_xgb]\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# MSE\n",
        "axs[0, 0].bar(models, mse_vals, color=['blue', 'green', 'orange', 'red'])\n",
        "axs[0, 0].set_title('MSE Test')\n",
        "axs[0, 0].set_ylabel('MSE')\n",
        "axs[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# R²\n",
        "axs[0, 1].bar(models, r2_vals, color=['blue', 'green', 'orange', 'red'])\n",
        "axs[0, 1].set_title('R² Score')\n",
        "axs[0, 1].set_ylabel('R²')\n",
        "axs[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# R² Aggiustato\n",
        "axs[1, 0].bar(models, r2_adj_vals, color=['blue', 'green', 'orange', 'red'])\n",
        "axs[1, 0].set_title('R² Aggiustato')\n",
        "axs[1, 0].set_ylabel('R² Adjusted')\n",
        "axs[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Numero di parametri (scala logaritmica)\n",
        "axs[1, 1].bar(models, params_vals, color=['blue', 'green', 'orange', 'red'])\n",
        "axs[1, 1].set_title('Numero di Parametri')\n",
        "axs[1, 1].set_ylabel('Count')\n",
        "axs[1, 1].set_yscale('log')\n",
        "axs[1, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Tabella riassuntiva\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': models,\n",
        "    'MSE': mse_vals,\n",
        "    'R²': r2_vals,\n",
        "    'R²_Adjusted': r2_adj_vals,\n",
        "    'Parameters': params_vals\n",
        "})\n",
        "\n",
        "print(\"\\n=== TABELLA RIASSUNTIVA ===\")\n",
        "print(results_df.round(4))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "t2-yNkVyOo0p",
        "fTm4gnAdOo0s",
        "b4ytHD44Vng_",
        "1ERHBFS0Oo00",
        "1LQEB6jT7pJo",
        "vo6B5sH0Oo1A",
        "AUYVpfq6Oo1F",
        "OOiglnqCTrf7",
        "nyNK9pF4Trf7",
        "VZ0kfSVbTrf8",
        "wUySFSMoTrf9",
        "CG_luOrkTrf9"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}