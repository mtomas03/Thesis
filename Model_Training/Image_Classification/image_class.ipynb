{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857f2f91",
   "metadata": {
    "id": "857f2f91",
    "papermill": {
     "duration": 0.00445,
     "end_time": "2023-10-20T02:15:45.071851",
     "exception": false,
     "start_time": "2023-10-20T02:15:45.067401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Faces Age Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51-VyZP_BGdJ",
   "metadata": {
    "id": "51-VyZP_BGdJ"
   },
   "source": [
    "## Import Libraries and Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XSCWWgUMMU7Y",
   "metadata": {
    "id": "XSCWWgUMMU7Y"
   },
   "outputs": [],
   "source": [
    "!pip install pykan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5hT9QMsYMXVx",
   "metadata": {
    "id": "5hT9QMsYMXVx"
   },
   "outputs": [],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07538deb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T02:15:45.088859Z",
     "iopub.status.busy": "2023-10-20T02:15:45.088192Z",
     "iopub.status.idle": "2023-10-20T02:16:02.778549Z",
     "shell.execute_reply": "2023-10-20T02:16:02.777382Z"
    },
    "id": "07538deb",
    "papermill": {
     "duration": 17.69764,
     "end_time": "2023-10-20T02:16:02.780972",
     "exception": false,
     "start_time": "2023-10-20T02:15:45.083332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import inspect\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset, WeightedRandomSampler\n",
    "import torch.nn.utils.prune as prune\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "from kan import *\n",
    "from sklearn.model_selection import ParameterSampler, KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    running_in_colab = True\n",
    "except ImportError:\n",
    "    running_in_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BSh8HbaKYUpQ",
   "metadata": {
    "id": "BSh8HbaKYUpQ"
   },
   "outputs": [],
   "source": [
    "if running_in_colab:\n",
    "    print(\"Running on Google Colab\")\n",
    "    !apt-get update -qq\n",
    "    !apt-get install -qq git-lfs\n",
    "    !git lfs install\n",
    "    !git clone https://github.com/vMxster/Thesis.git\n",
    "    !cd Thesis && git lfs pull\n",
    "    zip_part   = \"Thesis/Datasets/UTKFace_\"\n",
    "else:\n",
    "    print(\"Running locally in Jupyter\")\n",
    "    zip_part   = \"Datasets/UTKFace_\"\n",
    "\n",
    "zip_extract_to = \"datasets\"\n",
    "os.makedirs(zip_extract_to, exist_ok=True)\n",
    "\n",
    "for i in range(1,4):\n",
    "    zip_path = zip_part + str(i) + \".zip\"\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(zip_extract_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8rTDr1p2Fl6p",
   "metadata": {
    "id": "8rTDr1p2Fl6p"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BGt_VamtFCMK",
   "metadata": {
    "id": "BGt_VamtFCMK"
   },
   "outputs": [],
   "source": [
    "if running_in_colab:\n",
    "    filenames = glob.glob(f'{zip_extract_to}/*.jpg')\n",
    "else:\n",
    "    filenames = [str(p.as_posix()) for p in Path(zip_extract_to).glob(f'*.jpg')]\n",
    "\n",
    "print(len(filenames))\n",
    "print(filenames[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L1QI6KzTHTHy",
   "metadata": {
    "id": "L1QI6KzTHTHy"
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "np.random.shuffle(filenames)\n",
    "\n",
    "age_labels, gender_labels, ethnic_labels, image_path = [], [], [], []\n",
    "\n",
    "for filename in filenames:\n",
    "    image_path.append(filename)\n",
    "    temp = filename.split('_')\n",
    "    age_labels.append(temp[0].split('/')[1])\n",
    "    gender_labels.append(temp[1])\n",
    "    ethnic_labels.append(temp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VegCPN3lJrJA",
   "metadata": {
    "id": "VegCPN3lJrJA"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['image'], df['age'], df['gender'], df['ethnic'] = image_path, age_labels, gender_labels, ethnic_labels\n",
    "\n",
    "df = df[df['age'].str.isdigit()]\n",
    "df = df[df['gender'].str.isdigit()]\n",
    "df = df[df['ethnic'].str.isdigit()]\n",
    "\n",
    "df = df.astype({'age':'int64', 'gender': 'int64', 'ethnic': 'int64'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mZoI-z0w0UMF",
   "metadata": {
    "id": "mZoI-z0w0UMF"
   },
   "outputs": [],
   "source": [
    "gender_dict = {0:\"Male\", 1:\"Female\"}\n",
    "df = df[df['gender'].isin([0, 1])]\n",
    "df['gender'] = df['gender'].map(gender_dict)\n",
    "df['gender'] = df['gender'].astype('category')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rK7dIggU51wR",
   "metadata": {
    "id": "rK7dIggU51wR"
   },
   "outputs": [],
   "source": [
    "ethnic_dict = {0:\"White\", 1:\"Black\", 2:\"Asian\", 3:\"Indian\", 4:\"Others\"}\n",
    "df = df[df['ethnic'].isin([0, 1, 2, 3, 4])]\n",
    "df['ethnic'] = df['ethnic'].map(ethnic_dict)\n",
    "df['ethnic'] = df['ethnic'].astype('category')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iQ04xFMTv605",
   "metadata": {
    "id": "iQ04xFMTv605"
   },
   "outputs": [],
   "source": [
    "def age_group(age):\n",
    "    if age <= 12:\n",
    "        return 0\n",
    "    elif age <= 18:\n",
    "        return 1\n",
    "    elif age <= 60:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "df['age_group'] = df['age'].apply(age_group)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gcgFvVC0-MZX",
   "metadata": {
    "id": "gcgFvVC0-MZX"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p9edBnTJSSFy",
   "metadata": {
    "id": "p9edBnTJSSFy"
   },
   "outputs": [],
   "source": [
    "# Group by age group\n",
    "grouped = df.groupby('age_group')\n",
    "\n",
    "# Determine the target number of instances per group\n",
    "target_instances_per_group = 16000 // len(grouped)\n",
    "if 16000 % len(grouped) != 0:\n",
    "    print(f\"Warning: Total target instances ({16000}) is not perfectly divisible by the number of groups ({len(grouped)}). Some groups might have one more instance.\")\n",
    "\n",
    "# Sample from each group to balance the dataset\n",
    "balanced_df_list = []\n",
    "for _, group_df in grouped:\n",
    "    # Sample with replacement if a group has fewer instances than target\n",
    "    replace = len(group_df) < target_instances_per_group\n",
    "    sampled_group = group_df.sample(n=target_instances_per_group, replace=replace, random_state=42)\n",
    "    balanced_df_list.append(sampled_group)\n",
    "\n",
    "# Concatenate the sampled dataframes\n",
    "df = pd.concat(balanced_df_list).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"New DataFrame size: {len(df)}\")\n",
    "print(\"\\nNew distribution of age groups:\\n\")\n",
    "display(df['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FxBixBRxUf6Q",
   "metadata": {
    "id": "FxBixBRxUf6Q"
   },
   "outputs": [],
   "source": [
    "# Check if each image file exists and replace missing images by sampling from the same age group\n",
    "def check_image_existence_and_replace(df, age_group_column='age_group'):\n",
    "    \"\"\"\n",
    "    Checks if each image file in the dataframe exists and replaces rows with missing images\n",
    "    by sampling from the same age group.\n",
    "    \"\"\"\n",
    "    valid_df_list = []\n",
    "    missing_images_count = 0\n",
    "\n",
    "    # Group by age group to sample from the correct group\n",
    "    grouped = df.groupby(age_group_column)\n",
    "    group_dfs = {name: group.copy() for name, group in grouped} # Use copy to avoid SettingWithCopyWarning\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Checking images\"):\n",
    "        image_path = row['image']\n",
    "        if os.path.exists(image_path):\n",
    "            valid_df_list.append(row)\n",
    "        else:\n",
    "            missing_images_count += 1\n",
    "            # Find the age group of the missing image\n",
    "            age_group = row[age_group_column]\n",
    "\n",
    "            # Sample a replacement from the same age group\n",
    "            if age_group in group_dfs and not group_dfs[age_group].empty:\n",
    "                # Sample with replacement from the original group_df for this age group\n",
    "                replacement_row = group_dfs[age_group].sample(n=1, replace=True, random_state=np.random.randint(0, 10000)).iloc[0]\n",
    "                valid_df_list.append(replacement_row)\n",
    "            else:\n",
    "                # If no instances are available for this group (shouldn't happen with balanced sampling but as a fallback)\n",
    "                print(f\"Warning: No replacement found for age group {age_group}. Skipping row {index}.\")\n",
    "\n",
    "\n",
    "    if missing_images_count > 0:\n",
    "        print(f\"\\nFound and replaced {missing_images_count} missing image files.\")\n",
    "    else:\n",
    "        print(\"\\nAll image files found.\")\n",
    "\n",
    "    # Create a new dataframe from the valid and replaced rows\n",
    "    new_df = pd.DataFrame(valid_df_list)\n",
    "    return new_df\n",
    "\n",
    "# Run the check and replacement\n",
    "df = check_image_existence_and_replace(df)\n",
    "\n",
    "print(\"\\nFinal DataFrame size after checking images:\")\n",
    "print(len(df))\n",
    "\n",
    "print(\"\\nFinal distribution of age groups after checking images:\\n\")\n",
    "display(df['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5mfmIBJdA5vB",
   "metadata": {
    "id": "5mfmIBJdA5vB"
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4NV3--n4BkyG",
   "metadata": {
    "id": "4NV3--n4BkyG"
   },
   "outputs": [],
   "source": [
    "df.drop('image', axis=1).describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UGztZCEZGB1e",
   "metadata": {
    "id": "UGztZCEZGB1e"
   },
   "outputs": [],
   "source": [
    "age_counts = df.age.value_counts()\n",
    "total_count = age_counts.sum()\n",
    "age_percentages = (age_counts / total_count) * 100\n",
    "\n",
    "# Identify ages with less than 1%\n",
    "other_ages = age_percentages[age_percentages < 1]\n",
    "other_percentage = other_ages.sum()\n",
    "\n",
    "# Create a new series for plotting\n",
    "plot_data = age_percentages[age_percentages >= 1]\n",
    "if other_percentage > 0:\n",
    "    plot_data['Others'] = other_percentage\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Distribution of Ages in Percentage\")\n",
    "plot_data.plot.pie(autopct='%1.1f%%', startangle=90)\n",
    "plt.ylabel('')\n",
    "plt.figtext(0.5, 0.01, \"The 'Others' category includes ages with a distribution of less than 1%.\", ha=\"center\", fontsize=10, bbox={\"facecolor\":\"orange\", \"alpha\":0.5, \"pad\":5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qe5iSfD3wMPw",
   "metadata": {
    "id": "Qe5iSfD3wMPw"
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(40, 30)) # Create a figure with 3 subplots (3 rows, 1 column)\n",
    "fig.suptitle(\"Distribution of Ages by Gender\", fontsize=40) # Main title\n",
    "\n",
    "# Plot for all ages\n",
    "age_counts = df.age.value_counts()\n",
    "sns.barplot(x=age_counts.index, y=age_counts.values, ax=axes[0], color='black')\n",
    "axes[0].set_title(\"Distribution of All Ages\", fontsize=20)\n",
    "axes[0].set_xlabel(\"Age\", fontsize=18)\n",
    "axes[0].set_ylabel(\"Count\", fontsize=18)\n",
    "\n",
    "# Plot for male ages\n",
    "male_age_counts = df[df.gender == 'Male'].age.value_counts()\n",
    "sns.barplot(x=male_age_counts.index, y=male_age_counts.values, ax=axes[1], color='blue')\n",
    "axes[1].set_title(\"Distribution of Ages for Males\", fontsize=20)\n",
    "axes[1].set_xlabel(\"Age\", fontsize=18)\n",
    "axes[1].set_ylabel(\"Count\", fontsize=18)\n",
    "\n",
    "# Plot for female ages\n",
    "female_age_counts = df[df.gender == 'Female'].age.value_counts()\n",
    "sns.barplot(x=female_age_counts.index, y=female_age_counts.values, ax=axes[2], color='orange')\n",
    "axes[2].set_title(\"Distribution of Ages for Females\", fontsize=20)\n",
    "axes[2].set_xlabel(\"Age\", fontsize=18)\n",
    "axes[2].set_ylabel(\"Count\", fontsize=18)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent titles overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yx8Q8UqdxITP",
   "metadata": {
    "id": "yx8Q8UqdxITP"
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"Distribution of Genders\")\n",
    "plt.pie(df.gender.value_counts(), labels=df.gender.value_counts().index, autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ECdTrF6aEcra",
   "metadata": {
    "id": "ECdTrF6aEcra"
   },
   "outputs": [],
   "source": [
    "age_gender_counts = df.groupby(['age', 'gender'], observed=True).size().unstack(fill_value=0)\n",
    "age_gender_percentages = age_gender_counts.apply(lambda x: x / x.sum(), axis=1)\n",
    "\n",
    "ax = age_gender_percentages.plot(kind='bar', stacked=True, figsize=(20, 10), color=['blue', 'orange'])\n",
    "\n",
    "plt.title('Percentage of Males and Females by Age', fontsize=20)\n",
    "plt.xlabel('Age', fontsize=15)\n",
    "plt.ylabel('Percentage', fontsize=15)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(title='Gender')\n",
    "\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    if height > 0:\n",
    "        x, y = p.get_xy()\n",
    "        ax.text(x + width / 2,\n",
    "                y + height / 2,\n",
    "                '{:.1f}%'.format(height * 100),\n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='center',\n",
    "                fontsize=6,\n",
    "                color='white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59YJwsUGzefI",
   "metadata": {
    "id": "59YJwsUGzefI"
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"Distribution of Ethnic groups\")\n",
    "plt.pie(df.ethnic.value_counts(), labels=df.ethnic.value_counts().index, autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8C21Q_DxFT1o",
   "metadata": {
    "id": "8C21Q_DxFT1o"
   },
   "outputs": [],
   "source": [
    "# Bar plot for age and ethnicity\n",
    "for ethnic_group in df['ethnic'].unique():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    ethnic_df = df[df['ethnic'] == ethnic_group]\n",
    "    sns.countplot(data=ethnic_df, x='age')\n",
    "    plt.title(f'Age Distribution for {ethnic_group}')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "# Bar plot for ethnicity and gender\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='ethnic', hue='gender')\n",
    "plt.title('Distribution of Gender by Ethnicity')\n",
    "plt.xlabel('Ethnicity')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WlqCwcVEa0Vt",
   "metadata": {
    "id": "WlqCwcVEa0Vt"
   },
   "outputs": [],
   "source": [
    "class_counts = df['age_group'].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "age_group_labels = {0: \"Child [1;12]\", 1: \"Young [13;18]\", 2: \"Adult [19;60]\", 3: \"Senior [60;inf]\"}\n",
    "pie_labels = [age_group_labels[i] for i in class_counts.index]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(class_counts, labels=pie_labels, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WFrnOr1MwNvn",
   "metadata": {
    "id": "WFrnOr1MwNvn"
   },
   "source": [
    "### Plotting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81LQDyyUv8",
   "metadata": {
    "id": "8b81LQDyyUv8"
   },
   "outputs": [],
   "source": [
    "# Options\n",
    "print(f'Choose one Age in: {sorted([int(age) for age in df[\"age\"].unique()])}\\n')\n",
    "print(f'Choose one Gender in: {df[\"gender\"].unique()}\\n')\n",
    "print(f'Choose one Ethnic (or \"All\") in: {df[\"ethnic\"].unique()}\\n')\n",
    "\n",
    "# Define Specifics\n",
    "age = 26\n",
    "gender = 'Male'\n",
    "ethnic = 'All'\n",
    "\n",
    "if ethnic == 'All':\n",
    "    files = df.loc[(df['gender'] == gender) & (df['age'] == age)]\n",
    "else:\n",
    "    files = df.loc[(df['gender'] == gender) & (df['ethnic'] == ethnic) & (df['age'] == age)]\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for i, (index, row) in enumerate(files.head(25).iterrows()):\n",
    "    plt.subplot(5,5, i+1)\n",
    "    img = Image.open(row['image'])\n",
    "    img = np.array(img)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Age: {row['age']} ; Gender: {row['gender']}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "S5I6uB7hJBDo",
   "metadata": {
    "id": "S5I6uB7hJBDo"
   },
   "source": [
    "## Export Dataset in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xG79f3mxJDyE",
   "metadata": {
    "id": "xG79f3mxJDyE"
   },
   "outputs": [],
   "source": [
    "df.to_csv('UTKFace_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F7qEzz1oMGRj",
   "metadata": {
    "id": "F7qEzz1oMGRj"
   },
   "source": [
    "## Allenamento Modelli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5GZyqqRSUQF-",
   "metadata": {
    "id": "5GZyqqRSUQF-"
   },
   "source": [
    "### Definizione Modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2gGooYZWNFZD",
   "metadata": {
    "id": "2gGooYZWNFZD"
   },
   "outputs": [],
   "source": [
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels=3):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        # Per input 224x224, dopo conv1 (3x3, stride 1) e max_pool (2x2):\n",
    "        # (224 - 3 + 1)/1 = 222, poi 222/2 = 111\n",
    "        # Dopo conv2 (3x3, stride 1) e max_pool (2x2):\n",
    "        # (111 - 3 + 1)/1 = 109, poi 109/2 = 54.5 -> floor a 54\n",
    "        self.feature_dim = 16 * 54 * 54\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, self.feature_dim)  # Flatten\n",
    "        return x\n",
    "\n",
    "class CNN_MLP(nn.Module):\n",
    "    def __init__(self, input_channels=3, hidden_sizes=[120, 84, 20], dropout=0.0, num_classes=6, device='cpu'):\n",
    "        super(CNN_MLP, self).__init__()\n",
    "        self.cnn_features = CNNFeatureExtractor(input_channels)\n",
    "\n",
    "        # MLP layers\n",
    "        layers = []\n",
    "        dim = self.cnn_features.feature_dim\n",
    "        for hs in hidden_sizes:\n",
    "            layers.append(nn.Linear(dim, hs))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            dim = hs\n",
    "        layers.append(nn.Linear(dim, num_classes))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.cnn_features(x)\n",
    "        return self.mlp(features)\n",
    "\n",
    "class CNN_KAN(nn.Module):\n",
    "    def __init__(self, input_channels=3, width=[8, 4], grid=5, k=3, num_classes=6, seed=0, device='cpu'):\n",
    "        super(CNN_KAN, self).__init__()\n",
    "        self.cnn_features = CNNFeatureExtractor(input_channels)\n",
    "\n",
    "        # KAN network\n",
    "        kan_width = [self.cnn_features.feature_dim] + list(width) + [num_classes]\n",
    "        self.kan = KAN(\n",
    "            width=kan_width,\n",
    "            grid=grid,\n",
    "            k=k,\n",
    "            seed=seed,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.cnn_features(x)\n",
    "        return self.kan(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toQbpNSDUSKt",
   "metadata": {
    "id": "toQbpNSDUSKt"
   },
   "source": [
    "### Definizione Dataset e Split in Train e Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xHD4e-EwNSLZ",
   "metadata": {
    "id": "xHD4e-EwNSLZ"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset personalizzato per immagini con preprocessing\"\"\"\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "        # Transform di default come nel primo documento\n",
    "        if self.transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                   [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "            img = self.transform(img)\n",
    "            label = self.labels[idx]\n",
    "            return img, label\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nel caricamento dell'immagine {self.image_paths[idx]}: {e}\")\n",
    "            # Restituisci un'immagine nera come fallback\n",
    "            img = torch.zeros(3, 224, 224)\n",
    "            return img, self.labels[idx]\n",
    "\n",
    "def create_image_train_test_sets(image_paths, labels, split=0.8):\n",
    "    \"\"\"Crea train e test set per le immagini mantenendo l'ordine temporale\"\"\"\n",
    "    dataset_size = len(image_paths)\n",
    "    train_size = int(dataset_size * split)\n",
    "\n",
    "    train_paths = image_paths[:train_size]\n",
    "    test_paths = image_paths[train_size:]\n",
    "    train_labels = labels[:train_size]\n",
    "    test_labels = labels[train_size:]\n",
    "\n",
    "    return train_paths, test_paths, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GFSzW1CBUM7y",
   "metadata": {
    "id": "GFSzW1CBUM7y"
   },
   "source": [
    "### EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hpit6FBPOfEj",
   "metadata": {
    "id": "Hpit6FBPOfEj"
   },
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=3, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, val_loss):\n",
    "        # Se la loss migliora (di almeno min_delta), resettiamo il counter\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            # Se la loss non migliora da 'patience' epoche, dobbiamo fermarci\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RAZJ5vZNUJe7",
   "metadata": {
    "id": "RAZJ5vZNUJe7"
   },
   "source": [
    "### Train ed Eval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3B_jwfgAOXM6",
   "metadata": {
    "id": "3B_jwfgAOXM6"
   },
   "outputs": [],
   "source": [
    "def train_cnn_epoch(model, loader, optimizer, criterion, device, l2_lambda=0.0):\n",
    "    \"\"\"Training epoch per modelli CNN\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch_idx, (images, labels) in enumerate(tqdm(loader, desc=\"Training\")):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # L2 Regularization\n",
    "        if l2_lambda > 0:\n",
    "            l2_reg = torch.tensor(0.).to(device)\n",
    "            for param in model.parameters():\n",
    "                l2_reg += torch.norm(param, 2)\n",
    "            loss += l2_lambda * l2_reg\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def eval_cnn_loss(model, loader, criterion, device):\n",
    "    \"\"\"Valutazione loss per modelli CNN\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            total_loss += criterion(outputs, labels).item() * images.size(0)\n",
    "    return total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JP9fNayGUFuW",
   "metadata": {
    "id": "JP9fNayGUFuW"
   },
   "source": [
    "### RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NvcF1uNkOT3E",
   "metadata": {
    "id": "NvcF1uNkOT3E"
   },
   "outputs": [],
   "source": [
    "def random_search_cnn(model_builder, param_dist, train_paths, train_labels,\n",
    "                      n_iter=10, cv_folds=5, batch_size=32,\n",
    "                      early_patience=5, early_min_delta=1e-4,\n",
    "                      class_weights=None, device='cpu'):\n",
    "    \"\"\"Random search for CNN models with KFold Cross Validation\"\"\"\n",
    "\n",
    "    train_keys = ['lr', 'l2_lambda']\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_params, best_train_params = None, None\n",
    "    best_model = None\n",
    "\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    print(\"Starting Random Search CNN with KFold Cross Validation...\")\n",
    "\n",
    "    for param_id, params in enumerate(ParameterSampler(param_dist, n_iter=n_iter, random_state=42)):\n",
    "        print(f\"Testing parameter set {param_id+1}/{n_iter}\")\n",
    "\n",
    "        model_params = {k: v for k, v in params.items() if k not in train_keys}\n",
    "        train_params = {k: v for k, v in params.items() if k in train_keys}\n",
    "        val_losses = []\n",
    "\n",
    "        # Prepare indices for KFold\n",
    "        indices = np.arange(len(train_paths))\n",
    "\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(kf.split(indices)):\n",
    "            print(f\"  Fold {fold_idx+1}/{cv_folds}\")\n",
    "\n",
    "            # Create subsets for this fold\n",
    "            fold_train_paths = [train_paths[i] for i in train_idx]\n",
    "            fold_train_labels = [train_labels[i] for i in train_idx]\n",
    "            fold_val_paths = [train_paths[i] for i in val_idx]\n",
    "            fold_val_labels = [train_labels[i] for i in val_idx]\n",
    "\n",
    "            # Create dataset for this fold\n",
    "            train_dataset = ImageDataset(fold_train_paths, fold_train_labels)\n",
    "            val_dataset = ImageDataset(fold_val_paths, fold_val_labels)\n",
    "\n",
    "            # Calculate weights for weighted sampling\n",
    "            if class_weights is not None:\n",
    "                sample_weights = np.array([class_weights.get(label, 1.0) for label in fold_train_labels])\n",
    "                sampler = WeightedRandomSampler(\n",
    "                    weights=sample_weights,\n",
    "                    num_samples=len(sample_weights),\n",
    "                    replacement=True\n",
    "                )\n",
    "                train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "            else:\n",
    "                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            # Create and train the model\n",
    "            if 'width' in model_params:\n",
    "                model = model_builder(**model_params, device=device)\n",
    "                if isinstance(model, CNN_KAN):\n",
    "                    model.kan.speed()\n",
    "            else:\n",
    "                model = model_builder(**model_params)\n",
    "            model.to(device)\n",
    "\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=train_params['lr'])\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            stopper = EarlyStopper(patience=early_patience, min_delta=early_min_delta)\n",
    "\n",
    "            for epoch in range(100):\n",
    "                train_loss = train_cnn_epoch(model, train_loader, optimizer, criterion, device,\n",
    "                                           l2_lambda=train_params.get('l2_lambda', 0.0))\n",
    "                val_loss = eval_cnn_loss(model, val_loader, criterion, device)\n",
    "\n",
    "                if epoch % 10 == 0:\n",
    "                    print(f\"    Epoch {epoch}: train_loss = {train_loss:.6f}, val_loss = {val_loss:.6f}\")\n",
    "\n",
    "                if stopper.early_stop(val_loss):\n",
    "                    print(f\"    Early stopping at epoch {epoch}, best_val_loss: {stopper.best_loss:.6f}\")\n",
    "                    break\n",
    "\n",
    "            final_val_loss = eval_cnn_loss(model, val_loader, criterion, device)\n",
    "            val_losses.append(final_val_loss)\n",
    "\n",
    "        mean_val = np.mean(val_losses)\n",
    "        print(f\"  Mean validation loss: {mean_val:.6f}\")\n",
    "\n",
    "        if mean_val < best_val_loss:\n",
    "            best_val_loss = mean_val\n",
    "            best_model_params = model_params\n",
    "            best_train_params = train_params\n",
    "            if 'width' in best_model_params:\n",
    "                best_model = model_builder(**best_model_params, device=device).to(device)\n",
    "            else:\n",
    "                best_model = model_builder(**best_model_params).to(device)\n",
    "\n",
    "            best_model.load_state_dict(model.state_dict())\n",
    "            print(f\"  New best validation loss: {best_val_loss:.6f}\")\n",
    "\n",
    "    print(f\"\\nBest validation loss: {best_val_loss:.6f}\")\n",
    "    return best_model, best_model_params, best_train_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aqmioU9_TzTk",
   "metadata": {
    "id": "aqmioU9_TzTk"
   },
   "source": [
    "### Calcolo Metriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O-k7I9v-L0up",
   "metadata": {
    "id": "O-k7I9v-L0up"
   },
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    total_params = 0\n",
    "\n",
    "    if isinstance(model, CNN_KAN):\n",
    "        # Count parameters for the CNNFeatureExtractor part (standard nn.Module)\n",
    "        cnn_params = sum(p.numel() for p in model.cnn_features.parameters() if p.requires_grad)\n",
    "        total_params += cnn_params\n",
    "\n",
    "        # Count parameters for the KAN part (using the specific KAN formula)\n",
    "        kan_model = model.kan\n",
    "        try:\n",
    "            if not kan_model.width or len(kan_model.width) < 2:\n",
    "                # No parameters if width is invalid\n",
    "                kan_params = 0\n",
    "            else:\n",
    "                sum_edge_terms = 0\n",
    "                for i in range(len(kan_model.width) - 1):\n",
    "                    # Nl and Nl+1 in the formula\n",
    "                    Nl = kan_model.width[i]\n",
    "                    Nl_plus_1 = kan_model.width[i+1]\n",
    "\n",
    "                    # Handle potential list formats for Nl/Nl+1, though integers are expected for width\n",
    "                    if isinstance(Nl, list): Nl = Nl[0]\n",
    "                    if isinstance(Nl_plus_1, list): Nl_plus_1 = Nl_plus_1[0]\n",
    "\n",
    "                    # G and k from the KAN object\n",
    "                    G = kan_model.grid\n",
    "                    k = kan_model.k\n",
    "\n",
    "                    # Nl * Nl+1 * (G + k - 1)\n",
    "                    sum_edge_terms += Nl * Nl_plus_1 * (G + k - 1)\n",
    "                kan_params = sum_edge_terms\n",
    "            total_params += kan_params\n",
    "            return total_params\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating KAN parameters for CNN_KAN's KAN component: {e}\")\n",
    "            return total_params # Return sum of CNN params + whatever could be calculated\n",
    "\n",
    "    # If it's a standard nn.Module (like CNN_MLP or CNNFeatureExtractor directly)\n",
    "    elif isinstance(model, nn.Module):\n",
    "        try:\n",
    "            return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating standard nn.Module parameters: {e}\")\n",
    "            return 0\n",
    "\n",
    "    # If it's directly a KAN instance (not wrapped in CNN_KAN)\n",
    "    elif isinstance(model, KAN):\n",
    "        try:\n",
    "            if not model.width or len(model.width) < 2:\n",
    "                return 0\n",
    "            else:\n",
    "                sum_edge_terms = 0\n",
    "                for i in range(len(model.width) - 1):\n",
    "                    Nl = model.width[i]\n",
    "                    Nl_plus_1 = model.width[i+1]\n",
    "                    if isinstance(Nl, list): Nl = Nl[0]\n",
    "                    if isinstance(Nl_plus_1, list): Nl_plus_1 = Nl_plus_1[0]\n",
    "                    G = model.grid\n",
    "                    k = model.k\n",
    "                    sum_edge_terms += Nl * Nl_plus_1 * (G + k - 1)\n",
    "                return sum_edge_terms\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating KAN parameters: {e}\")\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def bootstrap_ci(metric_fn, y_true, y_pred, n_bootstraps=1000, alpha=0.05, **metric_kwargs):\n",
    "    y_true_arr = np.asarray(y_true)\n",
    "    y_pred_arr = np.asarray(y_pred)\n",
    "    vals = []\n",
    "    n_samples = len(y_true)\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "        idx = np.random.randint(0, n_samples, n_samples)\n",
    "        vals.append(metric_fn(y_true_arr[idx], y_pred_arr[idx], **metric_kwargs))\n",
    "\n",
    "    low = np.percentile(vals, 100 * (alpha / 2))\n",
    "    high = np.percentile(vals, 100 * (1 - alpha / 2))\n",
    "    return low, high\n",
    "\n",
    "def get_cnn_estimator_scores(model_name, model, test_paths, test_labels,\n",
    "                           train_paths, train_labels, device, batch_size=32):\n",
    "    \"\"\"Valutazione prestazioni per modelli CNN - stile secondo documento\"\"\"\n",
    "    print(f\"\\n--- Valutazione Prestazioni per {model_name} (CNN) ---\")\n",
    "\n",
    "    # Calcola parametri del modello\n",
    "    param_count = count_params(model)\n",
    "    print(f\"Model Parameters: {param_count}\")\n",
    "\n",
    "    # Crea dataset e dataloader\n",
    "    train_dataset = ImageDataset(train_paths, train_labels)\n",
    "    test_dataset = ImageDataset(test_paths, test_labels)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Predizioni\n",
    "    model.eval()\n",
    "    y_pred_train, y_true_train = [], []\n",
    "    y_pred_test, y_true_test = [], []\n",
    "    y_proba_test = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Training set\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "            y_pred_train.extend(pred.cpu().numpy())\n",
    "            y_true_train.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Test set\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "            proba = F.softmax(outputs, dim=1)\n",
    "\n",
    "            y_pred_test.extend(pred.cpu().numpy())\n",
    "            y_true_test.extend(labels.cpu().numpy())\n",
    "            y_proba_test.extend(proba.cpu().numpy())\n",
    "\n",
    "    y_proba_test = np.array(y_proba_test)\n",
    "\n",
    "    # Calcola metriche\n",
    "    accuracy_tr = accuracy_score(y_true_train, y_pred_train)\n",
    "    f1_weighted_tr = f1_score(y_true_train, y_pred_train, average='weighted', zero_division=0)\n",
    "    f1_macro_tr = f1_score(y_true_train, y_pred_train, average='macro', zero_division=0)\n",
    "\n",
    "    accuracy_te = accuracy_score(y_true_test, y_pred_test)\n",
    "    f1_weighted_te = f1_score(y_true_test, y_pred_test, average='weighted', zero_division=0)\n",
    "    f1_macro_te = f1_score(y_true_test, y_pred_test, average='macro', zero_division=0)\n",
    "\n",
    "    # Bootstrap CI\n",
    "    f1_weighted_low, f1_weighted_high = bootstrap_ci(\n",
    "        f1_score, y_true_test, y_pred_test, average='weighted', zero_division=0\n",
    "    )\n",
    "    f1_macro_low, f1_macro_high = bootstrap_ci(\n",
    "        f1_score, y_true_test, y_pred_test, average='macro', zero_division=0\n",
    "    )\n",
    "\n",
    "    print(\"\\nClassification Report (Test Set):\")\n",
    "    print(classification_report(y_true_test, y_pred_test, zero_division=0))\n",
    "\n",
    "    print(\"\\nConfusion Matrix (Test Set):\")\n",
    "    print(confusion_matrix(y_true_test, y_pred_test))\n",
    "\n",
    "    scores_row = [\n",
    "        model_name, param_count,\n",
    "        accuracy_tr, accuracy_te,\n",
    "        f1_weighted_tr, f1_weighted_te, f1_weighted_low, f1_weighted_high,\n",
    "        f1_macro_tr, f1_macro_te, f1_macro_low, f1_macro_high\n",
    "    ]\n",
    "\n",
    "    # Calcolo AUC\n",
    "    try:\n",
    "        auc_roc_ovr = roc_auc_score(y_true_test, y_proba_test, multi_class='ovr', average='weighted')\n",
    "        auc_pr_ovr = average_precision_score(pd.get_dummies(y_true_test), y_proba_test, average='weighted')\n",
    "\n",
    "        # Bootstrap per AUC\n",
    "        auc_roc_low, auc_roc_high = bootstrap_ci(\n",
    "            lambda yt, yp: roc_auc_score(yt, yp, multi_class='ovr', average='weighted'),\n",
    "            y_true_test, y_proba_test\n",
    "        )\n",
    "        auc_pr_low, auc_pr_high = bootstrap_ci(\n",
    "            lambda yt, yp: average_precision_score(pd.get_dummies(yt), yp, average='weighted'),\n",
    "            y_true_test, y_proba_test\n",
    "        )\n",
    "\n",
    "        scores_row.extend([auc_roc_ovr, auc_roc_low, auc_roc_high, auc_pr_ovr, auc_pr_low, auc_pr_high])\n",
    "        print(f\"AUC-ROC (OVR, Weighted): {auc_roc_ovr:.3f}\")\n",
    "        print(f\"AUC-PR (OVR, Weighted): {auc_pr_ovr:.3f}\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Errore nel calcolo di AUC/PR: {e}\")\n",
    "        scores_row.extend([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "\n",
    "    all_scores.append(scores_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N2VbqTAtT4PW",
   "metadata": {
    "id": "N2VbqTAtT4PW"
   },
   "source": [
    "### Preparazione Dati, Definizione Griglia ed Allenamento Modelli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L7mFOrwMLmeE",
   "metadata": {
    "id": "L7mFOrwMLmeE"
   },
   "source": [
    "**Scelta del numero di iterazioni per RandomizedSearchCV con CNN_MLP grid**\n",
    "\n",
    "Il grid ha:\n",
    "\n",
    "- Configurazioni Totali:\n",
    "$$\n",
    "M = 54\n",
    "$$\n",
    "\n",
    "Supponiamo di voler avere una probabilità \\( P = 0.90 \\) di includere almeno una delle migliori \\( k = 10 \\) configurazioni tra queste 54.\n",
    "\n",
    "Usiamo la formula:\n",
    "\n",
    "$$\n",
    "n = \\frac{\\ln(1 - P)}{\\ln\\left(1 - \\frac{k}{M}\\right)}\n",
    "$$\n",
    "\n",
    "Calcoliamo:\n",
    "\n",
    "$$\n",
    "n = \\frac{\\ln(1 - 0.90)}{\\ln\\left(1 - \\frac{10}{54}\\right)} = \\frac{\\ln(0.10)}{\\ln\\left(\\frac{44}{54}\\right)} = \\frac{-2.3026}{\\ln(\\frac{44}{54})} \\approx \\frac{2.3026}{0.2047} \\approx 11.25\n",
    "$$\n",
    "\n",
    "Quindi, con **11 iterazioni** di Randomized Search, si ha circa il 90% di probabilità di testare almeno una delle 10 migliori configurazioni, risparmiando molto rispetto a un Grid Search completo con 54 combinazioni.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F7zhlGsyMYrT",
   "metadata": {
    "id": "F7zhlGsyMYrT"
   },
   "source": [
    "**Scelta del numero di iterazioni per RandomizedSearchCV con CNN_KAN grid**\n",
    "\n",
    "Il grid ha:\n",
    "\n",
    "- Configurazioni Totali:\n",
    "$$\n",
    "M = 72\n",
    "$$\n",
    "\n",
    "Supponiamo di voler avere una probabilità \\( P = 0.90 \\) di includere almeno una delle migliori \\( k = 10 \\) configurazioni tra queste 72.\n",
    "\n",
    "Usiamo la formula:\n",
    "\n",
    "$$\n",
    "n = \\frac{\\ln(1 - P)}{\\ln\\left(1 - \\frac{k}{M}\\right)}\n",
    "$$\n",
    "\n",
    "Calcoliamo:\n",
    "\n",
    "$$\n",
    "n = \\frac{\\ln(1 - 0.90)}{\\ln\\left(1 - \\frac{10}{72}\\right)} = \\frac{\\ln(0.10)}{\\ln\\left(\\frac{62}{72}\\right)} = \\frac{-2.3026}{\\ln(\\frac{62}{72})} \\approx \\frac{2.3026}{0.1495} \\approx 15.40\n",
    "$$\n",
    "\n",
    "Quindi, con **15 iterazioni** di Randomized Search, si ha circa il 90% di probabilità di testare almeno una delle 10 migliori configurazioni, risparmiando molto rispetto a un Grid Search completo con 72 combinazioni.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3Vwc1L7pL6L0",
   "metadata": {
    "id": "3Vwc1L7pL6L0"
   },
   "source": [
    "**Da dove viene la formula per stimare il numero di iterazioni nel Randomized Search?**\n",
    "\n",
    "Per stimare quante iterazioni (`n`) sono necessarie per avere una certa probabilità \\(P\\) di includere almeno una configurazione tra le \\(k\\) migliori (su \\(M\\) totali), usiamo la seguente logica probabilistica:\n",
    "\n",
    "1. Probabilità di *non* pescare una top-\\(k\\) in un singolo tentativo.\n",
    "Se ci sono \\(M\\) configurazioni totali e \\(k\\) di esse sono “quasi ottimali”, la probabilità di *non* sceglierne una buona è:\n",
    "$$\n",
    "1 - \\frac{k}{M}\n",
    "$$\n",
    "\n",
    "2. Probabilità di non pescarne *nessuna* in \\(n\\) tentativi indipendenti\n",
    "$$\n",
    "\\left(1 - \\frac{k}{M} \\right)^n\n",
    "$$\n",
    "\n",
    "3. Probabilità di pescare **almeno una** delle top-\\(k\\)\n",
    "$$\n",
    "P(\\text{≥1 top-}k) = 1 - \\left(1 - \\frac{k}{M} \\right)^n\n",
    "$$\n",
    "\n",
    "4. Ricavare \\(n\\) dalla formula\n",
    "$$\n",
    "1 - \\left(1 - \\frac{k}{M} \\right)^n = P\n",
    "\\quad \\Longrightarrow \\quad\n",
    "n = \\frac{\\ln(1 - P)}{\\ln\\left(1 - \\frac{k}{M} \\right)}\n",
    "$$\n",
    "\n",
    "5. Approssimazione per $$ k \\ll M $$\n",
    "Poiché $$ \\ln(1 - x) \\approx -x $$ per \\(x\\) piccolo:\n",
    "$$\n",
    "n \\approx - \\frac{\\ln(1 - P)}{k/M}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ns7CqHEEO_bM",
   "metadata": {
    "id": "Ns7CqHEEO_bM"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device utilizzato: {device}\")\n",
    "\n",
    "image_paths = list(df['image'])\n",
    "labels = list(df['age_group'].astype('category').cat.codes)\n",
    "\n",
    "# Dividi in train/test\n",
    "train_paths, test_paths, train_labels, test_labels = create_image_train_test_sets(\n",
    "    image_paths, labels, split=0.8\n",
    ")\n",
    "\n",
    "# Calcola pesi delle classi\n",
    "class_labels = np.unique(train_labels)\n",
    "class_weights_balanced = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=class_labels,\n",
    "    y=train_labels\n",
    ")\n",
    "class_weights_dict = dict(zip(class_labels, class_weights_balanced))\n",
    "\n",
    "# Definisci spazi di ricerca iperparametri\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NHod6sHw7aO-",
   "metadata": {
    "id": "NHod6sHw7aO-"
   },
   "outputs": [],
   "source": [
    "cnn_mlp_param_dist = {\n",
    "    'input_channels': [3],\n",
    "    'hidden_sizes': [[120, 84, 20], [64, 32], [128, 64, 32]],\n",
    "    'dropout': [0.0, 0.2, 0.5],\n",
    "    'num_classes': [num_classes],\n",
    "    'lr': [1e-3, 1e-4],\n",
    "    'l2_lambda': [0.0, 1e-5, 1e-4]\n",
    "}\n",
    "\n",
    "cnn_kan_param_dist = {\n",
    "    'input_channels': [3],\n",
    "    'width': [[8, 4], [16, 8], [32, 16]],\n",
    "    'grid': [5, 10],\n",
    "    'k': [2, 3],\n",
    "    'num_classes': [num_classes],\n",
    "    'seed': [0],\n",
    "    'lr': [1e-3, 1e-4],\n",
    "    'l2_lambda': [0.0, 1e-5, 1e-4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w_gR8hW3Orar",
   "metadata": {
    "id": "w_gR8hW3Orar"
   },
   "outputs": [],
   "source": [
    "# Addestramento CNN+MLP\n",
    "print(\"=== CNN + MLP Results ===\")\n",
    "best_cnn_mlp, model_params_cnn_mlp, train_params_cnn_mlp = random_search_cnn(\n",
    "    lambda **p: CNN_MLP(**p),\n",
    "    cnn_mlp_param_dist,\n",
    "    train_paths,\n",
    "    train_labels,\n",
    "    class_weights=class_weights_dict,\n",
    "    device=device,\n",
    "    n_iter=11\n",
    ")\n",
    "\n",
    "cnn_mlp_config = {\n",
    "    \"model_params\": model_params_cnn_mlp,\n",
    "    \"train_params\": train_params_cnn_mlp\n",
    "}\n",
    "\n",
    "with open('cnn_mlp_config.json', 'w') as f:\n",
    "    json.dump(cnn_mlp_config, f, indent=4)\n",
    "print(\"Configurazione completa di CNN_MLP salvata.\")\n",
    "\n",
    "torch.save(best_cnn_mlp.state_dict(), 'best_cnn_mlp.pth')\n",
    "print(\"Modello CNN_MLP salvato.\")\n",
    "\n",
    "get_cnn_estimator_scores(\"CNN_MLP\", best_cnn_mlp,\n",
    "                        test_paths, test_labels,\n",
    "                        train_paths, train_labels,\n",
    "                        device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bx0-pTEZ7XYD",
   "metadata": {
    "id": "Bx0-pTEZ7XYD"
   },
   "outputs": [],
   "source": [
    "# Addestramento CNN+KAN\n",
    "print(\"\\n=== CNN + KAN Results ===\")\n",
    "best_cnn_kan, model_params_cnn_kan, train_params_cnn_kan = random_search_cnn(\n",
    "    lambda **p: CNN_KAN(**p),\n",
    "    cnn_kan_param_dist,\n",
    "    train_paths,\n",
    "    train_labels,\n",
    "    class_weights=class_weights_dict,\n",
    "    device=device,\n",
    "    n_iter=15\n",
    ")\n",
    "\n",
    "cnn_kan_config = {\n",
    "    \"model_params\": model_params_cnn_kan,\n",
    "    \"train_params\": train_params_cnn_kan\n",
    "}\n",
    "\n",
    "with open('cnn_kan_config.json', 'w') as f:\n",
    "    json.dump(cnn_kan_config, f, indent=4)\n",
    "print(\"Configurazione completa di CNN_KAN salvata.\")\n",
    "\n",
    "torch.save(best_cnn_kan.state_dict(), 'best_cnn_kan.pth')\n",
    "print(\"Modello CNN_KAN salvato.\")\n",
    "\n",
    "get_cnn_estimator_scores(\"CNN_KAN\", best_cnn_kan,\n",
    "                        test_paths, test_labels,\n",
    "                        train_paths, train_labels,\n",
    "                        device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5uIugxCaMC9R",
   "metadata": {
    "id": "5uIugxCaMC9R"
   },
   "source": [
    "## Confronto Visivo delle Prestazioni dei Modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5vxh_8pW9qkC",
   "metadata": {
    "id": "5vxh_8pW9qkC"
   },
   "outputs": [],
   "source": [
    "def plot_estimator_scores(scores):\n",
    "    # Prepariamo i dati per il plot di Accuracy (Train vs Test)\n",
    "    melted_accuracy = (\n",
    "        scores[['Model', 'Accuracy_Train', 'Accuracy_Test']]\n",
    "        .rename(columns={'Accuracy_Train': 'Train', 'Accuracy_Test': 'Test'})\n",
    "        .melt(id_vars='Model', var_name='Set', value_name='Score')\n",
    "    )\n",
    "\n",
    "    model_order = scores['Model'].tolist()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    fig.tight_layout(pad=4.0)\n",
    "\n",
    "    # --- Plot 1: Accuracy (Train vs Test) ---\n",
    "    axs[0, 0].set_title('Accuracy')\n",
    "    sns.barplot(data=melted_accuracy, x='Score', y='Model', hue='Set', ax=axs[0, 0], order=model_order)\n",
    "    axs[0, 0].set_xlabel('Accuracy Score')\n",
    "    axs[0, 0].legend(loc='lower right', title='Set')\n",
    "    axs[0, 0].set_xlim(0, 1)\n",
    "\n",
    "    # --- Funzione helper per disegnare barh con CI in modo consistente ---\n",
    "    def plot_barh_with_ci(ax, data, metric_col, ci_low_col, ci_high_col, title, model_order):\n",
    "        ax.set_title(title)\n",
    "        # Assicurati che i dati siano ordinati per il plot coerente\n",
    "        data_ordered = data.set_index('Model').loc[model_order].reset_index()\n",
    "\n",
    "        for i, row in data_ordered.iterrows():\n",
    "            # Gestisci i valori NaN per i CI\n",
    "            val = row[metric_col]\n",
    "            if pd.isna(val):\n",
    "                continue # Salta il modello se il valore della metrica è NaN\n",
    "\n",
    "            err_low = [val - row[ci_low_col]] if not pd.isna(row[ci_low_col]) else [0]\n",
    "            err_high = [row[ci_high_col] - val] if not pd.isna(row[ci_high_col]) else [0]\n",
    "\n",
    "            ax.barh(\n",
    "                row['Model'], val,\n",
    "                xerr=[err_low, err_high],\n",
    "                capsize=5,\n",
    "                color=sns.color_palette(\"viridis\")[i % len(sns.color_palette(\"viridis\"))] # Colore coerente\n",
    "            )\n",
    "        ax.set_xlabel(title.split(' ')[0]) # Estrae il nome della metrica dal titolo\n",
    "        ax.invert_yaxis() # Per avere lo stesso ordine dei modelli sull'asse y\n",
    "        ax.set_xlim(0, 1) # Imposta i limiti per le metriche [0, 1]\n",
    "\n",
    "    # --- Plot 2: F1-Weighted Test Score ± CI95% ---\n",
    "    plot_barh_with_ci(axs[0, 1], scores, 'F1_Weighted_Test', 'F1_Weighted_CI_Low', 'F1_Weighted_CI_High',\n",
    "                      'F1-Weighted Test ± CI95%', model_order)\n",
    "\n",
    "    # --- Plot 3: F1-Macro Test Score ± CI95% ---\n",
    "    plot_barh_with_ci(axs[0, 2], scores, 'F1_Macro_Test', 'F1_Macro_CI_Low', 'F1_Macro_CI_High',\n",
    "                      'F1-Macro Test ± CI95%', model_order)\n",
    "\n",
    "    # --- Plot 4: AUC-ROC OVR Weighted Test Score ± CI95% ---\n",
    "    plot_barh_with_ci(axs[1, 0], scores, 'AUC_ROC_OVR_Weighted', 'AUC_ROC_CI_Low', 'AUC_ROC_CI_High',\n",
    "                      'AUC-ROC (OVR Weighted) Test ± CI95%', model_order)\n",
    "\n",
    "    # --- Plot 5: AUC-PR OVR Weighted Test Score ± CI95% ---\n",
    "    plot_barh_with_ci(axs[1, 1], scores, 'AUC_PR_OVR_Weighted', 'AUC_PR_CI_Low', 'AUC_PR_CI_High',\n",
    "                      'AUC-PR (OVR Weighted) Test ± CI95%', model_order)\n",
    "\n",
    "    # --- Plot 6: Model Complexity (Parameter/Node Count) ---\n",
    "    axs[1, 2].set_title('Model Complexity (Parameters/Nodes)', fontsize=12, fontweight='bold')\n",
    "\n",
    "    # Order data by model order for consistency\n",
    "    scores_ordered = scores.set_index('Model').loc[model_order].reset_index()\n",
    "\n",
    "    # Create color palette\n",
    "    colors = sns.color_palette(\"plasma\", len(scores_ordered))\n",
    "\n",
    "    bars = axs[1, 2].barh(scores_ordered['Model'], scores_ordered['Param_Count'], color=colors)\n",
    "    axs[1, 2].set_xlabel('Parameter/Node Count')\n",
    "    axs[1, 2].invert_yaxis()\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for i, (bar, count) in enumerate(zip(bars, scores_ordered['Param_Count'])):\n",
    "        if not pd.isna(count) and count > 0:\n",
    "            axs[1, 2].text(bar.get_width() + max(scores_ordered['Param_Count']) * 0.01,\n",
    "                          bar.get_y() + bar.get_height()/2,\n",
    "                          f'{int(count):,}',\n",
    "                          va='center', fontsize=9)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RTHU3LQ49qkD",
   "metadata": {
    "id": "RTHU3LQ49qkD"
   },
   "outputs": [],
   "source": [
    "estimator_scores_df = pd.DataFrame(\n",
    "    all_scores,\n",
    "    columns = [\n",
    "        'Model', 'Param_Count',\n",
    "        'Accuracy_Train', 'Accuracy_Test',\n",
    "        'F1_Weighted_Train', 'F1_Weighted_Test', 'F1_Weighted_CI_Low', 'F1_Weighted_CI_High',\n",
    "        'F1_Macro_Train', 'F1_Macro_Test', 'F1_Macro_CI_Low', 'F1_Macro_CI_High',\n",
    "        'AUC_ROC_OVR_Weighted', 'AUC_ROC_CI_Low', 'AUC_ROC_CI_High',\n",
    "        'AUC_PR_OVR_Weighted', 'AUC_PR_CI_Low', 'AUC_PR_CI_High'\n",
    "    ]\n",
    ")\n",
    "plot_estimator_scores(estimator_scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EvcGaDcg8Q8R",
   "metadata": {
    "id": "EvcGaDcg8Q8R"
   },
   "source": [
    "## Selezione del Miglior Modello\n",
    "Calcoliamo un punteggio complessivo per ciascun modello basandoci sulle metriche di valutazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B0DEhNMS8M8S",
   "metadata": {
    "id": "B0DEhNMS8M8S"
   },
   "outputs": [],
   "source": [
    "# 1) Define metrics and their optimization direction\n",
    "metrics = {\n",
    "    'Accuracy_Test': 'max',\n",
    "    'F1_Weighted_Test': 'max',\n",
    "    'F1_Macro_Test': 'max',\n",
    "    'AUC_ROC_OVR_Weighted': 'max',\n",
    "    'AUC_PR_OVR_Weighted': 'max'\n",
    "}\n",
    "\n",
    "# 2) Build ranking DataFrame\n",
    "df_ranks = estimator_scores_df.set_index('Model')\n",
    "ranks = pd.DataFrame(index=df_ranks.index)\n",
    "\n",
    "# Calculate ranks for performance metrics\n",
    "for metric, direction in metrics.items():\n",
    "    if direction == 'max':\n",
    "        # Per metriche 'max' (più alto è meglio), rank in ordine decrescente (rank 1 al migliore)\n",
    "        ranks[f\"{metric}_rank\"] = df_ranks[metric].rank(ascending=False, method='average')\n",
    "    elif direction == 'min':\n",
    "        # Per metriche 'min' (più basso è meglio), rank in ordine crescente (rank 1 al migliore)\n",
    "        ranks[f\"{metric}_rank\"] = df_ranks[metric].rank(ascending=True, method='average')\n",
    "\n",
    "# Calculate complexity rank (lower parameter count is better)\n",
    "ranks['Complexity_rank'] = df_ranks['Param_Count'].rank(ascending=True, method='average')\n",
    "\n",
    "# 3) Calculate weighted scores\n",
    "# Performance score (average of performance ranks)\n",
    "performance_cols = [col for col in ranks.columns if col.endswith('_rank') and col != 'Complexity_rank']\n",
    "ranks['performance_score'] = ranks[performance_cols].mean(axis=1)\n",
    "\n",
    "# Method 1: Equal weighting\n",
    "ranks['equal_weight_score'] = ranks['performance_score'] + ranks['Complexity_rank']\n",
    "\n",
    "# Method 2: Complexity heavily weighted (complexity counts 2x)\n",
    "ranks['complexity_weighted_score'] = ranks['performance_score'] + (2 * ranks['Complexity_rank'])\n",
    "\n",
    "# Method 3: Extreme complexity weighting (complexity counts 3x)\n",
    "ranks['extreme_complexity_score'] = ranks['performance_score'] + (3 * ranks['Complexity_rank'])\n",
    "\n",
    "# Method 4: Pareto efficiency approach (performance vs complexity)\n",
    "# Normalize scores to [0,1] for fair comparison\n",
    "performance_norm = (ranks['performance_score'] - ranks['performance_score'].min()) / (ranks['performance_score'].max() - ranks['performance_score'].min())\n",
    "complexity_norm = (ranks['Complexity_rank'] - ranks['Complexity_rank'].min()) / (ranks['Complexity_rank'].max() - ranks['Complexity_rank'].min())\n",
    "ranks['pareto_score'] = 0.4 * performance_norm + 0.6 * complexity_norm  # 60% weight on complexity\n",
    "\n",
    "# Display results for each method\n",
    "methods = {\n",
    "    'Equal Weight (1:1)': 'equal_weight_score',\n",
    "    'Complexity Weighted (1:2)': 'complexity_weighted_score',\n",
    "    'Extreme Complexity (1:3)': 'extreme_complexity_score',\n",
    "    'Pareto Approach (40:60)': 'pareto_score'\n",
    "}\n",
    "\n",
    "results_summary = pd.DataFrame(index=df_ranks.index)\n",
    "results_summary['Performance_Score'] = ranks['performance_score']\n",
    "results_summary['Complexity_Rank'] = ranks['Complexity_rank']\n",
    "results_summary['Param_Count'] = df_ranks['Param_Count']\n",
    "\n",
    "for method_name, score_col in methods.items():\n",
    "    best_model = ranks[score_col].idxmin() if 'pareto' not in score_col else ranks[score_col].idxmin()\n",
    "    best_score = ranks.loc[best_model, score_col]\n",
    "    results_summary[method_name] = ranks[score_col]\n",
    "    print(f\"{method_name:25} -> {best_model:15} (score: {best_score:.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED RANKING TABLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create comprehensive ranking table\n",
    "ranking_display = pd.DataFrame(index=df_ranks.index)\n",
    "ranking_display['Param_Count'] = df_ranks['Param_Count'].astype(int)\n",
    "ranking_display['Avg_Performance'] = ranks['performance_score'].round(2)\n",
    "ranking_display['Complexity_Rank'] = ranks['Complexity_rank'].astype(int)\n",
    "\n",
    "for method_name, score_col in methods.items():\n",
    "    ranking_display[f'{method_name.split()[0]}_Rank'] = ranks[score_col].rank().astype(int)\n",
    "\n",
    "# Sort by complexity-weighted score (our recommended approach)\n",
    "ranking_display_sorted = ranking_display.sort_values('Complexity_Rank')\n",
    "display(ranking_display_sorted)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Our recommended model (complexity weighted approach)\n",
    "recommended_model = ranks['complexity_weighted_score'].idxmin()\n",
    "recommended_score = ranks.loc[recommended_model, 'complexity_weighted_score']\n",
    "recommended_params = df_ranks.loc[recommended_model, 'Param_Count']\n",
    "recommended_f1_score = df_ranks.loc[recommended_model, 'F1_Weighted_Test']\n",
    "\n",
    "print(f\"   RECOMMENDED MODEL: {recommended_model}\")\n",
    "print(f\"   Reason: Best balance between performance and complexity\")\n",
    "print(f\"   Parameters: {int(recommended_params):,}\")\n",
    "print(f\"   F1-Weighted Score: {recommended_f1_score:.4f}\")\n",
    "print(f\"   Complexity-Weighted Rank Score: {recommended_score:.3f}\")\n",
    "\n",
    "# Show top 3 models for comparison\n",
    "print(f\"\\n  TOP 3 MODELS (Complexity-Weighted Ranking):\")\n",
    "top_3 = ranks.sort_values('complexity_weighted_score').head(3)\n",
    "for i, (model, row) in enumerate(top_3.iterrows(), 1):\n",
    "    params = int(df_ranks.loc[model, 'Param_Count'])\n",
    "    current_f1_score = df_ranks.loc[model, 'F1_Weighted_Test']\n",
    "    print(f\"   {i}. {model:15} | Params: {params:>8,} | F1: {current_f1_score:.4f} | Score: {row['complexity_weighted_score']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "51-VyZP_BGdJ",
    "8rTDr1p2Fl6p",
    "5mfmIBJdA5vB",
    "WFrnOr1MwNvn",
    "S5I6uB7hJBDo",
    "5GZyqqRSUQF-",
    "toQbpNSDUSKt",
    "GFSzW1CBUM7y",
    "RAZJ5vZNUJe7",
    "JP9fNayGUFuW",
    "aqmioU9_TzTk",
    "N2VbqTAtT4PW",
    "5uIugxCaMC9R",
    "EvcGaDcg8Q8R"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 249.324246,
   "end_time": "2023-10-20T02:19:51.297702",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-20T02:15:41.973456",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
